{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EstimationBias_in_DeepQNets.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "927XuS3miph7"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "\n",
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "from collections import deque, namedtuple\n",
        "import copy\n",
        "from itertools import count\n",
        "import math\n",
        "import random\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVxPAr-8jvzN",
        "outputId": "2dd0c5a2-6607-4a60-95d2-c1ca59d23e9e"
      },
      "source": [
        "!git clone 'https://github.com/jmichaux/dqn-pytorch'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'dqn-pytorch' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuuOZsTimS9R"
      },
      "source": [
        "import os\n",
        "os.chdir('dqn-pytorch')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13CVQzAZj_7w"
      },
      "source": [
        "from wrappers import *\n",
        "from wrappers import *\n",
        "from memory import ReplayMemory\n",
        "from models import *"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuEkR3bR2lF0"
      },
      "source": [
        "from collections import namedtuple\n",
        "import random\n",
        "\n",
        "Transition = namedtuple('Transion', \n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "Data = namedtuple('Data',('priority','probability','weight','index'))\n",
        "\n",
        "class ReplayMemory(object):\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "        \n",
        "    def push(self, *args):\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = Transition(*args)\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "        \n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "\n",
        "class ReplayBuffer:\n",
        "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
        "\n",
        "    def __init__(self, action_size, buffer_size, batch_size, experiences_per_sampling, seed, compute_weights):\n",
        "        \"\"\"Initialize a ReplayBuffer object.\n",
        "        Params\n",
        "        ======\n",
        "            action_size (int): dimension of each action\n",
        "            buffer_size (int): maximum size of buffer\n",
        "            experiences_per_sampling (int): number of experiences to sample during a sampling iteration\n",
        "            batch_size (int): size of each training batch\n",
        "            seed (int): random seed\n",
        "        \"\"\"\n",
        "        self.action_size = action_size\n",
        "        self.buffer_size = buffer_size\n",
        "        self.batch_size = batch_size\n",
        "        self.experiences_per_sampling = experiences_per_sampling\n",
        "        \n",
        "        self.alpha = 0.5\n",
        "        self.alpha_decay_rate = 0.99\n",
        "        self.beta = 0.5\n",
        "        self.beta_growth_rate = 1.001\n",
        "        self.seed = random.seed(seed)\n",
        "        self.compute_weights = compute_weights\n",
        "        self.experience_count = 0\n",
        "        \n",
        "        self.experience = namedtuple(\"Experience\", \n",
        "            field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
        "        self.data = namedtuple(\"Data\", \n",
        "            field_names=[\"priority\", \"probability\", \"weight\",\"index\"])\n",
        "\n",
        "        indexes = []\n",
        "        datas = []\n",
        "        for i in range(buffer_size):\n",
        "            indexes.append(i)\n",
        "            d = self.data(0,0,0,i)\n",
        "            datas.append(d)\n",
        "        \n",
        "        self.memory = {key: self.experience for key in indexes}\n",
        "        self.memory_data = {key: data for key,data in zip(indexes, datas)}\n",
        "        self.sampled_batches = []\n",
        "        self.current_batch = 0\n",
        "        self.priorities_sum_alpha = 0\n",
        "        self.priorities_max = 1\n",
        "        self.weights_max = 1\n",
        "    \n",
        "    def update_priorities(self, tds, indices):\n",
        "        for td, index in zip(tds, indices):\n",
        "            N = min(self.experience_count, self.buffer_size)\n",
        "\n",
        "            updated_priority = td[0]\n",
        "            if updated_priority > self.priorities_max:\n",
        "                self.priorities_max = updated_priority\n",
        "            \n",
        "            if self.compute_weights:\n",
        "                updated_weight = ((N * updated_priority)**(-self.beta))/self.weights_max\n",
        "                if updated_weight > self.weights_max:\n",
        "                    self.weights_max = updated_weight\n",
        "            else:\n",
        "                updated_weight = 1\n",
        "\n",
        "            old_priority = self.memory_data[index].priority\n",
        "            self.priorities_sum_alpha += updated_priority**self.alpha - old_priority**self.alpha\n",
        "            updated_probability = td[0]**self.alpha / self.priorities_sum_alpha\n",
        "            data = self.data(updated_priority, updated_probability, updated_weight, index) \n",
        "            self.memory_data[index] = data\n",
        "\n",
        "    def update_memory_sampling(self):\n",
        "        \"\"\"Randomly sample X batches of experiences from memory.\"\"\"\n",
        "        # X is the number of steps before updating memory\n",
        "        self.current_batch = 0\n",
        "        values = list(self.memory_data.values())\n",
        "        random_values = random.choices(self.memory_data, \n",
        "                                       [data.probability for data in values], \n",
        "                                       k=self.experiences_per_sampling)\n",
        "        self.sampled_batches = [random_values[i:i + self.batch_size] \n",
        "                                    for i in range(0, len(random_values), self.batch_size)]\n",
        "\n",
        "    def update_parameters(self):\n",
        "        self.alpha *= self.alpha_decay_rate\n",
        "        self.beta *= self.beta_growth_rate\n",
        "        if self.beta > 1:\n",
        "            self.beta = 1\n",
        "        N = min(self.experience_count, self.buffer_size)\n",
        "        self.priorities_sum_alpha = 0\n",
        "        sum_prob_before = 0\n",
        "        for element in self.memory_data.values():\n",
        "            sum_prob_before += element.probability\n",
        "            self.priorities_sum_alpha += element.priority**self.alpha\n",
        "        sum_prob_after = 0\n",
        "        for element in self.memory_data.values():\n",
        "            probability = element.priority**self.alpha / self.priorities_sum_alpha\n",
        "            sum_prob_after += probability\n",
        "            weight = 1\n",
        "            if self.compute_weights:\n",
        "                weight = ((N *  element.probability)**(-self.beta))/self.weights_max\n",
        "            d = self.data(element.priority, probability, weight, element.index)\n",
        "            self.memory_data[element.index] = d\n",
        "        print(\"sum_prob before\", sum_prob_before)\n",
        "        print(\"sum_prob after : \", sum_prob_after)\n",
        "    \n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Add a new experience to memory.\"\"\"\n",
        "        self.experience_count += 1\n",
        "        index = self.experience_count % self.buffer_size\n",
        "\n",
        "        if self.experience_count > self.buffer_size:\n",
        "            temp = self.memory_data[index]\n",
        "            self.priorities_sum_alpha -= temp.priority**self.alpha\n",
        "            if temp.priority == self.priorities_max:\n",
        "                self.memory_data[index].priority = 0\n",
        "                self.priorities_max = max(self.memory_data.items(), key=operator.itemgetter(1)).priority\n",
        "            if self.compute_weights:\n",
        "                if temp.weight == self.weights_max:\n",
        "                    self.memory_data[index].weight = 0\n",
        "                    self.weights_max = max(self.memory_data.items(), key=operator.itemgetter(2)).weight\n",
        "\n",
        "        priority = self.priorities_max\n",
        "        weight = self.weights_max\n",
        "        self.priorities_sum_alpha += priority ** self.alpha\n",
        "        probability = priority ** self.alpha / self.priorities_sum_alpha\n",
        "        e = self.experience(state, action, reward, next_state, done)\n",
        "        self.memory[index] = e\n",
        "        d = self.data(priority, probability, weight, index)\n",
        "        self.memory_data[index] = d\n",
        "            \n",
        "    def sample(self):\n",
        "        sampled_batch = self.sampled_batches[self.current_batch]\n",
        "        self.current_batch += 1\n",
        "        experiences = []\n",
        "        weights = []\n",
        "        indices = []\n",
        "        \n",
        "        for data in sampled_batch:\n",
        "            experiences.append(self.memory.get(data.index))\n",
        "            weights.append(data.weight)\n",
        "            indices.append(data.index)\n",
        "\n",
        "        states = torch.from_numpy(\n",
        "            np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
        "        actions = torch.from_numpy(\n",
        "            np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
        "        rewards = torch.from_numpy(\n",
        "            np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
        "        next_states = torch.from_numpy(\n",
        "            np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
        "        dones = torch.from_numpy(\n",
        "            np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
        "\n",
        "        return (states, actions, rewards, next_states, dones, weights, indices)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the current size of internal memory.\"\"\"\n",
        "        return len(self.memory)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uhGGIfF2uWG"
      },
      "source": [
        "class ConvDQNbn(nn.Module):\n",
        "    def __init__(self, in_channels=4, n_actions=14):\n",
        "        \"\"\"\n",
        "        Initialize Deep Q Network\n",
        "        Args:\n",
        "            in_channels (int): number of input channels\n",
        "            n_actions (int): number of outputs\n",
        "        \"\"\"\n",
        "        super(ConvDQNbn, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=8, stride=4)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.fc4 = nn.Linear(7 * 7 * 64, 512)\n",
        "        self.head = nn.Linear(512, n_actions)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.float() / 255\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.fc4(x.view(x.size(0), -1)))\n",
        "        return self.head(x)\n",
        "\n",
        "\n",
        "class ConvDQN(nn.Module):\n",
        "    def __init__(self, in_channels=4, n_actions=14):\n",
        "        \"\"\"\n",
        "        Initialize Deep Q Network\n",
        "        Args:\n",
        "            in_channels (int): number of input channels\n",
        "            n_actions (int): number of outputs\n",
        "        \"\"\"\n",
        "        super(ConvDQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=8, stride=4)\n",
        "        # self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        # self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
        "        # self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.fc4 = nn.Linear(7 * 7 * 64, 512)\n",
        "        self.head = nn.Linear(512, n_actions)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.float() / 255\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.fc4(x.view(x.size(0), -1)))\n",
        "        return self.head(x)\n",
        "\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(DQN, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.input_dim[0], 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, self.output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, state):\n",
        "        qvals = self.fc(state)\n",
        "        return qvals"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3mFNXYmTSW1"
      },
      "source": [
        "Transition = namedtuple('Transion', \n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END)* \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "    with torch.no_grad():\n",
        "      values = policy_net(state.to(device)).max(1)\n",
        "    if sample > eps_threshold:\n",
        "            return values[0], values[1].view(1,1) #choose greedy policy\n",
        "    else:\n",
        "            return values[0],torch.tensor([[random.randrange(env.action_space.n)]], device=device, dtype=torch.long)\n",
        "\n",
        "    \n",
        "def optimize_model(mode = 'DDQN'):\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    \"\"\"\n",
        "    zip(*transitions) unzips the transitions into\n",
        "    Transition(*) creates new named tuple\n",
        "    batch.state - tuple of all the states (each state is a tensor)\n",
        "    batch.next_state - tuple of all the next states (each state is a tensor)\n",
        "    batch.reward - tuple of all the rewards (each reward is a float)\n",
        "    batch.action - tuple of all the actions (each action is an int)    \n",
        "    \"\"\"\n",
        "    batch = Transition(*zip(*transitions))\n",
        "    \n",
        "    actions = tuple((map(lambda a: torch.tensor([[a]], device=device), batch.action))) \n",
        "    rewards = tuple((map(lambda r: torch.tensor([r], device=device), batch.reward))) \n",
        "\n",
        "    non_final_mask = torch.tensor(\n",
        "        tuple(map(lambda s: s is not None, batch.next_state)),\n",
        "        device=device, dtype=torch.uint8)\n",
        "    \n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                       if s is not None]).to(device)\n",
        "    \n",
        "\n",
        "    state_batch = torch.cat(batch.state).to(device)\n",
        "    action_batch = torch.cat(actions).to(device)\n",
        "    reward_batch = torch.cat(rewards).to(device)\n",
        "    \n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch) # q values\n",
        "\n",
        "\n",
        "    if mode == 'DQN':\n",
        "      next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "      next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
        "      expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "    \n",
        "    \n",
        "    elif mode == 'DDQN':\n",
        "      next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "      next_action_values = policy_net(non_final_next_states).max(1)[1].detach()\n",
        "      next_state_values[non_final_mask] = target_net(non_final_next_states).gather(1,next_action_values.unsqueeze(1)).detach().squeeze()\n",
        "      expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "    \n",
        "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    for param in policy_net.parameters():\n",
        "        param.grad.data.clamp_(-1, 1)\n",
        "    optimizer.step()\n",
        "\n",
        "def get_state(obs):\n",
        "    state = np.array(obs)\n",
        "    state = state.transpose((2, 0, 1))\n",
        "    state = torch.from_numpy(state)\n",
        "    return state.unsqueeze(0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4RfT9GSz9nc"
      },
      "source": [
        "def train(env, n_episodes, set_size, mode = 'DQN', render=False):\n",
        "    val_tensor = []\n",
        "    s = 0\n",
        "    total_reward = 0\n",
        "    result = np.zeros(int(n_episodes))\n",
        "    for episode in range(n_episodes):\n",
        "        obs = env.reset()\n",
        "        state = get_state(obs)\n",
        "        value_list = []\n",
        "        total_reward = 0\n",
        "        n_steps = 0\n",
        "        for t in count():\n",
        "            value, action = select_action(state)\n",
        "            n_steps += 1\n",
        "            value_list.append(value[0].item())\n",
        "            if steps_done % 1000 ==0:\n",
        "              val_tensor.append([np.mean(value_list), np.std(value_list)/np.sqrt(10000-1)])\n",
        "              value_list = []\n",
        "\n",
        "\n",
        "            if render:\n",
        "                env.render()\n",
        "\n",
        "            obs, reward, done, info = env.step(action)\n",
        "           \n",
        "            total_reward += reward\n",
        "\n",
        "            if not done:\n",
        "                next_state = get_state(obs)\n",
        "            else:\n",
        "                next_state = None\n",
        "                #total_reward += 1\n",
        "\n",
        "            reward = torch.tensor([reward], device=device)\n",
        "\n",
        "            memory.push(state, action.to('cpu'), next_state, reward.to('cpu'))\n",
        "            state = next_state\n",
        "\n",
        "            if steps_done > INITIAL_MEMORY:\n",
        "                optimize_model(mode)\n",
        "\n",
        "                if steps_done % TARGET_UPDATE == 0:\n",
        "                    target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "            if done:\n",
        "                result[episode] = total_reward / n_steps\n",
        "                n_steps = 0\n",
        "                break\n",
        "        if episode % 20 == 0:\n",
        "                print('Total steps: {} \\t Episode: {}/{} \\t Total reward: {}'.format(steps_done, episode, t, total_reward))\n",
        "    env.close()\n",
        "    return val_tensor, result\n",
        "\n",
        "def test(env, n_episodes, policy, render=True):\n",
        "    env = gym.wrappers.Monitor(env, './videos/' + 'dqn_pong_video')\n",
        "    for episode in range(n_episodes):\n",
        "        obs = env.reset()\n",
        "        state = get_state(obs)\n",
        "        total_reward = 0.0\n",
        "        for t in count():\n",
        "            action = policy(state.to('cuda')).max(1)[1].view(1,1)\n",
        "\n",
        "            if render:\n",
        "                env.render()\n",
        "                time.sleep(0.02)\n",
        "\n",
        "            obs, reward, done, info = env.step(action)\n",
        "\n",
        "            total_reward += reward\n",
        "\n",
        "            if not done:\n",
        "                next_state = get_state(obs)\n",
        "            else:\n",
        "                next_state = None\n",
        "\n",
        "            state = next_state\n",
        "\n",
        "            if done:\n",
        "                print(\"Finished Episode {} with reward {}\".format(episode, total_reward))\n",
        "                break\n",
        "\n",
        "    env.close()\n",
        "    return"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1mbReio2gCJ",
        "outputId": "217bfb19-f4b4-4e7b-a153-b4ca4d6abcde"
      },
      "source": [
        "# set device\n",
        "\n",
        "def weight_reset(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "        m.reset_parameters()\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# hyperparameters\n",
        "BATCH_SIZE = 32\n",
        "GAMMA = 0.99\n",
        "EPS_START = 1\n",
        "EPS_END = 0.02\n",
        "EPS_DECAY = 1000000\n",
        "TARGET_UPDATE = 1000\n",
        "RENDER = False\n",
        "lr = 1e-4\n",
        "INITIAL_MEMORY = 10000\n",
        "MEMORY_SIZE = 10 * INITIAL_MEMORY\n",
        "\n",
        "# create environment\n",
        "env = gym.make(\"Alien-v0\")\n",
        "env = make_env(env)\n",
        "\n",
        "\n",
        "# create networks\n",
        "policy_net = ConvDQNbn(n_actions=env.action_space.n).to(device)\n",
        "target_net = ConvDQNbn(n_actions=env.action_space.n).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "# setup optimizer\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=lr)\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "# initialize replay memory\n",
        "memory = ReplayMemory(MEMORY_SIZE)\n",
        "policy_net.apply(weight_reset)\n",
        "target_net.apply(weight_reset)\n",
        "# train model\n",
        "val_tensor_DDQN, result_DDQN = train(env, 2000, 10, mode='DDQN')\n",
        "torch.save(policy_net, \"ddqn_alien_model\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total steps: 92 \t Episode: 0/91 \t Total reward: 130.0\n",
            "Total steps: 1334 \t Episode: 20/54 \t Total reward: 20.0\n",
            "Total steps: 2575 \t Episode: 40/46 \t Total reward: 30.0\n",
            "Total steps: 3638 \t Episode: 60/73 \t Total reward: 160.0\n",
            "Total steps: 5020 \t Episode: 80/58 \t Total reward: 540.0\n",
            "Total steps: 6333 \t Episode: 100/70 \t Total reward: 40.0\n",
            "Total steps: 7673 \t Episode: 120/55 \t Total reward: 130.0\n",
            "Total steps: 9069 \t Episode: 140/42 \t Total reward: 90.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total steps: 10298 \t Episode: 160/51 \t Total reward: 20.0\n",
            "Total steps: 11678 \t Episode: 180/72 \t Total reward: 130.0\n",
            "Total steps: 12907 \t Episode: 200/52 \t Total reward: 10.0\n",
            "Total steps: 14339 \t Episode: 220/59 \t Total reward: 70.0\n",
            "Total steps: 15651 \t Episode: 240/156 \t Total reward: 310.0\n",
            "Total steps: 16984 \t Episode: 260/41 \t Total reward: 0.0\n",
            "Total steps: 18272 \t Episode: 280/69 \t Total reward: 90.0\n",
            "Total steps: 19526 \t Episode: 300/60 \t Total reward: 90.0\n",
            "Total steps: 21051 \t Episode: 320/56 \t Total reward: 80.0\n",
            "Total steps: 22273 \t Episode: 340/54 \t Total reward: 50.0\n",
            "Total steps: 23610 \t Episode: 360/55 \t Total reward: 50.0\n",
            "Total steps: 25086 \t Episode: 380/77 \t Total reward: 110.0\n",
            "Total steps: 26254 \t Episode: 400/46 \t Total reward: 30.0\n",
            "Total steps: 27374 \t Episode: 420/60 \t Total reward: 130.0\n",
            "Total steps: 28772 \t Episode: 440/55 \t Total reward: 10.0\n",
            "Total steps: 30090 \t Episode: 460/96 \t Total reward: 80.0\n",
            "Total steps: 31356 \t Episode: 480/67 \t Total reward: 110.0\n",
            "Total steps: 32777 \t Episode: 500/57 \t Total reward: 140.0\n",
            "Total steps: 34306 \t Episode: 520/41 \t Total reward: 100.0\n",
            "Total steps: 35633 \t Episode: 540/59 \t Total reward: 120.0\n",
            "Total steps: 37143 \t Episode: 560/79 \t Total reward: 90.0\n",
            "Total steps: 38358 \t Episode: 580/31 \t Total reward: 110.0\n",
            "Total steps: 39734 \t Episode: 600/49 \t Total reward: 130.0\n",
            "Total steps: 41134 \t Episode: 620/58 \t Total reward: 80.0\n",
            "Total steps: 42476 \t Episode: 640/78 \t Total reward: 130.0\n",
            "Total steps: 43957 \t Episode: 660/44 \t Total reward: 70.0\n",
            "Total steps: 45210 \t Episode: 680/36 \t Total reward: 10.0\n",
            "Total steps: 46504 \t Episode: 700/59 \t Total reward: 70.0\n",
            "Total steps: 47721 \t Episode: 720/54 \t Total reward: 90.0\n",
            "Total steps: 49101 \t Episode: 740/71 \t Total reward: 80.0\n",
            "Total steps: 50526 \t Episode: 760/46 \t Total reward: 20.0\n",
            "Total steps: 51958 \t Episode: 780/55 \t Total reward: 160.0\n",
            "Total steps: 53305 \t Episode: 800/74 \t Total reward: 110.0\n",
            "Total steps: 54841 \t Episode: 820/85 \t Total reward: 160.0\n",
            "Total steps: 56130 \t Episode: 840/66 \t Total reward: 170.0\n",
            "Total steps: 57411 \t Episode: 860/56 \t Total reward: 100.0\n",
            "Total steps: 58782 \t Episode: 880/140 \t Total reward: 320.0\n",
            "Total steps: 60234 \t Episode: 900/55 \t Total reward: 110.0\n",
            "Total steps: 61520 \t Episode: 920/44 \t Total reward: 20.0\n",
            "Total steps: 62888 \t Episode: 940/71 \t Total reward: 110.0\n",
            "Total steps: 64140 \t Episode: 960/45 \t Total reward: 160.0\n",
            "Total steps: 65752 \t Episode: 980/86 \t Total reward: 110.0\n",
            "Total steps: 66958 \t Episode: 1000/40 \t Total reward: 80.0\n",
            "Total steps: 68295 \t Episode: 1020/58 \t Total reward: 110.0\n",
            "Total steps: 69822 \t Episode: 1040/46 \t Total reward: 30.0\n",
            "Total steps: 71073 \t Episode: 1060/47 \t Total reward: 70.0\n",
            "Total steps: 72407 \t Episode: 1080/55 \t Total reward: 90.0\n",
            "Total steps: 73921 \t Episode: 1100/61 \t Total reward: 70.0\n",
            "Total steps: 75060 \t Episode: 1120/25 \t Total reward: 80.0\n",
            "Total steps: 76434 \t Episode: 1140/55 \t Total reward: 90.0\n",
            "Total steps: 77934 \t Episode: 1160/50 \t Total reward: 40.0\n",
            "Total steps: 79164 \t Episode: 1180/56 \t Total reward: 100.0\n",
            "Total steps: 80566 \t Episode: 1200/108 \t Total reward: 250.0\n",
            "Total steps: 81883 \t Episode: 1220/59 \t Total reward: 30.0\n",
            "Total steps: 83170 \t Episode: 1240/65 \t Total reward: 90.0\n",
            "Total steps: 84364 \t Episode: 1260/44 \t Total reward: 120.0\n",
            "Total steps: 85898 \t Episode: 1280/51 \t Total reward: 100.0\n",
            "Total steps: 87438 \t Episode: 1300/71 \t Total reward: 120.0\n",
            "Total steps: 88782 \t Episode: 1320/93 \t Total reward: 210.0\n",
            "Total steps: 90141 \t Episode: 1340/43 \t Total reward: 50.0\n",
            "Total steps: 91581 \t Episode: 1360/45 \t Total reward: 40.0\n",
            "Total steps: 92823 \t Episode: 1380/114 \t Total reward: 250.0\n",
            "Total steps: 94374 \t Episode: 1400/62 \t Total reward: 20.0\n",
            "Total steps: 95534 \t Episode: 1420/40 \t Total reward: 40.0\n",
            "Total steps: 96698 \t Episode: 1440/52 \t Total reward: 150.0\n",
            "Total steps: 98038 \t Episode: 1460/65 \t Total reward: 150.0\n",
            "Total steps: 99268 \t Episode: 1480/43 \t Total reward: 0.0\n",
            "Total steps: 100519 \t Episode: 1500/45 \t Total reward: 90.0\n",
            "Total steps: 101889 \t Episode: 1520/48 \t Total reward: 10.0\n",
            "Total steps: 103304 \t Episode: 1540/90 \t Total reward: 250.0\n",
            "Total steps: 104523 \t Episode: 1560/24 \t Total reward: 100.0\n",
            "Total steps: 105893 \t Episode: 1580/56 \t Total reward: 80.0\n",
            "Total steps: 107226 \t Episode: 1600/95 \t Total reward: 150.0\n",
            "Total steps: 108679 \t Episode: 1620/110 \t Total reward: 180.0\n",
            "Total steps: 109860 \t Episode: 1640/56 \t Total reward: 150.0\n",
            "Total steps: 111191 \t Episode: 1660/64 \t Total reward: 110.0\n",
            "Total steps: 112501 \t Episode: 1680/53 \t Total reward: 100.0\n",
            "Total steps: 113706 \t Episode: 1700/38 \t Total reward: 30.0\n",
            "Total steps: 115113 \t Episode: 1720/51 \t Total reward: 50.0\n",
            "Total steps: 116444 \t Episode: 1740/106 \t Total reward: 260.0\n",
            "Total steps: 117615 \t Episode: 1760/51 \t Total reward: 60.0\n",
            "Total steps: 118880 \t Episode: 1780/47 \t Total reward: 50.0\n",
            "Total steps: 120379 \t Episode: 1800/46 \t Total reward: 190.0\n",
            "Total steps: 121582 \t Episode: 1820/43 \t Total reward: 100.0\n",
            "Total steps: 123159 \t Episode: 1840/56 \t Total reward: 70.0\n",
            "Total steps: 124525 \t Episode: 1860/31 \t Total reward: 120.0\n",
            "Total steps: 125941 \t Episode: 1880/47 \t Total reward: 60.0\n",
            "Total steps: 127365 \t Episode: 1900/65 \t Total reward: 160.0\n",
            "Total steps: 128805 \t Episode: 1920/42 \t Total reward: 150.0\n",
            "Total steps: 130163 \t Episode: 1940/54 \t Total reward: 40.0\n",
            "Total steps: 131638 \t Episode: 1960/95 \t Total reward: 210.0\n",
            "Total steps: 132858 \t Episode: 1980/35 \t Total reward: 100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbstXox7Pl6u",
        "outputId": "43f687d6-8613-43c5-cdb0-25b916e0e201"
      },
      "source": [
        "steps_done = 0\n",
        "\n",
        "# initialize replay memory\n",
        "memory = ReplayMemory(MEMORY_SIZE)\n",
        "\n",
        "policy_net.apply(weight_reset)\n",
        "target_net.apply(weight_reset)\n",
        "#policy_net = torch.load(\"dqn_pong_model\")\n",
        "val_tensor_DQN, result_DQN = train(env, 2000, 10, mode='DQN')\n",
        "torch.save(policy_net, \"dqn_alien_model\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total steps: 62 \t Episode: 0/61 \t Total reward: 70.0\n",
            "Total steps: 1373 \t Episode: 20/53 \t Total reward: 60.0\n",
            "Total steps: 3052 \t Episode: 40/109 \t Total reward: 270.0\n",
            "Total steps: 4463 \t Episode: 60/70 \t Total reward: 50.0\n",
            "Total steps: 5894 \t Episode: 80/70 \t Total reward: 50.0\n",
            "Total steps: 7078 \t Episode: 100/85 \t Total reward: 180.0\n",
            "Total steps: 8340 \t Episode: 120/68 \t Total reward: 20.0\n",
            "Total steps: 9742 \t Episode: 140/65 \t Total reward: 60.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total steps: 11082 \t Episode: 160/83 \t Total reward: 210.0\n",
            "Total steps: 12398 \t Episode: 180/77 \t Total reward: 90.0\n",
            "Total steps: 13917 \t Episode: 200/65 \t Total reward: 40.0\n",
            "Total steps: 15041 \t Episode: 220/44 \t Total reward: 110.0\n",
            "Total steps: 16452 \t Episode: 240/71 \t Total reward: 50.0\n",
            "Total steps: 17902 \t Episode: 260/159 \t Total reward: 240.0\n",
            "Total steps: 19207 \t Episode: 280/45 \t Total reward: 80.0\n",
            "Total steps: 20543 \t Episode: 300/41 \t Total reward: 30.0\n",
            "Total steps: 21792 \t Episode: 320/46 \t Total reward: 30.0\n",
            "Total steps: 23279 \t Episode: 340/59 \t Total reward: 110.0\n",
            "Total steps: 24458 \t Episode: 360/54 \t Total reward: 60.0\n",
            "Total steps: 25743 \t Episode: 380/44 \t Total reward: 30.0\n",
            "Total steps: 26965 \t Episode: 400/53 \t Total reward: 100.0\n",
            "Total steps: 28333 \t Episode: 420/52 \t Total reward: 90.0\n",
            "Total steps: 29530 \t Episode: 440/127 \t Total reward: 70.0\n",
            "Total steps: 30920 \t Episode: 460/70 \t Total reward: 140.0\n",
            "Total steps: 32348 \t Episode: 480/41 \t Total reward: 0.0\n",
            "Total steps: 33575 \t Episode: 500/30 \t Total reward: 70.0\n",
            "Total steps: 35131 \t Episode: 520/67 \t Total reward: 150.0\n",
            "Total steps: 36399 \t Episode: 540/57 \t Total reward: 30.0\n",
            "Total steps: 37776 \t Episode: 560/57 \t Total reward: 100.0\n",
            "Total steps: 39273 \t Episode: 580/160 \t Total reward: 350.0\n",
            "Total steps: 40581 \t Episode: 600/75 \t Total reward: 130.0\n",
            "Total steps: 41977 \t Episode: 620/78 \t Total reward: 90.0\n",
            "Total steps: 43207 \t Episode: 640/37 \t Total reward: 110.0\n",
            "Total steps: 44455 \t Episode: 660/93 \t Total reward: 630.0\n",
            "Total steps: 46144 \t Episode: 680/130 \t Total reward: 90.0\n",
            "Total steps: 47695 \t Episode: 700/100 \t Total reward: 190.0\n",
            "Total steps: 49312 \t Episode: 720/92 \t Total reward: 160.0\n",
            "Total steps: 50731 \t Episode: 740/48 \t Total reward: 40.0\n",
            "Total steps: 52072 \t Episode: 760/39 \t Total reward: 80.0\n",
            "Total steps: 53289 \t Episode: 780/64 \t Total reward: 20.0\n",
            "Total steps: 54532 \t Episode: 800/56 \t Total reward: 170.0\n",
            "Total steps: 55887 \t Episode: 820/88 \t Total reward: 130.0\n",
            "Total steps: 57116 \t Episode: 840/48 \t Total reward: 60.0\n",
            "Total steps: 58488 \t Episode: 860/69 \t Total reward: 20.0\n",
            "Total steps: 59681 \t Episode: 880/91 \t Total reward: 170.0\n",
            "Total steps: 60930 \t Episode: 900/114 \t Total reward: 130.0\n",
            "Total steps: 62248 \t Episode: 920/40 \t Total reward: 60.0\n",
            "Total steps: 63385 \t Episode: 940/34 \t Total reward: 150.0\n",
            "Total steps: 64521 \t Episode: 960/65 \t Total reward: 40.0\n",
            "Total steps: 65982 \t Episode: 980/55 \t Total reward: 0.0\n",
            "Total steps: 67296 \t Episode: 1000/48 \t Total reward: 80.0\n",
            "Total steps: 68635 \t Episode: 1020/72 \t Total reward: 0.0\n",
            "Total steps: 69935 \t Episode: 1040/91 \t Total reward: 190.0\n",
            "Total steps: 71192 \t Episode: 1060/62 \t Total reward: 120.0\n",
            "Total steps: 72380 \t Episode: 1080/50 \t Total reward: 110.0\n",
            "Total steps: 73688 \t Episode: 1100/66 \t Total reward: 80.0\n",
            "Total steps: 74973 \t Episode: 1120/52 \t Total reward: 110.0\n",
            "Total steps: 76214 \t Episode: 1140/51 \t Total reward: 550.0\n",
            "Total steps: 77554 \t Episode: 1160/52 \t Total reward: 180.0\n",
            "Total steps: 79208 \t Episode: 1180/39 \t Total reward: 100.0\n",
            "Total steps: 80465 \t Episode: 1200/68 \t Total reward: 10.0\n",
            "Total steps: 81636 \t Episode: 1220/39 \t Total reward: 70.0\n",
            "Total steps: 82934 \t Episode: 1240/84 \t Total reward: 200.0\n",
            "Total steps: 84251 \t Episode: 1260/35 \t Total reward: 40.0\n",
            "Total steps: 85611 \t Episode: 1280/66 \t Total reward: 150.0\n",
            "Total steps: 86951 \t Episode: 1300/53 \t Total reward: 80.0\n",
            "Total steps: 88412 \t Episode: 1320/67 \t Total reward: 150.0\n",
            "Total steps: 89731 \t Episode: 1340/29 \t Total reward: 80.0\n",
            "Total steps: 91061 \t Episode: 1360/44 \t Total reward: 120.0\n",
            "Total steps: 92344 \t Episode: 1380/78 \t Total reward: 90.0\n",
            "Total steps: 93606 \t Episode: 1400/52 \t Total reward: 140.0\n",
            "Total steps: 94969 \t Episode: 1420/34 \t Total reward: 110.0\n",
            "Total steps: 96235 \t Episode: 1440/45 \t Total reward: 20.0\n",
            "Total steps: 97513 \t Episode: 1460/59 \t Total reward: 70.0\n",
            "Total steps: 98801 \t Episode: 1480/50 \t Total reward: 80.0\n",
            "Total steps: 100077 \t Episode: 1500/41 \t Total reward: 90.0\n",
            "Total steps: 101349 \t Episode: 1520/48 \t Total reward: 60.0\n",
            "Total steps: 102684 \t Episode: 1540/92 \t Total reward: 220.0\n",
            "Total steps: 103852 \t Episode: 1560/86 \t Total reward: 100.0\n",
            "Total steps: 105112 \t Episode: 1580/91 \t Total reward: 130.0\n",
            "Total steps: 106516 \t Episode: 1600/48 \t Total reward: 80.0\n",
            "Total steps: 107977 \t Episode: 1620/105 \t Total reward: 150.0\n",
            "Total steps: 109405 \t Episode: 1640/107 \t Total reward: 250.0\n",
            "Total steps: 110932 \t Episode: 1660/72 \t Total reward: 170.0\n",
            "Total steps: 112223 \t Episode: 1680/44 \t Total reward: 50.0\n",
            "Total steps: 113465 \t Episode: 1700/51 \t Total reward: 100.0\n",
            "Total steps: 114593 \t Episode: 1720/68 \t Total reward: 210.0\n",
            "Total steps: 115721 \t Episode: 1740/53 \t Total reward: 120.0\n",
            "Total steps: 117150 \t Episode: 1760/55 \t Total reward: 20.0\n",
            "Total steps: 118448 \t Episode: 1780/55 \t Total reward: 70.0\n",
            "Total steps: 119710 \t Episode: 1800/73 \t Total reward: 150.0\n",
            "Total steps: 121167 \t Episode: 1820/87 \t Total reward: 160.0\n",
            "Total steps: 122494 \t Episode: 1840/47 \t Total reward: 80.0\n",
            "Total steps: 123788 \t Episode: 1860/103 \t Total reward: 120.0\n",
            "Total steps: 125062 \t Episode: 1880/49 \t Total reward: 40.0\n",
            "Total steps: 126265 \t Episode: 1900/86 \t Total reward: 170.0\n",
            "Total steps: 127486 \t Episode: 1920/69 \t Total reward: 110.0\n",
            "Total steps: 128922 \t Episode: 1940/41 \t Total reward: 140.0\n",
            "Total steps: 130265 \t Episode: 1960/39 \t Total reward: 120.0\n",
            "Total steps: 131565 \t Episode: 1980/31 \t Total reward: 50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BmRAJhX6W0h",
        "outputId": "00ca2316-36f7-4f19-eafa-50f3d1cf03f5"
      },
      "source": [
        "#policy_net = torch.load('dqn_pong_model')\n",
        "test(env, 1, policy_net, render=False)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished Episode 0 with reward 230.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtYFJXJftopf"
      },
      "source": [
        "value_tensor_DDQN = np.array(val_tensor_DDQN)\n",
        "value_tensor_DQN = np.array(val_tensor_DQN)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "LHEx2WCkfl9t",
        "outputId": "c80bea4d-3374-473a-a91b-836ee3d470dd"
      },
      "source": [
        "import colorlover as cl\n",
        "import plotly.graph_objects as go\n",
        "colors = cl.scales['5']['qual']['Set1']\n",
        "\n",
        "fig = go.Figure([\n",
        "    go.Scatter(\n",
        "        name='Double Deep Q Networks',\n",
        "        x=np.arange(len(value_tensor_DDQN[:,0]))*1000,\n",
        "        y=value_tensor_DDQN[:,0],\n",
        "        mode='lines',\n",
        "        line=dict(color=colors[0], width = 2),\n",
        "    ),\n",
        "    go.Scatter(\n",
        "        name='Upper Bound',\n",
        "        x=np.arange(len(value_tensor_DDQN[:,0]))*1000,\n",
        "        y=value_tensor_DDQN[:,0]+(value_tensor_DDQN[:,1])*np.sqrt(10000-1),\n",
        "        mode='lines',\n",
        "        marker=dict(color=\"#444\"),\n",
        "        line=dict(width=0),\n",
        "        showlegend=False\n",
        "    ),\n",
        "    go.Scatter(\n",
        "        name='Lower Bound',\n",
        "        x=np.arange(len(value_tensor_DDQN[:,0]))*1000,\n",
        "        y=value_tensor_DDQN[:,0]-(value_tensor_DDQN[:,1])*np.sqrt(10000-1),\n",
        "        marker=dict(color=\"#444\"),\n",
        "        line=dict(width=0),\n",
        "        mode='lines',\n",
        "        fillcolor='rgba(68, 68, 68, 0.3)',\n",
        "        fill='tonexty',\n",
        "        showlegend=False\n",
        "    ),\n",
        "        go.Scatter(\n",
        "        name='Deep Q Networks',\n",
        "        x=np.arange(len(value_tensor_DQN[:,0]))*1000,\n",
        "        y=value_tensor_DQN[:,0],\n",
        "        mode='lines',\n",
        "        line=dict(color=colors[1], width = 2),\n",
        "    ),\n",
        "    go.Scatter(\n",
        "        name='Upper Bound',\n",
        "        x=np.arange(len(value_tensor_DQN[:,0]))*1000,\n",
        "        y=value_tensor_DQN[:,0]+(value_tensor_DQN[:,1])*np.sqrt(10000-1),\n",
        "        mode='lines',\n",
        "        marker=dict(color=\"#444\"),\n",
        "        line=dict(width=0),\n",
        "        showlegend=False\n",
        "    ),\n",
        "    go.Scatter(\n",
        "        name='Lower Bound',\n",
        "        x=np.arange(len(value_tensor_DQN[:,0]))*1000,\n",
        "        y=value_tensor_DQN[:,0]-(value_tensor_DQN[:,1])*np.sqrt(10000-1),\n",
        "        marker=dict(color=\"#444\"),\n",
        "        line=dict(width=0),\n",
        "        mode='lines',\n",
        "        fillcolor='rgba(68, 68, 68, 0.3)',\n",
        "        fill='tonexty',\n",
        "        showlegend=False\n",
        "    )\n",
        "])\n",
        "\n",
        "fig.update_layout(\n",
        "    yaxis_title='Avg. Value Estimate (greedy policy)',\n",
        "    title='Estimation Bias in Deep Q networks',\n",
        "    hovermode=\"x\",\n",
        "    paper_bgcolor = 'rgba(0,0,0,0)',\n",
        "    plot_bgcolor = 'rgba(0,0,0,0)',\n",
        "    font = dict(size = 16, color = 'black'),\n",
        "    width = 900,\n",
        "    height = 500\n",
        ")\n",
        "fig.update_xaxes(title = 'Time steps', showgrid=True, gridwidth=1.5, gridcolor='#DFDFDF', showline=True, linecolor = '#AFAFAF', linewidth = 2.5, nticks = 7)\n",
        "fig.update_yaxes(showgrid=True, gridwidth=1.5,gridcolor='#DFDFDF', showline=True, linecolor = '#AFAFAF', linewidth = 2.5, nticks = 7)\n",
        "fig.show()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"ad7e1001-f092-4b39-afea-d78bf529a6fe\" class=\"plotly-graph-div\" style=\"height:500px; width:900px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"ad7e1001-f092-4b39-afea-d78bf529a6fe\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'ad7e1001-f092-4b39-afea-d78bf529a6fe',\n",
              "                        [{\"line\": {\"color\": \"rgb(228,26,28)\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"Double Deep Q Networks\", \"type\": \"scatter\", \"x\": [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000, 21000, 22000, 23000, 24000, 25000, 26000, 27000, 28000, 29000, 30000, 31000, 32000, 33000, 34000, 35000, 36000, 37000, 38000, 39000, 40000, 41000, 42000, 43000, 44000, 45000, 46000, 47000, 48000, 49000, 50000, 51000, 52000, 53000, 54000, 55000, 56000, 57000, 58000, 59000, 60000, 61000, 62000, 63000, 64000, 65000, 66000, 67000, 68000, 69000, 70000, 71000, 72000, 73000, 74000, 75000, 76000, 77000, 78000, 79000, 80000, 81000, 82000, 83000, 84000, 85000, 86000, 87000, 88000, 89000, 90000, 91000, 92000, 93000, 94000, 95000, 96000, 97000, 98000, 99000, 100000, 101000, 102000, 103000, 104000, 105000, 106000, 107000, 108000, 109000, 110000, 111000, 112000, 113000, 114000, 115000, 116000, 117000, 118000, 119000, 120000, 121000, 122000, 123000, 124000, 125000, 126000, 127000, 128000, 129000, 130000, 131000, 132000, 133000], \"y\": [0.27854819324883545, 0.2855784504821426, 0.2995843120983669, 0.2965484123404433, 0.3022476824430319, 0.3176903910934925, 0.28683877039340233, 0.30097003254023463, 0.29578544444112637, 0.2765325958530108, 1.0809107578936077, 4.212015741521662, 4.993004068084385, 6.320441722869873, 13.707663536071777, 20.735286546790082, 27.18294405937195, 22.540376579060275, 37.70719698642163, 54.079734802246094, 44.101457595825195, 45.66331227620443, 52.938941955566406, 57.11847482408796, 51.56007412501744, 78.25212097167969, 71.05243214198521, 79.3710480892297, 104.14846838088263, 107.33386666434151, 101.84902157990828, 102.43305696759906, 135.27166652679443, 137.25644841687432, 127.30043029785156, 141.56828578313193, 140.45140250069755, 153.16319274902344, 155.03589477539063, 158.34704875946045, 150.12021682286027, 182.5030029296875, 201.36768188476563, 182.8551025390625, 179.1345849609375, 195.7509645948223, 191.01452323717947, 209.84555995210687, 209.78880615234374, 218.88981379294881, 218.5815258026123, 217.55627986363, 233.28785400390626, 247.48826060575598, 226.52531641179866, 216.67549670582088, 223.1655562551398, 230.724973042806, 267.88440997783954, 246.7957449386369, 259.63134765625, 262.1448330349392, 264.92724874745244, 254.44974361952916, 261.3573059854628, 263.36220925071024, 254.34301685151598, 271.802470157021, 305.99071502685547, 308.97442626953125, 300.36008580525714, 294.34362056337557, 278.7378194173177, 296.40771484375, 320.61687651134673, 308.7844514113206, 309.86903381347656, 309.0104747099035, 313.0566351218302, 338.20706431070965, 321.9813678448017, 302.1371765136719, 317.4611239963108, 331.82860989040796, 331.101126437717, 332.3657679966518, 361.89349365234375, 342.94356496710526, 353.01627672438656, 378.38494873046875, 339.9769937020761, 344.0986110142299, 357.8503688267299, 349.51854051862443, 351.2192290683962, 387.7617645263672, 358.91655504381333, 363.3512976510184, 375.41932000054254, 385.7881371634347, 384.3017256303267, 390.4973602294922, 406.65474676316785, 403.5865427652995, 404.4120381673177, 418.5162921085536, 384.3020314534505, 431.736855061849, 407.48928974950036, 385.79959685226964, 404.15666464709363, 386.97053293081433, 392.4715774890988, 414.7502927426939, 404.6163258428159, 421.3991465627411, 411.3270511627197, 434.3102827805739, 430.0107879638672, 435.82798549107144, 444.3755187988281, 427.5907287597656, 448.38917541503906, 450.7340037027995, 433.55912465062636, 442.1085453033447, 458.7200976285067, 448.6228088378906, 462.05792662154795, 489.6854553222656, 453.07042177261843, 451.7932782854353, 479.18334242876836, 482.76542599100463]}, {\"line\": {\"width\": 0}, \"marker\": {\"color\": \"#444\"}, \"mode\": \"lines\", \"name\": \"Upper Bound\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000, 21000, 22000, 23000, 24000, 25000, 26000, 27000, 28000, 29000, 30000, 31000, 32000, 33000, 34000, 35000, 36000, 37000, 38000, 39000, 40000, 41000, 42000, 43000, 44000, 45000, 46000, 47000, 48000, 49000, 50000, 51000, 52000, 53000, 54000, 55000, 56000, 57000, 58000, 59000, 60000, 61000, 62000, 63000, 64000, 65000, 66000, 67000, 68000, 69000, 70000, 71000, 72000, 73000, 74000, 75000, 76000, 77000, 78000, 79000, 80000, 81000, 82000, 83000, 84000, 85000, 86000, 87000, 88000, 89000, 90000, 91000, 92000, 93000, 94000, 95000, 96000, 97000, 98000, 99000, 100000, 101000, 102000, 103000, 104000, 105000, 106000, 107000, 108000, 109000, 110000, 111000, 112000, 113000, 114000, 115000, 116000, 117000, 118000, 119000, 120000, 121000, 122000, 123000, 124000, 125000, 126000, 127000, 128000, 129000, 130000, 131000, 132000, 133000], \"y\": [0.3611130780946246, 0.36095774927465657, 0.36440935568347266, 0.36596106784596594, 0.36018134142173497, 0.3983900742092992, 0.33024075574383194, 0.3558353487450283, 0.3663970991605346, 0.3380137516086229, 1.3550096724077454, 5.481870976054269, 5.981652311734154, 6.320441722869873, 13.707663536071777, 25.39786354968635, 34.23421992689664, 27.0923793110809, 45.67033638477608, 55.02191162109375, 47.808159691758924, 50.43309065990763, 52.938941955566406, 62.860231574510784, 56.43606076379503, 82.94418293687886, 75.69844018405647, 86.0301418023257, 113.42674323990502, 113.64594298259344, 109.50684873641694, 108.97438336618183, 141.41938357889464, 147.6237714982023, 131.402005011744, 155.77308265493164, 147.6397859234624, 158.02259466106892, 159.69165349181688, 166.69203970167842, 168.1565015564173, 195.27037777541545, 209.60758770255575, 184.61338728534852, 185.92759533962982, 208.4684924552536, 199.76824296214312, 219.82106606004984, 216.3944963178784, 233.2616756502417, 223.3557700218712, 226.33740369052984, 247.9802359242651, 255.73659453912242, 232.0638733378501, 229.7956575597935, 231.3832912618473, 236.38678950192798, 277.87355913850126, 262.7843636256085, 262.97957467813, 265.7591759750453, 272.3845161926578, 262.96545119082504, 276.3215917367554, 275.96264465756013, 264.2318736625728, 280.0182884109484, 310.1983085266396, 316.5968084476452, 306.7153606392018, 309.88041447203983, 288.85532316850936, 302.2958658677594, 327.70579189785553, 322.2261181080319, 313.2604052439203, 315.56083738625716, 320.4705931905683, 345.32151693511196, 327.66153135974463, 302.1371765136719, 321.94493638549625, 337.5938506262624, 345.6191788769121, 340.95243982077716, 362.8326110839844, 348.31913306811896, 367.9597313520715, 385.56102458325404, 346.6543372360643, 349.75635546796116, 368.699508092015, 363.9893456814367, 363.06897633444845, 391.3383036415159, 365.7576122641627, 370.4607593673178, 388.7473590230696, 398.5774698024438, 391.6906011308817, 393.7279357910156, 416.1961916692668, 411.6907104471565, 406.5188800065881, 431.7534749433891, 397.0042122944851, 443.3966051722724, 422.29632737715525, 395.35772438276496, 416.48727145398243, 395.8149848035583, 401.96458650401024, 424.66106976726917, 415.74658164850024, 435.04148500888977, 418.27943413670374, 446.94831504130684, 437.71776934979835, 441.34735299015074, 452.53798953234514, 434.79140625596176, 459.9610540479958, 454.6297639988642, 451.27341166061285, 451.62962271817884, 470.7586357087479, 452.89906085314635, 473.5580646996729, 489.6854553222656, 461.81142429647593, 456.1494359666988, 491.72440820761994, 497.94998990423454]}, {\"fill\": \"tonexty\", \"fillcolor\": \"rgba(68, 68, 68, 0.3)\", \"line\": {\"width\": 0}, \"marker\": {\"color\": \"#444\"}, \"mode\": \"lines\", \"name\": \"Lower Bound\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000, 21000, 22000, 23000, 24000, 25000, 26000, 27000, 28000, 29000, 30000, 31000, 32000, 33000, 34000, 35000, 36000, 37000, 38000, 39000, 40000, 41000, 42000, 43000, 44000, 45000, 46000, 47000, 48000, 49000, 50000, 51000, 52000, 53000, 54000, 55000, 56000, 57000, 58000, 59000, 60000, 61000, 62000, 63000, 64000, 65000, 66000, 67000, 68000, 69000, 70000, 71000, 72000, 73000, 74000, 75000, 76000, 77000, 78000, 79000, 80000, 81000, 82000, 83000, 84000, 85000, 86000, 87000, 88000, 89000, 90000, 91000, 92000, 93000, 94000, 95000, 96000, 97000, 98000, 99000, 100000, 101000, 102000, 103000, 104000, 105000, 106000, 107000, 108000, 109000, 110000, 111000, 112000, 113000, 114000, 115000, 116000, 117000, 118000, 119000, 120000, 121000, 122000, 123000, 124000, 125000, 126000, 127000, 128000, 129000, 130000, 131000, 132000, 133000], \"y\": [0.19598330840304629, 0.2101991516896286, 0.23475926851326115, 0.2271357568349207, 0.24431402346432884, 0.2369907079776858, 0.24343678504297273, 0.24610471633544098, 0.22517378972171814, 0.21505144009739874, 0.8068118433794699, 2.942160506989054, 4.004355824434617, 6.320441722869873, 13.707663536071777, 16.072709543893815, 20.131668191847254, 17.98837384703965, 29.744057588067182, 53.13755798339844, 40.39475549989147, 40.89353389250123, 52.938941955566406, 51.37671807366514, 46.68408748623985, 73.56005900648051, 66.40642409991395, 72.7119543761337, 94.87019352186024, 101.02179034608959, 94.19119442339962, 95.89173056901629, 129.12394947469423, 126.88912533554634, 123.19885558395913, 127.36348891133221, 133.2630190779327, 148.30379083697795, 150.38013605896438, 150.00205781724247, 132.08393208930323, 169.73562808395957, 193.1277760669755, 181.09681779277648, 172.3415745822452, 183.03343673439102, 182.26080351221583, 199.8700538441639, 203.18311598680907, 204.51795193565593, 213.80728158335342, 208.77515603673018, 218.59547208354743, 239.23992667238954, 220.9867594857472, 203.55533585184824, 214.9478212484323, 225.06315658368402, 257.8952608171778, 230.80712625166532, 256.28312063437, 258.5304900948331, 257.46998130224705, 245.93403604823325, 246.39302023417017, 250.7617738438603, 244.4541600404592, 263.5866519030936, 301.78312152707133, 301.3520440914173, 294.0048109713125, 278.8068266547113, 268.6203156661261, 290.5195638197406, 313.52796112483793, 295.3427847146093, 306.47766238303285, 302.4601120335499, 305.6426770530921, 331.09261168630735, 316.30120432985876, 302.1371765136719, 312.97731160712533, 326.0633691545535, 316.58307399852197, 323.77909617252647, 360.9543762207031, 337.56799686609156, 338.0728220967016, 371.20887287768346, 333.29965016808785, 338.44086656049865, 347.0012295614448, 335.04773535581216, 339.36948180234396, 384.1852254112185, 352.075497823464, 356.241835934719, 362.0912809780155, 372.9988045244257, 376.9128501297717, 387.26678466796875, 397.1133018570689, 395.4823750834425, 402.30519632804726, 405.2791092737181, 371.59985061241593, 420.07710495142555, 392.68225212184547, 376.24146932177433, 391.82605784020484, 378.1260810580704, 382.9785684741874, 404.8395157181186, 393.4860700371316, 407.7568081165925, 404.3746681887357, 421.672250519841, 422.30380657793603, 430.30861799199215, 436.2130480653111, 420.3900512635695, 436.81729678208234, 446.8382434067348, 415.84483764063987, 432.5874678885106, 446.68155954826557, 444.34655682263485, 450.557788543423, 489.6854553222656, 444.3294192487609, 447.4371206041718, 466.64227664991677, 467.5808620777747]}, {\"line\": {\"color\": \"rgb(55,126,184)\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"Deep Q Networks\", \"type\": \"scatter\", \"x\": [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000, 21000, 22000, 23000, 24000, 25000, 26000, 27000, 28000, 29000, 30000, 31000, 32000, 33000, 34000, 35000, 36000, 37000, 38000, 39000, 40000, 41000, 42000, 43000, 44000, 45000, 46000, 47000, 48000, 49000, 50000, 51000, 52000, 53000, 54000, 55000, 56000, 57000, 58000, 59000, 60000, 61000, 62000, 63000, 64000, 65000, 66000, 67000, 68000, 69000, 70000, 71000, 72000, 73000, 74000, 75000, 76000, 77000, 78000, 79000, 80000, 81000, 82000, 83000, 84000, 85000, 86000, 87000, 88000, 89000, 90000, 91000, 92000, 93000, 94000, 95000, 96000, 97000, 98000, 99000, 100000, 101000, 102000, 103000, 104000, 105000, 106000, 107000, 108000, 109000, 110000, 111000, 112000, 113000, 114000, 115000, 116000, 117000, 118000, 119000, 120000, 121000, 122000, 123000, 124000, 125000, 126000, 127000, 128000, 129000, 130000, 131000], \"y\": [0.4469165802001953, 0.4616326854300143, 0.4814189965354985, 0.4661732369235584, 0.49623406016164356, 0.49133723189956263, 0.445674292743206, 0.4407048324743907, 0.4385860366953744, 0.5074087580045065, 1.483333945274353, 2.1248617649078367, 3.574233961105347, 5.22815302213033, 8.883125305175781, 10.251750185682967, 12.588460805464765, 20.52444663414588, 23.761208182887028, 24.282511901855468, 37.386253356933594, 38.67532825469971, 41.88459289073944, 45.54210361681486, 58.4052393253033, 67.06952073838976, 71.22240774972099, 76.58644561767578, 78.69422884340639, 85.70589403836232, 88.2258516584124, 106.59196685791015, 112.02353913443429, 119.0930658976237, 113.95101165771484, 127.38185272216796, 154.24955701828003, 132.55511951446533, 145.65219394977277, 139.84954662537308, 186.49723205566406, 163.7817084270975, 205.66754404703775, 176.28003258798637, 195.5376796722412, 196.33185707254611, 193.85770840115018, 202.4662628173828, 216.6211395263672, 219.65583292643228, 251.73755340576173, 218.47796187862272, 236.44204376220702, 239.48841857910156, 238.54971504211426, 242.42153181109512, 274.0642895968455, 282.3550994873047, 256.64603097098217, 297.84600219726565, 284.95490199497766, 318.9070351340554, 326.34629516601564, 295.47145263671877, 333.05433772160455, 322.0625356038411, 327.4541778564453, 319.21803009815704, 330.7774421938004, 368.1193411690848, 345.887548828125, 349.1873380220853, 341.85948852539065, 352.04240223277696, 367.20972131799766, 390.4433242134426, 373.8193112327939, 411.04701450892856, 391.1009553421375, 375.76744486490884, 421.6489741884429, 391.9058967003456, 410.5965936834162, 398.4928274154663, 435.76668051014775, 432.1199965043501, 439.2251667879066, 424.10519683495, 446.09849548339844, 472.32088385687933, 443.75289769326486, 451.6283941501524, 454.8540217081706, 461.5449807810229, 465.752449281754, 452.9308149549696, 471.59528302131815, 479.8546511332194, 493.15993626912433, 490.7106943766276, 496.9461502075195, 502.3914313065378, 507.8617955258018, 532.2098943536931, 512.6271993702856, 506.38107347488403, 523.2712364196777, 536.7184899371604, 534.1180804217303, 540.1450641338641, 527.7343377506031, 528.1235540981951, 526.2717168280419, 559.1577085297683, 588.1121215820312, 562.0091372841283, 546.4027610311703, 564.88525390625, 569.4879268523185, 582.0515688941592, 571.2323269314236, 585.3623962402344, 579.1914469401041, 586.7235717773438, 588.4873179560122, 574.5148954845611, 579.8337170410156, 593.1989246715199, 615.5526394314236, 610.5462027884819, 617.3430678423713, 587.397175339033]}, {\"line\": {\"width\": 0}, \"marker\": {\"color\": \"#444\"}, \"mode\": \"lines\", \"name\": \"Upper Bound\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000, 21000, 22000, 23000, 24000, 25000, 26000, 27000, 28000, 29000, 30000, 31000, 32000, 33000, 34000, 35000, 36000, 37000, 38000, 39000, 40000, 41000, 42000, 43000, 44000, 45000, 46000, 47000, 48000, 49000, 50000, 51000, 52000, 53000, 54000, 55000, 56000, 57000, 58000, 59000, 60000, 61000, 62000, 63000, 64000, 65000, 66000, 67000, 68000, 69000, 70000, 71000, 72000, 73000, 74000, 75000, 76000, 77000, 78000, 79000, 80000, 81000, 82000, 83000, 84000, 85000, 86000, 87000, 88000, 89000, 90000, 91000, 92000, 93000, 94000, 95000, 96000, 97000, 98000, 99000, 100000, 101000, 102000, 103000, 104000, 105000, 106000, 107000, 108000, 109000, 110000, 111000, 112000, 113000, 114000, 115000, 116000, 117000, 118000, 119000, 120000, 121000, 122000, 123000, 124000, 125000, 126000, 127000, 128000, 129000, 130000, 131000], \"y\": [0.5479173902094587, 0.560893246918302, 0.5860303942823952, 0.537487636300907, 0.6005199393440801, 0.5894273128337393, 0.5098196993155102, 0.5256832054953167, 0.5335899450500343, 0.5840679371353588, 1.7132705450057983, 2.352318244195034, 4.174776630703791, 5.93916886379285, 9.195628571447406, 11.436921109790283, 14.108137237955956, 21.641559070776587, 26.061788914846357, 25.4841306619885, 38.21442951807725, 40.720770557207764, 44.94803515721972, 48.28044546362686, 62.54474123860099, 70.81402437336317, 74.48692816273564, 81.69646912501996, 82.13613915902893, 90.08029269553856, 92.50168763347273, 112.95348118762745, 116.04017899911285, 121.75697249598714, 117.51445651841625, 132.55514498627335, 162.141953448695, 136.10171517605193, 153.69095760991698, 149.90464015192074, 194.90006122982857, 170.62898049120662, 208.64705808152877, 183.82101286521444, 210.485369607716, 211.19100725508326, 199.7438401604264, 202.4662628173828, 222.74302856872933, 224.05802995747874, 253.94615736589836, 226.5315266134274, 242.00364509487383, 242.73663008983047, 244.3337148278042, 248.40555404740383, 281.8404740703876, 288.7046766742059, 264.12914678218874, 306.9594267032162, 291.26702100479275, 325.14902455827064, 329.8567111727327, 309.2927275167734, 342.96723044564345, 329.63499864898114, 331.3746594655998, 325.7226015793622, 335.6980686800627, 370.63590395402116, 350.7048575027471, 359.49469629787177, 348.48541179938604, 361.512254557513, 374.9608586559675, 404.72526964508154, 381.8263130295911, 414.1619887373567, 403.5200838270183, 383.77741700828574, 435.29033553422977, 400.05350293443706, 417.11594042444483, 411.8218880822862, 448.57506592280737, 436.1004258225473, 448.0554148605958, 433.7586402230399, 454.95422815906477, 480.1623863228013, 453.3450150487187, 466.4773224280187, 461.3186207562258, 467.6045780593772, 476.36398993987905, 462.80386665045796, 482.3909794900628, 492.1802713741741, 504.89030130299625, 502.686359893355, 507.5948110329473, 510.9697031465551, 521.5644882513076, 538.5260013651338, 524.9896381843333, 515.9877843987849, 539.106115724784, 550.6952775499557, 546.7061545629134, 553.7922059995892, 537.4018944002514, 534.3531489049533, 535.5662726213989, 571.1855237555204, 588.1121215820312, 572.0528941890135, 554.99852205762, 566.6475830078125, 578.6051031227539, 590.0031529486033, 582.998800812407, 587.6229858398438, 587.086426637668, 602.3346270779347, 603.1674680046335, 586.0555150841385, 592.6289012729234, 605.4798338980295, 622.3124824224913, 624.4954901017978, 634.1367362102851, 601.2483504957361]}, {\"fill\": \"tonexty\", \"fillcolor\": \"rgba(68, 68, 68, 0.3)\", \"line\": {\"width\": 0}, \"marker\": {\"color\": \"#444\"}, \"mode\": \"lines\", \"name\": \"Lower Bound\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000, 21000, 22000, 23000, 24000, 25000, 26000, 27000, 28000, 29000, 30000, 31000, 32000, 33000, 34000, 35000, 36000, 37000, 38000, 39000, 40000, 41000, 42000, 43000, 44000, 45000, 46000, 47000, 48000, 49000, 50000, 51000, 52000, 53000, 54000, 55000, 56000, 57000, 58000, 59000, 60000, 61000, 62000, 63000, 64000, 65000, 66000, 67000, 68000, 69000, 70000, 71000, 72000, 73000, 74000, 75000, 76000, 77000, 78000, 79000, 80000, 81000, 82000, 83000, 84000, 85000, 86000, 87000, 88000, 89000, 90000, 91000, 92000, 93000, 94000, 95000, 96000, 97000, 98000, 99000, 100000, 101000, 102000, 103000, 104000, 105000, 106000, 107000, 108000, 109000, 110000, 111000, 112000, 113000, 114000, 115000, 116000, 117000, 118000, 119000, 120000, 121000, 122000, 123000, 124000, 125000, 126000, 127000, 128000, 129000, 130000, 131000], \"y\": [0.3459157701909319, 0.3623721239417266, 0.37680759878860187, 0.39485883754620976, 0.39194818097920703, 0.393247150965386, 0.38152888617090186, 0.3557264594534647, 0.34358212834071444, 0.43074957887365417, 1.2533973455429077, 1.8974052856206396, 2.9736912915069027, 4.51713718046781, 8.570622038904157, 9.06657926157565, 11.068784372973573, 19.407334197515176, 21.4606274509277, 23.080893141722434, 36.558077195789934, 36.62988595219165, 38.82115062425916, 42.803761770002865, 54.265737412005606, 63.325017103416336, 67.95788733670634, 71.4764221103316, 75.25231852778386, 81.33149538118607, 83.95001568335206, 100.23045252819286, 108.00689926975572, 116.42915929926026, 110.38756679701343, 122.20856045806259, 146.35716058786505, 129.00852385287874, 137.61343028962855, 129.79445309882541, 178.09440288149955, 156.93443636298838, 202.68803001254673, 168.7390523107583, 180.58998973676643, 181.47270689000896, 187.97157664187395, 202.4662628173828, 210.49925048400505, 215.25363589538583, 249.5289494456251, 210.42439714381806, 230.8804424295402, 236.24020706837265, 232.76571525642433, 236.43750957478642, 266.28810512330347, 276.00552230040347, 249.16291515977562, 288.7325776913151, 278.64278298516257, 312.6650457098401, 322.8358791592986, 281.6501777566641, 323.14144499756566, 314.4900725587011, 323.53369624729083, 312.71345861695187, 325.85681570753815, 365.60277838414845, 341.0702401535029, 338.8799797462989, 335.23356525139525, 342.5725499080409, 359.4585839800278, 376.1613787818037, 365.81230943599667, 407.9320402805004, 378.68182685725674, 367.75747272153194, 408.007612842656, 383.7582904662541, 404.07724694238755, 385.1637667486464, 422.95829509748813, 428.13956718615293, 430.39491871521733, 414.4517534468601, 437.2427628077321, 464.47938139095737, 434.160780337811, 436.77946587228615, 448.3894226601154, 455.4853835026686, 455.140908623629, 443.05776325948125, 460.7995865525735, 467.52903089226476, 481.4295712352524, 478.7350288599002, 486.2974893820917, 493.8131594665205, 494.1591028002961, 525.8937873422525, 500.2647605562377, 496.7743625509832, 507.4363571145715, 522.7417023243651, 521.5300062805471, 526.4979222681391, 518.0667811009548, 521.8939592914369, 516.977161034685, 547.1298933040163, 588.1121215820312, 551.9653803792431, 537.8070000047205, 563.1229248046875, 560.3707505818832, 574.0999848397151, 559.4658530504402, 583.101806640625, 571.2964672425403, 571.1125164767528, 573.807167907391, 562.9742758849836, 567.0385328091078, 580.9180154450103, 608.7927964403559, 596.5969154751659, 600.5493994744575, 573.5460001823299]}],\n",
              "                        {\"font\": {\"color\": \"black\", \"size\": 16}, \"height\": 500, \"hovermode\": \"x\", \"paper_bgcolor\": \"rgba(0,0,0,0)\", \"plot_bgcolor\": \"rgba(0,0,0,0)\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Estimation Bias in Deep Q networks\"}, \"width\": 900, \"xaxis\": {\"gridcolor\": \"#DFDFDF\", \"gridwidth\": 1.5, \"linecolor\": \"#AFAFAF\", \"linewidth\": 2.5, \"nticks\": 7, \"showgrid\": true, \"showline\": true, \"title\": {\"text\": \"Time steps\"}}, \"yaxis\": {\"gridcolor\": \"#DFDFDF\", \"gridwidth\": 1.5, \"linecolor\": \"#AFAFAF\", \"linewidth\": 2.5, \"nticks\": 7, \"showgrid\": true, \"showline\": true, \"title\": {\"text\": \"Avg. Value Estimate (greedy policy)\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ad7e1001-f092-4b39-afea-d78bf529a6fe');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To1WGMUfTbmZ"
      },
      "source": [
        "avg_result_DDQN = np.mean(np.array(result_DDQN).reshape(-1, 10), axis=1)\n",
        "avg_result_DQN = np.mean(np.array(result_DQN).reshape(-1, 10), axis=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "8bKG4eDVh3Bl",
        "outputId": "f7fc5bdc-c976-4821-ebad-562bdf4543a1"
      },
      "source": [
        "import colorlover as cl\n",
        "import plotly.graph_objects as go\n",
        "colors = cl.scales['5']['qual']['Set1']\n",
        "\n",
        "fig = go.Figure([\n",
        "    go.Scatter(\n",
        "        name='Double Deep Q Networks',\n",
        "        x=np.arange(len(avg_result_DDQN)),\n",
        "        y=avg_result_DDQN,\n",
        "        mode='lines',\n",
        "        line=dict(color=colors[0], width = 2),\n",
        "    ),\n",
        "        go.Scatter(\n",
        "        name='Deep Q Networks',\n",
        "        x=np.arange(len(avg_result_DQN)),\n",
        "        y=avg_result_DQN,\n",
        "        mode='lines',\n",
        "        line=dict(color=colors[1], width = 2),\n",
        "    ),\n",
        "])\n",
        "\n",
        "fig.update_layout(\n",
        "    yaxis_title='Avg. Rewards per episode',\n",
        "    title='Reward accumulation profile',\n",
        "    hovermode=\"x\",\n",
        "    paper_bgcolor = 'rgba(0,0,0,0)',\n",
        "    plot_bgcolor = 'rgba(0,0,0,0)',\n",
        "    font = dict(size = 16, color = 'black'),\n",
        "    width = 900,\n",
        "    height = 500\n",
        ")\n",
        "fig.update_xaxes(title = 'Sets (10 episodes in each set)', showgrid=True, gridwidth=1.5, gridcolor='#DFDFDF', showline=True, linecolor = '#AFAFAF', linewidth = 2.5, nticks = 7)\n",
        "fig.update_yaxes(showgrid=True, gridwidth=1.5,gridcolor='#DFDFDF', showline=True, linecolor = '#AFAFAF', linewidth = 2.5, nticks = 7)\n",
        "fig.show()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"0f8908ab-6bf4-41aa-82a7-d6613f491d93\" class=\"plotly-graph-div\" style=\"height:500px; width:900px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"0f8908ab-6bf4-41aa-82a7-d6613f491d93\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '0f8908ab-6bf4-41aa-82a7-d6613f491d93',\n",
              "                        [{\"line\": {\"color\": \"rgb(228,26,28)\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"Double Deep Q Networks\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"y\": [1.6327701097580998, 1.7764296702492341, 1.3888686143809297, 1.9209893238324416, 1.433918835811612, 1.3783200137068536, 1.4604873851944227, 1.4183004619572428, 2.1944454635192097, 1.3047713866663826, 1.7595453869130584, 1.444396181852144, 1.31160144376972, 1.1932995376043825, 1.6030985076128714, 1.572994480445685, 1.153154994923332, 1.5167603963058625, 1.7923218778403496, 1.854511492237899, 1.7845210907842108, 1.7113784025896397, 1.938062002746335, 1.3148291209034302, 1.3863759647619918, 1.4861052362448135, 1.4558732514657735, 1.8755603479523635, 1.5407830731568422, 1.4076818207107131, 1.29870676127558, 1.5554879376534196, 1.6119218892670886, 1.9702857378586682, 2.1611584846885346, 1.2551368964148213, 1.5232009641173878, 1.302947802971893, 1.4533157937931411, 1.39267030422478, 1.908585306792657, 1.5442854769007026, 1.4306302223052048, 2.588757544596381, 1.5341066483852983, 1.5404826022789013, 1.2246359789421561, 1.5861124574685985, 1.6011928345872917, 1.6004754062174686, 2.328410564563484, 2.1056627691389105, 2.0213712910404977, 1.5463871612822715, 1.5719452955996327, 1.4809151497780413, 2.123554789237946, 1.4946403911466255, 3.208057006667714, 1.9408704489815218, 1.440381065517082, 1.4200581542588218, 1.3199763677052105, 1.518314951861936, 1.6935751184991066, 1.3484734853282285, 1.9426394595365282, 1.7904462870262812, 1.4657717359104963, 1.3747162671782984, 1.5614288650669519, 1.4869516915178909, 1.2979527390660877, 1.4220652585163103, 1.6471352204685281, 1.9348025525744177, 1.4227598232554457, 1.5486630883224444, 2.948844402517594, 1.7049719836423833, 1.5453143695975646, 1.380652813919474, 1.5360299200815146, 1.3161154316975008, 1.5866163699190003, 1.4225899712156775, 1.3287825846511805, 1.5577439027394901, 1.3695301226551226, 1.5547782267610342, 1.537590417054297, 1.6011289849689487, 1.521468727227537, 1.801093607434121, 1.2694810370687428, 2.1784098475274947, 1.546527402972989, 1.3465770114259688, 1.5378963612451693, 1.5837482221243195, 1.359387857671158, 1.3392596083520516, 2.4633661342661965, 1.6466609419877352, 2.5914982677371774, 1.8375931522656668, 1.9362781864640461, 1.3539535287832511, 1.2832667512925031, 1.7770164373374946, 1.449700185404383, 1.8164907045456133, 2.1118268879313873, 1.4484736334126458, 1.4625668513604226, 1.6703324336241567, 2.9609427113797926, 1.666520676149256, 1.668219658389885, 1.6359698329228434, 1.647196296667552, 1.623274666130455, 1.6685504249590095, 1.7766403136145772, 1.9529163037106656, 1.5614660007425702, 1.778467025766329, 1.4696508724555095, 1.6662799786205666, 2.39477836461143, 1.5299203305484963, 2.061565183322973, 1.8956217796603299, 1.4379233599363783, 1.4360810570101836, 1.4359075495402984, 1.6483430671323471, 1.4890105758243233, 1.4734277243509104, 2.051133185386818, 1.5372812666124127, 1.6082452998387555, 1.608602952209008, 1.8686871362118105, 1.7573804813177625, 1.2611734511856103, 1.693689344729864, 1.6657372022707377, 1.839588619240213, 1.5491899639749134, 1.714452632743464, 1.932416648566561, 1.7330796282742007, 1.5068919412683424, 1.5611582854371417, 1.5635837318049564, 1.9782083270388768, 1.2062126203384549, 1.9730249670621824, 2.138218778393632, 2.0478088928756186, 1.4425457576902216, 1.9575406055198836, 1.9900381897328725, 1.6331186475855262, 1.8990764200573071, 1.972956707533013, 1.2954658429196604, 1.5267068801888812, 1.9232146699264319, 1.2617997082284258, 1.6863069805108588, 1.8048542530666587, 1.9414285013291797, 1.6146706247618166, 1.2594654888326686, 1.6388210752604864, 1.4988351989410797, 1.5759005544391234, 1.4705736927699085, 3.062249780817984, 2.047953775880708, 1.5930162391489788, 1.533795611903544, 1.3093403789299043, 1.7543673303107798, 2.334330325119798, 1.6002962339119626, 1.6990203080624293, 1.7967472215747957, 1.8336316964335784, 1.752575386974197, 1.702749354461205, 2.101108089090711, 1.5481076574903818, 1.80926274083836, 2.116551607942916, 2.1524814576574007, 1.8273055408657015, 1.7921253963345625]}, {\"line\": {\"color\": \"rgb(55,126,184)\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"Deep Q Networks\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"y\": [1.6068361490652248, 1.925283840872852, 1.4966384767657268, 1.0850025790317637, 1.4876489797048296, 1.9340799231723025, 1.597745082450444, 1.4191907227784668, 1.5325733192383582, 1.7078024715011015, 1.627092952671901, 2.2215212130074393, 1.5588963380348166, 1.7693280501281343, 1.2672219207429634, 1.8241910166433501, 2.3330338639907433, 1.4886742439493497, 1.5828559649564535, 1.6998075746722912, 1.255195090904905, 1.5766130330006454, 1.3363873983794885, 1.179732693353531, 1.4469511963694353, 1.7175502918300716, 3.0245492666603004, 1.5461999242876177, 1.997239492796447, 1.1326198368476195, 1.3693768286780779, 1.7565873015873017, 1.4235400922445387, 1.9201101321402079, 1.282152892235059, 1.4040738546399174, 2.337901744088767, 1.8467850644934525, 3.055846277254716, 1.661178288821634, 1.5067186937945976, 1.395216351087551, 1.8369737038042733, 1.8276135902947668, 1.3506548924025616, 1.4198758660640023, 1.7859573542119827, 1.749290448267147, 1.7846228139030464, 2.065631584235738, 1.5065924500400059, 1.4838003796054906, 1.722609105583399, 1.2697249129433008, 1.2823718958996895, 1.6351304745650548, 2.0725394418607896, 1.7741140004995988, 1.6309744512299045, 1.569345104591358, 1.215909561512984, 2.7288501811536117, 1.2308956603435388, 1.4100826228068866, 1.759524318013351, 1.339538170563607, 1.8113440745715663, 1.8594480888042106, 1.4270567112005073, 1.5540059661099566, 2.1741157324061193, 1.3830048490603246, 1.890503309597846, 1.5550735470361712, 1.9743898835854048, 1.2688610518363792, 2.092425928267637, 1.6012474460288053, 1.4260921172623502, 1.754150931848915, 1.6255813959497796, 1.7179398103714085, 1.8089883738333197, 1.8000505521731938, 1.5657480321211568, 1.6676608157711026, 1.1587913693417244, 1.4343248388176835, 1.330110121954643, 1.7677394722008315, 1.9372589614922546, 1.7399528625474083, 1.8959259009486455, 1.4193618660789777, 2.0482713818789735, 1.5286758983847204, 1.4771775905452227, 2.160485980762683, 1.4169298858269799, 1.7412439045163453, 1.7696086732983694, 1.4710850617319162, 1.4907893359457887, 1.5392135450025788, 1.567081139741689, 1.420235579267843, 2.700722895871163, 1.677583329321445, 1.9802812661961025, 1.5871878055338988, 1.400855497375095, 1.4956728634232976, 1.7482265622997164, 1.3036472806189112, 2.729948339770539, 1.6969417922165952, 2.4514926624039517, 1.1581186002917652, 2.044086865705658, 1.7662361784521643, 1.447169360325131, 1.6074777286240085, 1.6034785012620731, 1.5391283581476418, 1.7203462250155515, 2.2723445188305362, 2.046560062298492, 1.6026186423494828, 1.6783067272371497, 1.5195329988311312, 1.511803467292052, 1.7853624529203067, 1.3412458981963218, 1.6133281342634405, 1.6821410515568833, 1.8674263258565584, 1.3952239533001785, 1.8779669673142152, 1.5639163346212075, 1.923546018658915, 1.7195290190563406, 1.2927833569963827, 1.7989082403430625, 1.6997811234495308, 1.5055390977270986, 1.731417715117939, 1.5979498968045998, 1.7379320710617745, 1.830401400756274, 1.6218929280253787, 1.4908517116445883, 1.6721698202507072, 1.694642462707566, 1.6892806105841853, 1.6249167659980177, 1.6700950814700697, 1.9735169822804721, 1.7103568136006846, 1.8048032253232287, 1.879420737549511, 1.4872556552846998, 2.4823300902764047, 1.5961000794394051, 1.5049177164389582, 2.0371735001462747, 1.5680769939273644, 1.4630514467120996, 1.353494086737567, 1.7295048193642741, 1.9433308264100844, 2.232495283676016, 1.500492769409011, 2.0095468107066727, 1.8205994802172178, 1.7136386594356565, 1.8616263160945088, 1.9572477289424584, 1.8251431175425725, 1.5361040100856946, 1.957934044078545, 1.3402815762266655, 1.6426845226255167, 1.999557359973497, 1.4263905362962717, 1.9776999060421736, 1.9486070821725838, 2.0135475120140582, 1.9354698921362747, 2.090985253648297, 1.4357665515901337, 2.3272846245993604, 1.8526161998902313, 1.8059751826721908, 1.823491972301822, 1.7640655453999272, 2.081596156463378, 1.90457412865782, 1.7894193335442519, 1.8635681254559575, 1.7266243480430792]}],\n",
              "                        {\"font\": {\"color\": \"black\", \"size\": 16}, \"height\": 500, \"hovermode\": \"x\", \"paper_bgcolor\": \"rgba(0,0,0,0)\", \"plot_bgcolor\": \"rgba(0,0,0,0)\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Reward accumulation profile\"}, \"width\": 900, \"xaxis\": {\"gridcolor\": \"#DFDFDF\", \"gridwidth\": 1.5, \"linecolor\": \"#AFAFAF\", \"linewidth\": 2.5, \"nticks\": 7, \"showgrid\": true, \"showline\": true, \"title\": {\"text\": \"Sets (10 episodes in each set)\"}}, \"yaxis\": {\"gridcolor\": \"#DFDFDF\", \"gridwidth\": 1.5, \"linecolor\": \"#AFAFAF\", \"linewidth\": 2.5, \"nticks\": 7, \"showgrid\": true, \"showline\": true, \"title\": {\"text\": \"Avg. Rewards per episode\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0f8908ab-6bf4-41aa-82a7-d6613f491d93');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he05cAg4jXus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7d55bf0-72f8-4ebb-9e6d-c0f2acddf77e"
      },
      "source": [
        "policy_net = torch.load('ddqn_pong_model')\n",
        "obs = env.reset()\n",
        "state = get_state(obs)\n",
        "for t in count():\n",
        "  action = policy_net(state.to('cuda')).max(1)[1].view(1,1)\n",
        "  obs, reward, done, info = env.step(action)\n",
        "  print(reward)\n",
        "  \n",
        "  if not done:\n",
        "    next_state = get_state(obs)\n",
        "  else:\n",
        "    next_state = None\n",
        "  state = next_state\n",
        "  if done:\n",
        "    break\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALCzuQIeVpdb",
        "outputId": "deebf3c9-1790-4eb4-85ce-cdb9d8332238"
      },
      "source": [
        "env.unwrapped.get_action_meanings()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnNz6fr3dekl",
        "outputId": "d6ce456d-e018-42f7-b088-2f340bc482bf"
      },
      "source": [
        "gym.envs.registry.all()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values([EnvSpec(Copy-v0), EnvSpec(RepeatCopy-v0), EnvSpec(ReversedAddition-v0), EnvSpec(ReversedAddition3-v0), EnvSpec(DuplicatedInput-v0), EnvSpec(Reverse-v0), EnvSpec(CartPole-v0), EnvSpec(CartPole-v1), EnvSpec(MountainCar-v0), EnvSpec(MountainCarContinuous-v0), EnvSpec(Pendulum-v0), EnvSpec(Acrobot-v1), EnvSpec(LunarLander-v2), EnvSpec(LunarLanderContinuous-v2), EnvSpec(BipedalWalker-v3), EnvSpec(BipedalWalkerHardcore-v3), EnvSpec(CarRacing-v0), EnvSpec(Blackjack-v0), EnvSpec(KellyCoinflip-v0), EnvSpec(KellyCoinflipGeneralized-v0), EnvSpec(FrozenLake-v0), EnvSpec(FrozenLake8x8-v0), EnvSpec(CliffWalking-v0), EnvSpec(NChain-v0), EnvSpec(Roulette-v0), EnvSpec(Taxi-v3), EnvSpec(GuessingGame-v0), EnvSpec(HotterColder-v0), EnvSpec(Reacher-v2), EnvSpec(Pusher-v2), EnvSpec(Thrower-v2), EnvSpec(Striker-v2), EnvSpec(InvertedPendulum-v2), EnvSpec(InvertedDoublePendulum-v2), EnvSpec(HalfCheetah-v2), EnvSpec(HalfCheetah-v3), EnvSpec(Hopper-v2), EnvSpec(Hopper-v3), EnvSpec(Swimmer-v2), EnvSpec(Swimmer-v3), EnvSpec(Walker2d-v2), EnvSpec(Walker2d-v3), EnvSpec(Ant-v2), EnvSpec(Ant-v3), EnvSpec(Humanoid-v2), EnvSpec(Humanoid-v3), EnvSpec(HumanoidStandup-v2), EnvSpec(FetchSlide-v1), EnvSpec(FetchPickAndPlace-v1), EnvSpec(FetchReach-v1), EnvSpec(FetchPush-v1), EnvSpec(HandReach-v0), EnvSpec(HandManipulateBlockRotateZ-v0), EnvSpec(HandManipulateBlockRotateZTouchSensors-v0), EnvSpec(HandManipulateBlockRotateZTouchSensors-v1), EnvSpec(HandManipulateBlockRotateParallel-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensors-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensors-v1), EnvSpec(HandManipulateBlockRotateXYZ-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensors-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensors-v1), EnvSpec(HandManipulateBlockFull-v0), EnvSpec(HandManipulateBlock-v0), EnvSpec(HandManipulateBlockTouchSensors-v0), EnvSpec(HandManipulateBlockTouchSensors-v1), EnvSpec(HandManipulateEggRotate-v0), EnvSpec(HandManipulateEggRotateTouchSensors-v0), EnvSpec(HandManipulateEggRotateTouchSensors-v1), EnvSpec(HandManipulateEggFull-v0), EnvSpec(HandManipulateEgg-v0), EnvSpec(HandManipulateEggTouchSensors-v0), EnvSpec(HandManipulateEggTouchSensors-v1), EnvSpec(HandManipulatePenRotate-v0), EnvSpec(HandManipulatePenRotateTouchSensors-v0), EnvSpec(HandManipulatePenRotateTouchSensors-v1), EnvSpec(HandManipulatePenFull-v0), EnvSpec(HandManipulatePen-v0), EnvSpec(HandManipulatePenTouchSensors-v0), EnvSpec(HandManipulatePenTouchSensors-v1), EnvSpec(FetchSlideDense-v1), EnvSpec(FetchPickAndPlaceDense-v1), EnvSpec(FetchReachDense-v1), EnvSpec(FetchPushDense-v1), EnvSpec(HandReachDense-v0), EnvSpec(HandManipulateBlockRotateZDense-v0), EnvSpec(HandManipulateBlockRotateZTouchSensorsDense-v0), EnvSpec(HandManipulateBlockRotateZTouchSensorsDense-v1), EnvSpec(HandManipulateBlockRotateParallelDense-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensorsDense-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensorsDense-v1), EnvSpec(HandManipulateBlockRotateXYZDense-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensorsDense-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensorsDense-v1), EnvSpec(HandManipulateBlockFullDense-v0), EnvSpec(HandManipulateBlockDense-v0), EnvSpec(HandManipulateBlockTouchSensorsDense-v0), EnvSpec(HandManipulateBlockTouchSensorsDense-v1), EnvSpec(HandManipulateEggRotateDense-v0), EnvSpec(HandManipulateEggRotateTouchSensorsDense-v0), EnvSpec(HandManipulateEggRotateTouchSensorsDense-v1), EnvSpec(HandManipulateEggFullDense-v0), EnvSpec(HandManipulateEggDense-v0), EnvSpec(HandManipulateEggTouchSensorsDense-v0), EnvSpec(HandManipulateEggTouchSensorsDense-v1), EnvSpec(HandManipulatePenRotateDense-v0), EnvSpec(HandManipulatePenRotateTouchSensorsDense-v0), EnvSpec(HandManipulatePenRotateTouchSensorsDense-v1), EnvSpec(HandManipulatePenFullDense-v0), EnvSpec(HandManipulatePenDense-v0), EnvSpec(HandManipulatePenTouchSensorsDense-v0), EnvSpec(HandManipulatePenTouchSensorsDense-v1), EnvSpec(Adventure-v0), EnvSpec(Adventure-v4), EnvSpec(AdventureDeterministic-v0), EnvSpec(AdventureDeterministic-v4), EnvSpec(AdventureNoFrameskip-v0), EnvSpec(AdventureNoFrameskip-v4), EnvSpec(Adventure-ram-v0), EnvSpec(Adventure-ram-v4), EnvSpec(Adventure-ramDeterministic-v0), EnvSpec(Adventure-ramDeterministic-v4), EnvSpec(Adventure-ramNoFrameskip-v0), EnvSpec(Adventure-ramNoFrameskip-v4), EnvSpec(AirRaid-v0), EnvSpec(AirRaid-v4), EnvSpec(AirRaidDeterministic-v0), EnvSpec(AirRaidDeterministic-v4), EnvSpec(AirRaidNoFrameskip-v0), EnvSpec(AirRaidNoFrameskip-v4), EnvSpec(AirRaid-ram-v0), EnvSpec(AirRaid-ram-v4), EnvSpec(AirRaid-ramDeterministic-v0), EnvSpec(AirRaid-ramDeterministic-v4), EnvSpec(AirRaid-ramNoFrameskip-v0), EnvSpec(AirRaid-ramNoFrameskip-v4), EnvSpec(Alien-v0), EnvSpec(Alien-v4), EnvSpec(AlienDeterministic-v0), EnvSpec(AlienDeterministic-v4), EnvSpec(AlienNoFrameskip-v0), EnvSpec(AlienNoFrameskip-v4), EnvSpec(Alien-ram-v0), EnvSpec(Alien-ram-v4), EnvSpec(Alien-ramDeterministic-v0), EnvSpec(Alien-ramDeterministic-v4), EnvSpec(Alien-ramNoFrameskip-v0), EnvSpec(Alien-ramNoFrameskip-v4), EnvSpec(Amidar-v0), EnvSpec(Amidar-v4), EnvSpec(AmidarDeterministic-v0), EnvSpec(AmidarDeterministic-v4), EnvSpec(AmidarNoFrameskip-v0), EnvSpec(AmidarNoFrameskip-v4), EnvSpec(Amidar-ram-v0), EnvSpec(Amidar-ram-v4), EnvSpec(Amidar-ramDeterministic-v0), EnvSpec(Amidar-ramDeterministic-v4), EnvSpec(Amidar-ramNoFrameskip-v0), EnvSpec(Amidar-ramNoFrameskip-v4), EnvSpec(Assault-v0), EnvSpec(Assault-v4), EnvSpec(AssaultDeterministic-v0), EnvSpec(AssaultDeterministic-v4), EnvSpec(AssaultNoFrameskip-v0), EnvSpec(AssaultNoFrameskip-v4), EnvSpec(Assault-ram-v0), EnvSpec(Assault-ram-v4), EnvSpec(Assault-ramDeterministic-v0), EnvSpec(Assault-ramDeterministic-v4), EnvSpec(Assault-ramNoFrameskip-v0), EnvSpec(Assault-ramNoFrameskip-v4), EnvSpec(Asterix-v0), EnvSpec(Asterix-v4), EnvSpec(AsterixDeterministic-v0), EnvSpec(AsterixDeterministic-v4), EnvSpec(AsterixNoFrameskip-v0), EnvSpec(AsterixNoFrameskip-v4), EnvSpec(Asterix-ram-v0), EnvSpec(Asterix-ram-v4), EnvSpec(Asterix-ramDeterministic-v0), EnvSpec(Asterix-ramDeterministic-v4), EnvSpec(Asterix-ramNoFrameskip-v0), EnvSpec(Asterix-ramNoFrameskip-v4), EnvSpec(Asteroids-v0), EnvSpec(Asteroids-v4), EnvSpec(AsteroidsDeterministic-v0), EnvSpec(AsteroidsDeterministic-v4), EnvSpec(AsteroidsNoFrameskip-v0), EnvSpec(AsteroidsNoFrameskip-v4), EnvSpec(Asteroids-ram-v0), EnvSpec(Asteroids-ram-v4), EnvSpec(Asteroids-ramDeterministic-v0), EnvSpec(Asteroids-ramDeterministic-v4), EnvSpec(Asteroids-ramNoFrameskip-v0), EnvSpec(Asteroids-ramNoFrameskip-v4), EnvSpec(Atlantis-v0), EnvSpec(Atlantis-v4), EnvSpec(AtlantisDeterministic-v0), EnvSpec(AtlantisDeterministic-v4), EnvSpec(AtlantisNoFrameskip-v0), EnvSpec(AtlantisNoFrameskip-v4), EnvSpec(Atlantis-ram-v0), EnvSpec(Atlantis-ram-v4), EnvSpec(Atlantis-ramDeterministic-v0), EnvSpec(Atlantis-ramDeterministic-v4), EnvSpec(Atlantis-ramNoFrameskip-v0), EnvSpec(Atlantis-ramNoFrameskip-v4), EnvSpec(BankHeist-v0), EnvSpec(BankHeist-v4), EnvSpec(BankHeistDeterministic-v0), EnvSpec(BankHeistDeterministic-v4), EnvSpec(BankHeistNoFrameskip-v0), EnvSpec(BankHeistNoFrameskip-v4), EnvSpec(BankHeist-ram-v0), EnvSpec(BankHeist-ram-v4), EnvSpec(BankHeist-ramDeterministic-v0), EnvSpec(BankHeist-ramDeterministic-v4), EnvSpec(BankHeist-ramNoFrameskip-v0), EnvSpec(BankHeist-ramNoFrameskip-v4), EnvSpec(BattleZone-v0), EnvSpec(BattleZone-v4), EnvSpec(BattleZoneDeterministic-v0), EnvSpec(BattleZoneDeterministic-v4), EnvSpec(BattleZoneNoFrameskip-v0), EnvSpec(BattleZoneNoFrameskip-v4), EnvSpec(BattleZone-ram-v0), EnvSpec(BattleZone-ram-v4), EnvSpec(BattleZone-ramDeterministic-v0), EnvSpec(BattleZone-ramDeterministic-v4), EnvSpec(BattleZone-ramNoFrameskip-v0), EnvSpec(BattleZone-ramNoFrameskip-v4), EnvSpec(BeamRider-v0), EnvSpec(BeamRider-v4), EnvSpec(BeamRiderDeterministic-v0), EnvSpec(BeamRiderDeterministic-v4), EnvSpec(BeamRiderNoFrameskip-v0), EnvSpec(BeamRiderNoFrameskip-v4), EnvSpec(BeamRider-ram-v0), EnvSpec(BeamRider-ram-v4), EnvSpec(BeamRider-ramDeterministic-v0), EnvSpec(BeamRider-ramDeterministic-v4), EnvSpec(BeamRider-ramNoFrameskip-v0), EnvSpec(BeamRider-ramNoFrameskip-v4), EnvSpec(Berzerk-v0), EnvSpec(Berzerk-v4), EnvSpec(BerzerkDeterministic-v0), EnvSpec(BerzerkDeterministic-v4), EnvSpec(BerzerkNoFrameskip-v0), EnvSpec(BerzerkNoFrameskip-v4), EnvSpec(Berzerk-ram-v0), EnvSpec(Berzerk-ram-v4), EnvSpec(Berzerk-ramDeterministic-v0), EnvSpec(Berzerk-ramDeterministic-v4), EnvSpec(Berzerk-ramNoFrameskip-v0), EnvSpec(Berzerk-ramNoFrameskip-v4), EnvSpec(Bowling-v0), EnvSpec(Bowling-v4), EnvSpec(BowlingDeterministic-v0), EnvSpec(BowlingDeterministic-v4), EnvSpec(BowlingNoFrameskip-v0), EnvSpec(BowlingNoFrameskip-v4), EnvSpec(Bowling-ram-v0), EnvSpec(Bowling-ram-v4), EnvSpec(Bowling-ramDeterministic-v0), EnvSpec(Bowling-ramDeterministic-v4), EnvSpec(Bowling-ramNoFrameskip-v0), EnvSpec(Bowling-ramNoFrameskip-v4), EnvSpec(Boxing-v0), EnvSpec(Boxing-v4), EnvSpec(BoxingDeterministic-v0), EnvSpec(BoxingDeterministic-v4), EnvSpec(BoxingNoFrameskip-v0), EnvSpec(BoxingNoFrameskip-v4), EnvSpec(Boxing-ram-v0), EnvSpec(Boxing-ram-v4), EnvSpec(Boxing-ramDeterministic-v0), EnvSpec(Boxing-ramDeterministic-v4), EnvSpec(Boxing-ramNoFrameskip-v0), EnvSpec(Boxing-ramNoFrameskip-v4), EnvSpec(Breakout-v0), EnvSpec(Breakout-v4), EnvSpec(BreakoutDeterministic-v0), EnvSpec(BreakoutDeterministic-v4), EnvSpec(BreakoutNoFrameskip-v0), EnvSpec(BreakoutNoFrameskip-v4), EnvSpec(Breakout-ram-v0), EnvSpec(Breakout-ram-v4), EnvSpec(Breakout-ramDeterministic-v0), EnvSpec(Breakout-ramDeterministic-v4), EnvSpec(Breakout-ramNoFrameskip-v0), EnvSpec(Breakout-ramNoFrameskip-v4), EnvSpec(Carnival-v0), EnvSpec(Carnival-v4), EnvSpec(CarnivalDeterministic-v0), EnvSpec(CarnivalDeterministic-v4), EnvSpec(CarnivalNoFrameskip-v0), EnvSpec(CarnivalNoFrameskip-v4), EnvSpec(Carnival-ram-v0), EnvSpec(Carnival-ram-v4), EnvSpec(Carnival-ramDeterministic-v0), EnvSpec(Carnival-ramDeterministic-v4), EnvSpec(Carnival-ramNoFrameskip-v0), EnvSpec(Carnival-ramNoFrameskip-v4), EnvSpec(Centipede-v0), EnvSpec(Centipede-v4), EnvSpec(CentipedeDeterministic-v0), EnvSpec(CentipedeDeterministic-v4), EnvSpec(CentipedeNoFrameskip-v0), EnvSpec(CentipedeNoFrameskip-v4), EnvSpec(Centipede-ram-v0), EnvSpec(Centipede-ram-v4), EnvSpec(Centipede-ramDeterministic-v0), EnvSpec(Centipede-ramDeterministic-v4), EnvSpec(Centipede-ramNoFrameskip-v0), EnvSpec(Centipede-ramNoFrameskip-v4), EnvSpec(ChopperCommand-v0), EnvSpec(ChopperCommand-v4), EnvSpec(ChopperCommandDeterministic-v0), EnvSpec(ChopperCommandDeterministic-v4), EnvSpec(ChopperCommandNoFrameskip-v0), EnvSpec(ChopperCommandNoFrameskip-v4), EnvSpec(ChopperCommand-ram-v0), EnvSpec(ChopperCommand-ram-v4), EnvSpec(ChopperCommand-ramDeterministic-v0), EnvSpec(ChopperCommand-ramDeterministic-v4), EnvSpec(ChopperCommand-ramNoFrameskip-v0), EnvSpec(ChopperCommand-ramNoFrameskip-v4), EnvSpec(CrazyClimber-v0), EnvSpec(CrazyClimber-v4), EnvSpec(CrazyClimberDeterministic-v0), EnvSpec(CrazyClimberDeterministic-v4), EnvSpec(CrazyClimberNoFrameskip-v0), EnvSpec(CrazyClimberNoFrameskip-v4), EnvSpec(CrazyClimber-ram-v0), EnvSpec(CrazyClimber-ram-v4), EnvSpec(CrazyClimber-ramDeterministic-v0), EnvSpec(CrazyClimber-ramDeterministic-v4), EnvSpec(CrazyClimber-ramNoFrameskip-v0), EnvSpec(CrazyClimber-ramNoFrameskip-v4), EnvSpec(Defender-v0), EnvSpec(Defender-v4), EnvSpec(DefenderDeterministic-v0), EnvSpec(DefenderDeterministic-v4), EnvSpec(DefenderNoFrameskip-v0), EnvSpec(DefenderNoFrameskip-v4), EnvSpec(Defender-ram-v0), EnvSpec(Defender-ram-v4), EnvSpec(Defender-ramDeterministic-v0), EnvSpec(Defender-ramDeterministic-v4), EnvSpec(Defender-ramNoFrameskip-v0), EnvSpec(Defender-ramNoFrameskip-v4), EnvSpec(DemonAttack-v0), EnvSpec(DemonAttack-v4), EnvSpec(DemonAttackDeterministic-v0), EnvSpec(DemonAttackDeterministic-v4), EnvSpec(DemonAttackNoFrameskip-v0), EnvSpec(DemonAttackNoFrameskip-v4), EnvSpec(DemonAttack-ram-v0), EnvSpec(DemonAttack-ram-v4), EnvSpec(DemonAttack-ramDeterministic-v0), EnvSpec(DemonAttack-ramDeterministic-v4), EnvSpec(DemonAttack-ramNoFrameskip-v0), EnvSpec(DemonAttack-ramNoFrameskip-v4), EnvSpec(DoubleDunk-v0), EnvSpec(DoubleDunk-v4), EnvSpec(DoubleDunkDeterministic-v0), EnvSpec(DoubleDunkDeterministic-v4), EnvSpec(DoubleDunkNoFrameskip-v0), EnvSpec(DoubleDunkNoFrameskip-v4), EnvSpec(DoubleDunk-ram-v0), EnvSpec(DoubleDunk-ram-v4), EnvSpec(DoubleDunk-ramDeterministic-v0), EnvSpec(DoubleDunk-ramDeterministic-v4), EnvSpec(DoubleDunk-ramNoFrameskip-v0), EnvSpec(DoubleDunk-ramNoFrameskip-v4), EnvSpec(ElevatorAction-v0), EnvSpec(ElevatorAction-v4), EnvSpec(ElevatorActionDeterministic-v0), EnvSpec(ElevatorActionDeterministic-v4), EnvSpec(ElevatorActionNoFrameskip-v0), EnvSpec(ElevatorActionNoFrameskip-v4), EnvSpec(ElevatorAction-ram-v0), EnvSpec(ElevatorAction-ram-v4), EnvSpec(ElevatorAction-ramDeterministic-v0), EnvSpec(ElevatorAction-ramDeterministic-v4), EnvSpec(ElevatorAction-ramNoFrameskip-v0), EnvSpec(ElevatorAction-ramNoFrameskip-v4), EnvSpec(Enduro-v0), EnvSpec(Enduro-v4), EnvSpec(EnduroDeterministic-v0), EnvSpec(EnduroDeterministic-v4), EnvSpec(EnduroNoFrameskip-v0), EnvSpec(EnduroNoFrameskip-v4), EnvSpec(Enduro-ram-v0), EnvSpec(Enduro-ram-v4), EnvSpec(Enduro-ramDeterministic-v0), EnvSpec(Enduro-ramDeterministic-v4), EnvSpec(Enduro-ramNoFrameskip-v0), EnvSpec(Enduro-ramNoFrameskip-v4), EnvSpec(FishingDerby-v0), EnvSpec(FishingDerby-v4), EnvSpec(FishingDerbyDeterministic-v0), EnvSpec(FishingDerbyDeterministic-v4), EnvSpec(FishingDerbyNoFrameskip-v0), EnvSpec(FishingDerbyNoFrameskip-v4), EnvSpec(FishingDerby-ram-v0), EnvSpec(FishingDerby-ram-v4), EnvSpec(FishingDerby-ramDeterministic-v0), EnvSpec(FishingDerby-ramDeterministic-v4), EnvSpec(FishingDerby-ramNoFrameskip-v0), EnvSpec(FishingDerby-ramNoFrameskip-v4), EnvSpec(Freeway-v0), EnvSpec(Freeway-v4), EnvSpec(FreewayDeterministic-v0), EnvSpec(FreewayDeterministic-v4), EnvSpec(FreewayNoFrameskip-v0), EnvSpec(FreewayNoFrameskip-v4), EnvSpec(Freeway-ram-v0), EnvSpec(Freeway-ram-v4), EnvSpec(Freeway-ramDeterministic-v0), EnvSpec(Freeway-ramDeterministic-v4), EnvSpec(Freeway-ramNoFrameskip-v0), EnvSpec(Freeway-ramNoFrameskip-v4), EnvSpec(Frostbite-v0), EnvSpec(Frostbite-v4), EnvSpec(FrostbiteDeterministic-v0), EnvSpec(FrostbiteDeterministic-v4), EnvSpec(FrostbiteNoFrameskip-v0), EnvSpec(FrostbiteNoFrameskip-v4), EnvSpec(Frostbite-ram-v0), EnvSpec(Frostbite-ram-v4), EnvSpec(Frostbite-ramDeterministic-v0), EnvSpec(Frostbite-ramDeterministic-v4), EnvSpec(Frostbite-ramNoFrameskip-v0), EnvSpec(Frostbite-ramNoFrameskip-v4), EnvSpec(Gopher-v0), EnvSpec(Gopher-v4), EnvSpec(GopherDeterministic-v0), EnvSpec(GopherDeterministic-v4), EnvSpec(GopherNoFrameskip-v0), EnvSpec(GopherNoFrameskip-v4), EnvSpec(Gopher-ram-v0), EnvSpec(Gopher-ram-v4), EnvSpec(Gopher-ramDeterministic-v0), EnvSpec(Gopher-ramDeterministic-v4), EnvSpec(Gopher-ramNoFrameskip-v0), EnvSpec(Gopher-ramNoFrameskip-v4), EnvSpec(Gravitar-v0), EnvSpec(Gravitar-v4), EnvSpec(GravitarDeterministic-v0), EnvSpec(GravitarDeterministic-v4), EnvSpec(GravitarNoFrameskip-v0), EnvSpec(GravitarNoFrameskip-v4), EnvSpec(Gravitar-ram-v0), EnvSpec(Gravitar-ram-v4), EnvSpec(Gravitar-ramDeterministic-v0), EnvSpec(Gravitar-ramDeterministic-v4), EnvSpec(Gravitar-ramNoFrameskip-v0), EnvSpec(Gravitar-ramNoFrameskip-v4), EnvSpec(Hero-v0), EnvSpec(Hero-v4), EnvSpec(HeroDeterministic-v0), EnvSpec(HeroDeterministic-v4), EnvSpec(HeroNoFrameskip-v0), EnvSpec(HeroNoFrameskip-v4), EnvSpec(Hero-ram-v0), EnvSpec(Hero-ram-v4), EnvSpec(Hero-ramDeterministic-v0), EnvSpec(Hero-ramDeterministic-v4), EnvSpec(Hero-ramNoFrameskip-v0), EnvSpec(Hero-ramNoFrameskip-v4), EnvSpec(IceHockey-v0), EnvSpec(IceHockey-v4), EnvSpec(IceHockeyDeterministic-v0), EnvSpec(IceHockeyDeterministic-v4), EnvSpec(IceHockeyNoFrameskip-v0), EnvSpec(IceHockeyNoFrameskip-v4), EnvSpec(IceHockey-ram-v0), EnvSpec(IceHockey-ram-v4), EnvSpec(IceHockey-ramDeterministic-v0), EnvSpec(IceHockey-ramDeterministic-v4), EnvSpec(IceHockey-ramNoFrameskip-v0), EnvSpec(IceHockey-ramNoFrameskip-v4), EnvSpec(Jamesbond-v0), EnvSpec(Jamesbond-v4), EnvSpec(JamesbondDeterministic-v0), EnvSpec(JamesbondDeterministic-v4), EnvSpec(JamesbondNoFrameskip-v0), EnvSpec(JamesbondNoFrameskip-v4), EnvSpec(Jamesbond-ram-v0), EnvSpec(Jamesbond-ram-v4), EnvSpec(Jamesbond-ramDeterministic-v0), EnvSpec(Jamesbond-ramDeterministic-v4), EnvSpec(Jamesbond-ramNoFrameskip-v0), EnvSpec(Jamesbond-ramNoFrameskip-v4), EnvSpec(JourneyEscape-v0), EnvSpec(JourneyEscape-v4), EnvSpec(JourneyEscapeDeterministic-v0), EnvSpec(JourneyEscapeDeterministic-v4), EnvSpec(JourneyEscapeNoFrameskip-v0), EnvSpec(JourneyEscapeNoFrameskip-v4), EnvSpec(JourneyEscape-ram-v0), EnvSpec(JourneyEscape-ram-v4), EnvSpec(JourneyEscape-ramDeterministic-v0), EnvSpec(JourneyEscape-ramDeterministic-v4), EnvSpec(JourneyEscape-ramNoFrameskip-v0), EnvSpec(JourneyEscape-ramNoFrameskip-v4), EnvSpec(Kangaroo-v0), EnvSpec(Kangaroo-v4), EnvSpec(KangarooDeterministic-v0), EnvSpec(KangarooDeterministic-v4), EnvSpec(KangarooNoFrameskip-v0), EnvSpec(KangarooNoFrameskip-v4), EnvSpec(Kangaroo-ram-v0), EnvSpec(Kangaroo-ram-v4), EnvSpec(Kangaroo-ramDeterministic-v0), EnvSpec(Kangaroo-ramDeterministic-v4), EnvSpec(Kangaroo-ramNoFrameskip-v0), EnvSpec(Kangaroo-ramNoFrameskip-v4), EnvSpec(Krull-v0), EnvSpec(Krull-v4), EnvSpec(KrullDeterministic-v0), EnvSpec(KrullDeterministic-v4), EnvSpec(KrullNoFrameskip-v0), EnvSpec(KrullNoFrameskip-v4), EnvSpec(Krull-ram-v0), EnvSpec(Krull-ram-v4), EnvSpec(Krull-ramDeterministic-v0), EnvSpec(Krull-ramDeterministic-v4), EnvSpec(Krull-ramNoFrameskip-v0), EnvSpec(Krull-ramNoFrameskip-v4), EnvSpec(KungFuMaster-v0), EnvSpec(KungFuMaster-v4), EnvSpec(KungFuMasterDeterministic-v0), EnvSpec(KungFuMasterDeterministic-v4), EnvSpec(KungFuMasterNoFrameskip-v0), EnvSpec(KungFuMasterNoFrameskip-v4), EnvSpec(KungFuMaster-ram-v0), EnvSpec(KungFuMaster-ram-v4), EnvSpec(KungFuMaster-ramDeterministic-v0), EnvSpec(KungFuMaster-ramDeterministic-v4), EnvSpec(KungFuMaster-ramNoFrameskip-v0), EnvSpec(KungFuMaster-ramNoFrameskip-v4), EnvSpec(MontezumaRevenge-v0), EnvSpec(MontezumaRevenge-v4), EnvSpec(MontezumaRevengeDeterministic-v0), EnvSpec(MontezumaRevengeDeterministic-v4), EnvSpec(MontezumaRevengeNoFrameskip-v0), EnvSpec(MontezumaRevengeNoFrameskip-v4), EnvSpec(MontezumaRevenge-ram-v0), EnvSpec(MontezumaRevenge-ram-v4), EnvSpec(MontezumaRevenge-ramDeterministic-v0), EnvSpec(MontezumaRevenge-ramDeterministic-v4), EnvSpec(MontezumaRevenge-ramNoFrameskip-v0), EnvSpec(MontezumaRevenge-ramNoFrameskip-v4), EnvSpec(MsPacman-v0), EnvSpec(MsPacman-v4), EnvSpec(MsPacmanDeterministic-v0), EnvSpec(MsPacmanDeterministic-v4), EnvSpec(MsPacmanNoFrameskip-v0), EnvSpec(MsPacmanNoFrameskip-v4), EnvSpec(MsPacman-ram-v0), EnvSpec(MsPacman-ram-v4), EnvSpec(MsPacman-ramDeterministic-v0), EnvSpec(MsPacman-ramDeterministic-v4), EnvSpec(MsPacman-ramNoFrameskip-v0), EnvSpec(MsPacman-ramNoFrameskip-v4), EnvSpec(NameThisGame-v0), EnvSpec(NameThisGame-v4), EnvSpec(NameThisGameDeterministic-v0), EnvSpec(NameThisGameDeterministic-v4), EnvSpec(NameThisGameNoFrameskip-v0), EnvSpec(NameThisGameNoFrameskip-v4), EnvSpec(NameThisGame-ram-v0), EnvSpec(NameThisGame-ram-v4), EnvSpec(NameThisGame-ramDeterministic-v0), EnvSpec(NameThisGame-ramDeterministic-v4), EnvSpec(NameThisGame-ramNoFrameskip-v0), EnvSpec(NameThisGame-ramNoFrameskip-v4), EnvSpec(Phoenix-v0), EnvSpec(Phoenix-v4), EnvSpec(PhoenixDeterministic-v0), EnvSpec(PhoenixDeterministic-v4), EnvSpec(PhoenixNoFrameskip-v0), EnvSpec(PhoenixNoFrameskip-v4), EnvSpec(Phoenix-ram-v0), EnvSpec(Phoenix-ram-v4), EnvSpec(Phoenix-ramDeterministic-v0), EnvSpec(Phoenix-ramDeterministic-v4), EnvSpec(Phoenix-ramNoFrameskip-v0), EnvSpec(Phoenix-ramNoFrameskip-v4), EnvSpec(Pitfall-v0), EnvSpec(Pitfall-v4), EnvSpec(PitfallDeterministic-v0), EnvSpec(PitfallDeterministic-v4), EnvSpec(PitfallNoFrameskip-v0), EnvSpec(PitfallNoFrameskip-v4), EnvSpec(Pitfall-ram-v0), EnvSpec(Pitfall-ram-v4), EnvSpec(Pitfall-ramDeterministic-v0), EnvSpec(Pitfall-ramDeterministic-v4), EnvSpec(Pitfall-ramNoFrameskip-v0), EnvSpec(Pitfall-ramNoFrameskip-v4), EnvSpec(Pong-v0), EnvSpec(Pong-v4), EnvSpec(PongDeterministic-v0), EnvSpec(PongDeterministic-v4), EnvSpec(PongNoFrameskip-v0), EnvSpec(PongNoFrameskip-v4), EnvSpec(Pong-ram-v0), EnvSpec(Pong-ram-v4), EnvSpec(Pong-ramDeterministic-v0), EnvSpec(Pong-ramDeterministic-v4), EnvSpec(Pong-ramNoFrameskip-v0), EnvSpec(Pong-ramNoFrameskip-v4), EnvSpec(Pooyan-v0), EnvSpec(Pooyan-v4), EnvSpec(PooyanDeterministic-v0), EnvSpec(PooyanDeterministic-v4), EnvSpec(PooyanNoFrameskip-v0), EnvSpec(PooyanNoFrameskip-v4), EnvSpec(Pooyan-ram-v0), EnvSpec(Pooyan-ram-v4), EnvSpec(Pooyan-ramDeterministic-v0), EnvSpec(Pooyan-ramDeterministic-v4), EnvSpec(Pooyan-ramNoFrameskip-v0), EnvSpec(Pooyan-ramNoFrameskip-v4), EnvSpec(PrivateEye-v0), EnvSpec(PrivateEye-v4), EnvSpec(PrivateEyeDeterministic-v0), EnvSpec(PrivateEyeDeterministic-v4), EnvSpec(PrivateEyeNoFrameskip-v0), EnvSpec(PrivateEyeNoFrameskip-v4), EnvSpec(PrivateEye-ram-v0), EnvSpec(PrivateEye-ram-v4), EnvSpec(PrivateEye-ramDeterministic-v0), EnvSpec(PrivateEye-ramDeterministic-v4), EnvSpec(PrivateEye-ramNoFrameskip-v0), EnvSpec(PrivateEye-ramNoFrameskip-v4), EnvSpec(Qbert-v0), EnvSpec(Qbert-v4), EnvSpec(QbertDeterministic-v0), EnvSpec(QbertDeterministic-v4), EnvSpec(QbertNoFrameskip-v0), EnvSpec(QbertNoFrameskip-v4), EnvSpec(Qbert-ram-v0), EnvSpec(Qbert-ram-v4), EnvSpec(Qbert-ramDeterministic-v0), EnvSpec(Qbert-ramDeterministic-v4), EnvSpec(Qbert-ramNoFrameskip-v0), EnvSpec(Qbert-ramNoFrameskip-v4), EnvSpec(Riverraid-v0), EnvSpec(Riverraid-v4), EnvSpec(RiverraidDeterministic-v0), EnvSpec(RiverraidDeterministic-v4), EnvSpec(RiverraidNoFrameskip-v0), EnvSpec(RiverraidNoFrameskip-v4), EnvSpec(Riverraid-ram-v0), EnvSpec(Riverraid-ram-v4), EnvSpec(Riverraid-ramDeterministic-v0), EnvSpec(Riverraid-ramDeterministic-v4), EnvSpec(Riverraid-ramNoFrameskip-v0), EnvSpec(Riverraid-ramNoFrameskip-v4), EnvSpec(RoadRunner-v0), EnvSpec(RoadRunner-v4), EnvSpec(RoadRunnerDeterministic-v0), EnvSpec(RoadRunnerDeterministic-v4), EnvSpec(RoadRunnerNoFrameskip-v0), EnvSpec(RoadRunnerNoFrameskip-v4), EnvSpec(RoadRunner-ram-v0), EnvSpec(RoadRunner-ram-v4), EnvSpec(RoadRunner-ramDeterministic-v0), EnvSpec(RoadRunner-ramDeterministic-v4), EnvSpec(RoadRunner-ramNoFrameskip-v0), EnvSpec(RoadRunner-ramNoFrameskip-v4), EnvSpec(Robotank-v0), EnvSpec(Robotank-v4), EnvSpec(RobotankDeterministic-v0), EnvSpec(RobotankDeterministic-v4), EnvSpec(RobotankNoFrameskip-v0), EnvSpec(RobotankNoFrameskip-v4), EnvSpec(Robotank-ram-v0), EnvSpec(Robotank-ram-v4), EnvSpec(Robotank-ramDeterministic-v0), EnvSpec(Robotank-ramDeterministic-v4), EnvSpec(Robotank-ramNoFrameskip-v0), EnvSpec(Robotank-ramNoFrameskip-v4), EnvSpec(Seaquest-v0), EnvSpec(Seaquest-v4), EnvSpec(SeaquestDeterministic-v0), EnvSpec(SeaquestDeterministic-v4), EnvSpec(SeaquestNoFrameskip-v0), EnvSpec(SeaquestNoFrameskip-v4), EnvSpec(Seaquest-ram-v0), EnvSpec(Seaquest-ram-v4), EnvSpec(Seaquest-ramDeterministic-v0), EnvSpec(Seaquest-ramDeterministic-v4), EnvSpec(Seaquest-ramNoFrameskip-v0), EnvSpec(Seaquest-ramNoFrameskip-v4), EnvSpec(Skiing-v0), EnvSpec(Skiing-v4), EnvSpec(SkiingDeterministic-v0), EnvSpec(SkiingDeterministic-v4), EnvSpec(SkiingNoFrameskip-v0), EnvSpec(SkiingNoFrameskip-v4), EnvSpec(Skiing-ram-v0), EnvSpec(Skiing-ram-v4), EnvSpec(Skiing-ramDeterministic-v0), EnvSpec(Skiing-ramDeterministic-v4), EnvSpec(Skiing-ramNoFrameskip-v0), EnvSpec(Skiing-ramNoFrameskip-v4), EnvSpec(Solaris-v0), EnvSpec(Solaris-v4), EnvSpec(SolarisDeterministic-v0), EnvSpec(SolarisDeterministic-v4), EnvSpec(SolarisNoFrameskip-v0), EnvSpec(SolarisNoFrameskip-v4), EnvSpec(Solaris-ram-v0), EnvSpec(Solaris-ram-v4), EnvSpec(Solaris-ramDeterministic-v0), EnvSpec(Solaris-ramDeterministic-v4), EnvSpec(Solaris-ramNoFrameskip-v0), EnvSpec(Solaris-ramNoFrameskip-v4), EnvSpec(SpaceInvaders-v0), EnvSpec(SpaceInvaders-v4), EnvSpec(SpaceInvadersDeterministic-v0), EnvSpec(SpaceInvadersDeterministic-v4), EnvSpec(SpaceInvadersNoFrameskip-v0), EnvSpec(SpaceInvadersNoFrameskip-v4), EnvSpec(SpaceInvaders-ram-v0), EnvSpec(SpaceInvaders-ram-v4), EnvSpec(SpaceInvaders-ramDeterministic-v0), EnvSpec(SpaceInvaders-ramDeterministic-v4), EnvSpec(SpaceInvaders-ramNoFrameskip-v0), EnvSpec(SpaceInvaders-ramNoFrameskip-v4), EnvSpec(StarGunner-v0), EnvSpec(StarGunner-v4), EnvSpec(StarGunnerDeterministic-v0), EnvSpec(StarGunnerDeterministic-v4), EnvSpec(StarGunnerNoFrameskip-v0), EnvSpec(StarGunnerNoFrameskip-v4), EnvSpec(StarGunner-ram-v0), EnvSpec(StarGunner-ram-v4), EnvSpec(StarGunner-ramDeterministic-v0), EnvSpec(StarGunner-ramDeterministic-v4), EnvSpec(StarGunner-ramNoFrameskip-v0), EnvSpec(StarGunner-ramNoFrameskip-v4), EnvSpec(Tennis-v0), EnvSpec(Tennis-v4), EnvSpec(TennisDeterministic-v0), EnvSpec(TennisDeterministic-v4), EnvSpec(TennisNoFrameskip-v0), EnvSpec(TennisNoFrameskip-v4), EnvSpec(Tennis-ram-v0), EnvSpec(Tennis-ram-v4), EnvSpec(Tennis-ramDeterministic-v0), EnvSpec(Tennis-ramDeterministic-v4), EnvSpec(Tennis-ramNoFrameskip-v0), EnvSpec(Tennis-ramNoFrameskip-v4), EnvSpec(TimePilot-v0), EnvSpec(TimePilot-v4), EnvSpec(TimePilotDeterministic-v0), EnvSpec(TimePilotDeterministic-v4), EnvSpec(TimePilotNoFrameskip-v0), EnvSpec(TimePilotNoFrameskip-v4), EnvSpec(TimePilot-ram-v0), EnvSpec(TimePilot-ram-v4), EnvSpec(TimePilot-ramDeterministic-v0), EnvSpec(TimePilot-ramDeterministic-v4), EnvSpec(TimePilot-ramNoFrameskip-v0), EnvSpec(TimePilot-ramNoFrameskip-v4), EnvSpec(Tutankham-v0), EnvSpec(Tutankham-v4), EnvSpec(TutankhamDeterministic-v0), EnvSpec(TutankhamDeterministic-v4), EnvSpec(TutankhamNoFrameskip-v0), EnvSpec(TutankhamNoFrameskip-v4), EnvSpec(Tutankham-ram-v0), EnvSpec(Tutankham-ram-v4), EnvSpec(Tutankham-ramDeterministic-v0), EnvSpec(Tutankham-ramDeterministic-v4), EnvSpec(Tutankham-ramNoFrameskip-v0), EnvSpec(Tutankham-ramNoFrameskip-v4), EnvSpec(UpNDown-v0), EnvSpec(UpNDown-v4), EnvSpec(UpNDownDeterministic-v0), EnvSpec(UpNDownDeterministic-v4), EnvSpec(UpNDownNoFrameskip-v0), EnvSpec(UpNDownNoFrameskip-v4), EnvSpec(UpNDown-ram-v0), EnvSpec(UpNDown-ram-v4), EnvSpec(UpNDown-ramDeterministic-v0), EnvSpec(UpNDown-ramDeterministic-v4), EnvSpec(UpNDown-ramNoFrameskip-v0), EnvSpec(UpNDown-ramNoFrameskip-v4), EnvSpec(Venture-v0), EnvSpec(Venture-v4), EnvSpec(VentureDeterministic-v0), EnvSpec(VentureDeterministic-v4), EnvSpec(VentureNoFrameskip-v0), EnvSpec(VentureNoFrameskip-v4), EnvSpec(Venture-ram-v0), EnvSpec(Venture-ram-v4), EnvSpec(Venture-ramDeterministic-v0), EnvSpec(Venture-ramDeterministic-v4), EnvSpec(Venture-ramNoFrameskip-v0), EnvSpec(Venture-ramNoFrameskip-v4), EnvSpec(VideoPinball-v0), EnvSpec(VideoPinball-v4), EnvSpec(VideoPinballDeterministic-v0), EnvSpec(VideoPinballDeterministic-v4), EnvSpec(VideoPinballNoFrameskip-v0), EnvSpec(VideoPinballNoFrameskip-v4), EnvSpec(VideoPinball-ram-v0), EnvSpec(VideoPinball-ram-v4), EnvSpec(VideoPinball-ramDeterministic-v0), EnvSpec(VideoPinball-ramDeterministic-v4), EnvSpec(VideoPinball-ramNoFrameskip-v0), EnvSpec(VideoPinball-ramNoFrameskip-v4), EnvSpec(WizardOfWor-v0), EnvSpec(WizardOfWor-v4), EnvSpec(WizardOfWorDeterministic-v0), EnvSpec(WizardOfWorDeterministic-v4), EnvSpec(WizardOfWorNoFrameskip-v0), EnvSpec(WizardOfWorNoFrameskip-v4), EnvSpec(WizardOfWor-ram-v0), EnvSpec(WizardOfWor-ram-v4), EnvSpec(WizardOfWor-ramDeterministic-v0), EnvSpec(WizardOfWor-ramDeterministic-v4), EnvSpec(WizardOfWor-ramNoFrameskip-v0), EnvSpec(WizardOfWor-ramNoFrameskip-v4), EnvSpec(YarsRevenge-v0), EnvSpec(YarsRevenge-v4), EnvSpec(YarsRevengeDeterministic-v0), EnvSpec(YarsRevengeDeterministic-v4), EnvSpec(YarsRevengeNoFrameskip-v0), EnvSpec(YarsRevengeNoFrameskip-v4), EnvSpec(YarsRevenge-ram-v0), EnvSpec(YarsRevenge-ram-v4), EnvSpec(YarsRevenge-ramDeterministic-v0), EnvSpec(YarsRevenge-ramDeterministic-v4), EnvSpec(YarsRevenge-ramNoFrameskip-v0), EnvSpec(YarsRevenge-ramNoFrameskip-v4), EnvSpec(Zaxxon-v0), EnvSpec(Zaxxon-v4), EnvSpec(ZaxxonDeterministic-v0), EnvSpec(ZaxxonDeterministic-v4), EnvSpec(ZaxxonNoFrameskip-v0), EnvSpec(ZaxxonNoFrameskip-v4), EnvSpec(Zaxxon-ram-v0), EnvSpec(Zaxxon-ram-v4), EnvSpec(Zaxxon-ramDeterministic-v0), EnvSpec(Zaxxon-ramDeterministic-v4), EnvSpec(Zaxxon-ramNoFrameskip-v0), EnvSpec(Zaxxon-ramNoFrameskip-v4), EnvSpec(CubeCrash-v0), EnvSpec(CubeCrashSparse-v0), EnvSpec(CubeCrashScreenBecomesBlack-v0), EnvSpec(MemorizeDigits-v0)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "I4JZQnqxIptg",
        "outputId": "332bfee7-8d2d-435a-bde2-48db1af13543"
      },
      "source": [
        "gym.EnvSpec('Alien-v0')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-639d431e099d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnvSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Alien-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'gym' has no attribute 'EnvSpec'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX_4yjQvI6dU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}