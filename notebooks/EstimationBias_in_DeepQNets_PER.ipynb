{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EstimationBias_in_DeepQNets.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "927XuS3miph7"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "\n",
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "from collections import deque, namedtuple\n",
        "import copy\n",
        "from itertools import count\n",
        "import math\n",
        "import random\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVxPAr-8jvzN",
        "outputId": "9612ec14-2272-43b1-dc21-392aa3e28717"
      },
      "source": [
        "!git clone 'https://github.com/jmichaux/dqn-pytorch'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'dqn-pytorch' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuuOZsTimS9R"
      },
      "source": [
        "import os\n",
        "os.chdir('dqn-pytorch')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13CVQzAZj_7w"
      },
      "source": [
        "from wrappers import *\n",
        "from wrappers import *\n",
        "from memory import ReplayMemory\n",
        "from models import *"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuEkR3bR2lF0"
      },
      "source": [
        "from collections import namedtuple\n",
        "import random\n",
        "\n",
        "Transition = namedtuple('Experience', \n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "Data = namedtuple('Data',('priority','probability','weight','index'))\n",
        "\n",
        "class ReplayMemory(object):\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "        \n",
        "    def push(self, *args):\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = Transition(*args)\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "        \n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "\n",
        "class PriorityReplayMemory():\n",
        "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
        "\n",
        "    def __init__(self, action_size, buffer_size, batch_size, experiences_per_sampling, seed, compute_weights):\n",
        "        \"\"\"Initialize a ReplayBuffer object.\n",
        "        Params\n",
        "        ======\n",
        "            action_size (int): dimension of each action\n",
        "            buffer_size (int): maximum size of buffer\n",
        "            experiences_per_sampling (int): number of experiences to sample during a sampling iteration\n",
        "            batch_size (int): size of each training batch\n",
        "            seed (int): random seed\n",
        "        \"\"\"\n",
        "        self.action_size = action_size\n",
        "        self.buffer_size = buffer_size\n",
        "        self.batch_size = batch_size\n",
        "        self.experiences_per_sampling = experiences_per_sampling\n",
        "        \n",
        "        self.alpha = 0.5\n",
        "        self.alpha_decay_rate = 0.99\n",
        "        self.beta = 0.5\n",
        "        self.beta_growth_rate = 1.001\n",
        "        self.seed = random.seed(seed)\n",
        "        self.compute_weights = compute_weights\n",
        "        self.experience_count = 0\n",
        "        \n",
        "        self.experience = namedtuple('Experience', \n",
        "            field_names=('state', 'action', 'next_state', 'reward'))\n",
        "        self.data = namedtuple('Data', \n",
        "            field_names=('priority', 'probability', 'weight', 'index'))\n",
        "\n",
        "        indexes = []\n",
        "        datas = []\n",
        "        for i in range(buffer_size):\n",
        "            indexes.append(i)\n",
        "            d = self.data(0,0,0,i)\n",
        "            datas.append(d)\n",
        "        \n",
        "        self.memory = {key: self.experience for key in indexes}\n",
        "        self.memory_data = {key: data for key,data in zip(indexes, datas)}\n",
        "        self.sampled_batches = []\n",
        "        self.current_batch = 0\n",
        "        self.priorities_sum_alpha = 0\n",
        "        self.priorities_max = 1\n",
        "        self.weights_max = 1\n",
        "    \n",
        "    def update_priorities(self, tds, indices):\n",
        "        for td, index in zip(tds, indices):\n",
        "            N = min(self.experience_count, self.buffer_size)\n",
        "\n",
        "            updated_priority = td[0]\n",
        "            if updated_priority > self.priorities_max:\n",
        "                self.priorities_max = updated_priority\n",
        "            \n",
        "            if self.compute_weights:\n",
        "                updated_weight = ((N * updated_priority)**(-self.beta))/self.weights_max\n",
        "                if updated_weight > self.weights_max:\n",
        "                    self.weights_max = updated_weight\n",
        "            else:\n",
        "                updated_weight = 1\n",
        "\n",
        "            old_priority = self.memory_data[index].priority\n",
        "            self.priorities_sum_alpha += updated_priority**self.alpha - old_priority**self.alpha\n",
        "            updated_probability = td[0]**self.alpha / self.priorities_sum_alpha\n",
        "            data = self.data(updated_priority, updated_probability, updated_weight, index) \n",
        "            self.memory_data[index] = data\n",
        "\n",
        "    def update_memory_sampling(self):\n",
        "        \"\"\"Randomly sample X batches of experiences from memory.\"\"\"\n",
        "        # X is the number of steps before updating memory\n",
        "        self.current_batch = 0\n",
        "        values = list(self.memory_data.values())\n",
        "        random_values = random.choices(self.memory_data, \n",
        "                                       [data.probability for data in values], \n",
        "                                       k=self.experiences_per_sampling)\n",
        "        self.sampled_batches = [random_values[i:i + self.batch_size] \n",
        "                                    for i in range(0, len(random_values), self.batch_size)]\n",
        "\n",
        "    def update_parameters(self):\n",
        "        self.alpha *= self.alpha_decay_rate\n",
        "        self.beta *= self.beta_growth_rate\n",
        "        if self.beta > 1:\n",
        "            self.beta = 1\n",
        "        N = min(self.experience_count, self.buffer_size)\n",
        "        self.priorities_sum_alpha = 0\n",
        "        sum_prob_before = 0\n",
        "        for element in self.memory_data.values():\n",
        "            sum_prob_before += element.probability\n",
        "            self.priorities_sum_alpha += element.priority**self.alpha\n",
        "        sum_prob_after = 0\n",
        "        for element in self.memory_data.values():\n",
        "            probability = element.priority**self.alpha / self.priorities_sum_alpha\n",
        "            sum_prob_after += probability\n",
        "            weight = 1\n",
        "            if self.compute_weights:\n",
        "                weight = ((N *  element.probability)**(-self.beta))/self.weights_max\n",
        "            d = self.data(element.priority, probability, weight, element.index)\n",
        "            self.memory_data[element.index] = d\n",
        "        print(\"sum_prob before\", sum_prob_before)\n",
        "        print(\"sum_prob after : \", sum_prob_after)\n",
        "    \n",
        "    def push(self, state, action, next_state, reward):\n",
        "        \"\"\"Add a new experience to memory.\"\"\"\n",
        "        self.experience_count += 1\n",
        "        index = self.experience_count % self.buffer_size\n",
        "\n",
        "        if self.experience_count > self.buffer_size:\n",
        "            temp = self.memory_data[index]\n",
        "            self.priorities_sum_alpha -= temp.priority**self.alpha\n",
        "            if temp.priority == self.priorities_max:\n",
        "                self.memory_data[index].priority = 0\n",
        "                self.priorities_max = max(self.memory_data.items(), key=operator.itemgetter(1)).priority\n",
        "            if self.compute_weights:\n",
        "                if temp.weight == self.weights_max:\n",
        "                    self.memory_data[index].weight = 0\n",
        "                    self.weights_max = max(self.memory_data.items(), key=operator.itemgetter(2)).weight\n",
        "\n",
        "        priority = self.priorities_max\n",
        "        weight = self.weights_max\n",
        "        self.priorities_sum_alpha += priority ** self.alpha\n",
        "        probability = priority ** self.alpha / self.priorities_sum_alpha\n",
        "        e = self.experience(state, action, next_state, reward)\n",
        "        self.memory[index] = e\n",
        "        d = self.data(priority, probability, weight, index)\n",
        "        self.memory_data[index] = d\n",
        "            \n",
        "    def sample(self):\n",
        "      if not self.sampled_batches:\n",
        "        print(len(self.sampled_batches))\n",
        "        sampled_batch = self.sampled_batches#[self.current_batch]\n",
        "      else:\n",
        "        self.update_memory_sampling()\n",
        "        sampled_batch = self.sampled_batches#[self.current_batch]\n",
        "        print(sampled_batch)\n",
        "          # values = list(self.memory_data.values())\n",
        "          # random_values = random.choices(self.memory_data, \n",
        "          #                              [data.probability for data in values], \n",
        "          #                              k=self.experiences_per_sampling)\n",
        "          # temp = [random_values[i:i + self.batch_size] \n",
        "          #                           for i in range(0, len(random_values), self.batch_size)]\n",
        "          # print(temp)\n",
        "        self.current_batch += 1\n",
        "        experiences = []\n",
        "        weights = []\n",
        "        indices = []\n",
        "        \n",
        "        for data in sampled_batch:\n",
        "            experiences.append(self.memory.get(data.index))\n",
        "            weights.append(data.weight)\n",
        "            indices.append(data.index)\n",
        "\n",
        "        states = torch.from_numpy(\n",
        "            np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
        "        actions = torch.from_numpy(\n",
        "            np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
        "        rewards = torch.from_numpy(\n",
        "            np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
        "        next_states = torch.from_numpy(\n",
        "            np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
        "\n",
        "        return (states, actions, next_states, rewards, weights, indices)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the current size of internal memory.\"\"\"\n",
        "        return len(self.memory)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uhGGIfF2uWG"
      },
      "source": [
        "class ConvDQNbn(nn.Module):\n",
        "    def __init__(self, in_channels=4, n_actions=14):\n",
        "        \"\"\"\n",
        "        Initialize Deep Q Network\n",
        "        Args:\n",
        "            in_channels (int): number of input channels\n",
        "            n_actions (int): number of outputs\n",
        "        \"\"\"\n",
        "        super(ConvDQNbn, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=8, stride=4)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.fc4 = nn.Linear(7 * 7 * 64, 512)\n",
        "        self.head = nn.Linear(512, n_actions)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.float() / 255\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.fc4(x.view(x.size(0), -1)))\n",
        "        return self.head(x)\n",
        "\n",
        "\n",
        "class ConvDQN(nn.Module):\n",
        "    def __init__(self, in_channels=4, n_actions=14):\n",
        "        \"\"\"\n",
        "        Initialize Deep Q Network\n",
        "        Args:\n",
        "            in_channels (int): number of input channels\n",
        "            n_actions (int): number of outputs\n",
        "        \"\"\"\n",
        "        super(ConvDQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=8, stride=4)\n",
        "        # self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        # self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
        "        # self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.fc4 = nn.Linear(7 * 7 * 64, 512)\n",
        "        self.head = nn.Linear(512, n_actions)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.float() / 255\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.fc4(x.view(x.size(0), -1)))\n",
        "        return self.head(x)\n",
        "\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(DQN, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.input_dim[0], 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, self.output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, state):\n",
        "        qvals = self.fc(state)\n",
        "        return qvals"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3mFNXYmTSW1"
      },
      "source": [
        "Transition = namedtuple('Experience', \n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END)* \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "    with torch.no_grad():\n",
        "      values = policy_net(state.to(device)).max(1)\n",
        "    if sample > eps_threshold:\n",
        "            return values[0], values[1].view(1,1) #choose greedy policy\n",
        "    else:\n",
        "            return values[0],torch.tensor([[random.randrange(env.action_space.n)]], device=device, dtype=torch.long)\n",
        "\n",
        "    \n",
        "def optimize_model(mode = 'DDQN', eType = 'uniform'):\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    if eType == 'uniform':\n",
        "          transitions = memory.sample(BATCH_SIZE)\n",
        "    elif eType =='priority':\n",
        "          states, actions, next_states, rewards, weights, indices = memory.sample()\n",
        "          transitions = (states, actions, next_states, rewards)\n",
        "    \"\"\"\n",
        "    zip(*transitions) unzips the transitions into\n",
        "    Transition(*) creates new named tuple\n",
        "    batch.state - tuple of all the states (each state is a tensor)\n",
        "    batch.next_state - tuple of all the next states (each state is a tensor)\n",
        "    batch.reward - tuple of all the rewards (each reward is a float)\n",
        "    batch.action - tuple of all the actions (each action is an int)    \n",
        "    \"\"\"\n",
        "    batch = Transition(*zip(*transitions))\n",
        "    \n",
        "    actions = tuple((map(lambda a: torch.tensor([[a]], device=device), batch.action))) \n",
        "    rewards = tuple((map(lambda r: torch.tensor([r], device=device), batch.reward))) \n",
        "\n",
        "    non_final_mask = torch.tensor(\n",
        "        tuple(map(lambda s: s is not None, batch.next_state)),\n",
        "        device=device, dtype=torch.uint8)\n",
        "    \n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                       if s is not None]).to(device)\n",
        "    \n",
        "\n",
        "    state_batch = torch.cat(batch.state).to(device)\n",
        "    action_batch = torch.cat(actions).to(device)\n",
        "    reward_batch = torch.cat(rewards).to(device)\n",
        "    \n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch) # q values\n",
        "\n",
        "\n",
        "    if mode == 'DQN':\n",
        "      next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "      next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
        "      expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "    \n",
        "    \n",
        "    elif mode == 'DDQN':\n",
        "      next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "      next_action_values = policy_net(non_final_next_states).max(1)[1].detach()\n",
        "      next_state_values[non_final_mask] = target_net(non_final_next_states).gather(1,next_action_values.unsqueeze(1)).detach().squeeze()\n",
        "      expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "    \n",
        "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "    if eType == 'priority':\n",
        "      if memory.compute_weights:\n",
        "        with torch.no_grad():\n",
        "          weight = sum(np.multiply(weights, loss.data.cpu().numpy()))\n",
        "        loss *= weight\n",
        "      delta = abs(expected_state_action_values.unsqueeze(1) - state_action_values.detach()).numpy()\n",
        "      memory.update_priorities(delta, indices) \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    for param in policy_net.parameters():\n",
        "        param.grad.data.clamp_(-1, 1)\n",
        "    optimizer.step()\n",
        "\n",
        "def get_state(obs):\n",
        "    state = np.array(obs)\n",
        "    state = state.transpose((2, 0, 1))\n",
        "    state = torch.from_numpy(state)\n",
        "    return state.unsqueeze(0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4RfT9GSz9nc"
      },
      "source": [
        "def train(env, n_episodes, set_size, mode = 'DQN', eType = 'uniform', render=False):\n",
        "    val_tensor = []\n",
        "    s = 0\n",
        "    total_reward = 0\n",
        "    result = np.zeros(int(n_episodes))\n",
        "    for episode in range(n_episodes):\n",
        "        obs = env.reset()\n",
        "        state = get_state(obs)\n",
        "        value_list = []\n",
        "        total_reward = 0\n",
        "        n_steps = 0\n",
        "        t_step_mem = 0\n",
        "        t_step_mem_par = 0\n",
        "        for t in count():\n",
        "            value, action = select_action(state)\n",
        "            n_steps += 1\n",
        "            value_list.append(value[0].item())\n",
        "            if steps_done % 1000 ==0:\n",
        "              val_tensor.append([np.mean(value_list), np.std(value_list)/np.sqrt(10000-1)])\n",
        "              value_list = []\n",
        "\n",
        "\n",
        "            if render:\n",
        "                env.render()\n",
        "\n",
        "            obs, reward, done, info = env.step(action)\n",
        "           \n",
        "            total_reward += reward\n",
        "\n",
        "            if not done:\n",
        "                next_state = get_state(obs)\n",
        "            else:\n",
        "                next_state = None\n",
        "                #total_reward += 1\n",
        "\n",
        "            reward = torch.tensor([reward], device=device)\n",
        "\n",
        "            memory.push(state, action.to('cpu'), next_state, reward.to('cpu'))\n",
        "\n",
        "            state = next_state\n",
        "\n",
        "            if steps_done > INITIAL_MEMORY:\n",
        "                optimize_model(mode, eType)\n",
        "\n",
        "                if steps_done % TARGET_UPDATE == 0:\n",
        "                    target_net.load_state_dict(policy_net.state_dict())\n",
        "                \n",
        "                if eType == 'priority':\n",
        "                    if steps_done % UPDATE_MEM_EVERY == 0:\n",
        "                        memory.update_parameters()\n",
        "                    if steps_done % UPDATE_MEM_PAR_EVERY == 0:\n",
        "                        memory.update_memory_sampling()\n",
        "\n",
        "            if done:\n",
        "                result[episode] = total_reward / n_steps\n",
        "                n_steps = 0\n",
        "                break\n",
        "        if episode % 20 == 0:\n",
        "                length_mem = memory.__len__()\n",
        "                print('Total steps: {} \\t Episode: {}/{} \\t Total reward: {} \\t Memory length : {}'.format(steps_done, episode, t, total_reward, length_mem))\n",
        "    env.close()\n",
        "    return val_tensor, result\n",
        "\n",
        "def test(env, n_episodes, policy, render=True):\n",
        "    env = gym.wrappers.Monitor(env, './videos/' + 'dqn_pong_video')\n",
        "    for episode in range(n_episodes):\n",
        "        obs = env.reset()\n",
        "        state = get_state(obs)\n",
        "        total_reward = 0.0\n",
        "        for t in count():\n",
        "            action = policy(state.to('cuda')).max(1)[1].view(1,1)\n",
        "\n",
        "            if render:\n",
        "                env.render()\n",
        "                time.sleep(0.02)\n",
        "\n",
        "            obs, reward, done, info = env.step(action)\n",
        "\n",
        "            total_reward += reward\n",
        "\n",
        "            if not done:\n",
        "                next_state = get_state(obs)\n",
        "            else:\n",
        "                next_state = None\n",
        "\n",
        "            state = next_state\n",
        "\n",
        "            if done:\n",
        "                print(\"Finished Episode {} with reward {}\".format(episode, total_reward))\n",
        "                break\n",
        "\n",
        "    env.close()\n",
        "    return"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1mbReio2gCJ",
        "outputId": "dbefa649-0e12-4b97-fd8d-64f3b7607d5f"
      },
      "source": [
        "# set device\n",
        "\n",
        "def weight_reset(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "        m.reset_parameters()\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# hyperparameters\n",
        "BATCH_SIZE = 32\n",
        "GAMMA = 0.99\n",
        "EPS_START = 1\n",
        "EPS_END = 0.02\n",
        "EPS_DECAY = 1000000\n",
        "TARGET_UPDATE = 1000\n",
        "RENDER = False\n",
        "lr = 1e-4\n",
        "INITIAL_MEMORY = 1000000\n",
        "MEMORY_SIZE = 10 * INITIAL_MEMORY\n",
        "seed = 0\n",
        "compute_weights = True\n",
        "UPDATE_MEM_EVERY = 20          # how often to update the priorities\n",
        "global UPDATE_MEM_EVERY\n",
        "UPDATE_MEM_PAR_EVERY = 3000     # how often to update the hyperparameters\n",
        "global UPDATE_MEM_PAR_EVERY\n",
        "EXPERIENCES_PER_SAMPLING = math.ceil(BATCH_SIZE * UPDATE_MEM_EVERY)\n",
        "global EXPERIENCES_PER_SAMPLING\n",
        "\n",
        "# create environment\n",
        "env = gym.make(\"PongNoFrameskip-v4\")\n",
        "env = make_env(env)\n",
        "\n",
        "action_size = len(env.unwrapped.get_action_meanings())\n",
        "\n",
        "\n",
        "# create networks\n",
        "policy_net = ConvDQNbn(n_actions=env.action_space.n).to(device)\n",
        "target_net = ConvDQNbn(n_actions=env.action_space.n).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "# setup optimizer\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=lr)\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "# initialize replay memory\n",
        "  \n",
        "memory = PriorityReplayMemory(action_size, MEMORY_SIZE, BATCH_SIZE, EXPERIENCES_PER_SAMPLING, seed, compute_weights)\n",
        "policy_net.apply(weight_reset)\n",
        "target_net.apply(weight_reset)\n",
        "# train model\n",
        "val_tensor_DDQN, result_DDQN = train(env, 250, 10, mode='DDQN', eType ='priority')\n",
        "torch.save(policy_net, \"ddqn_pong_per_model\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total steps: 812 \t Episode: 0/811 \t Total reward: -21.0 \t Memory length : 10000000\n",
            "Total steps: 19971 \t Episode: 20/848 \t Total reward: -21.0 \t Memory length : 10000000\n",
            "Total steps: 38159 \t Episode: 40/1012 \t Total reward: -20.0 \t Memory length : 10000000\n",
            "Total steps: 56749 \t Episode: 60/1020 \t Total reward: -21.0 \t Memory length : 10000000\n",
            "Total steps: 75094 \t Episode: 80/895 \t Total reward: -20.0 \t Memory length : 10000000\n",
            "Total steps: 93442 \t Episode: 100/1003 \t Total reward: -20.0 \t Memory length : 10000000\n",
            "Total steps: 111829 \t Episode: 120/928 \t Total reward: -20.0 \t Memory length : 10000000\n",
            "Total steps: 129756 \t Episode: 140/927 \t Total reward: -20.0 \t Memory length : 10000000\n",
            "Total steps: 147516 \t Episode: 160/755 \t Total reward: -21.0 \t Memory length : 10000000\n",
            "Total steps: 165735 \t Episode: 180/909 \t Total reward: -21.0 \t Memory length : 10000000\n",
            "Total steps: 184938 \t Episode: 200/923 \t Total reward: -21.0 \t Memory length : 10000000\n",
            "Total steps: 203003 \t Episode: 220/784 \t Total reward: -21.0 \t Memory length : 10000000\n",
            "Total steps: 222123 \t Episode: 240/929 \t Total reward: -20.0 \t Memory length : 10000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvWY7t3jTJ4K"
      },
      "source": [
        "del memory"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbstXox7Pl6u",
        "outputId": "2dedfcd8-0f9d-4fa5-b895-2d078ab3d67b"
      },
      "source": [
        "steps_done = 0\n",
        "\n",
        "# initialize replay memory\n",
        "memory = ReplayMemory(MEMORY_SIZE)\n",
        "\n",
        "policy_net.apply(weight_reset)\n",
        "target_net.apply(weight_reset)\n",
        "#policy_net = torch.load(\"dqn_pong_model\")\n",
        "val_tensor_DQN, result_DQN = train(env, 250, 10, eType='uniform', mode='DDQN')\n",
        "torch.save(policy_net, \"ddqn_pong_no_per_model\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total steps: 985 \t Episode: 0/984 \t Total reward: -20.0 \t Memory length : 985\n",
            "Total steps: 19756 \t Episode: 20/942 \t Total reward: -19.0 \t Memory length : 19756\n",
            "Total steps: 38421 \t Episode: 40/756 \t Total reward: -21.0 \t Memory length : 38421\n",
            "Total steps: 57078 \t Episode: 60/780 \t Total reward: -21.0 \t Memory length : 57078\n",
            "Total steps: 75436 \t Episode: 80/1039 \t Total reward: -19.0 \t Memory length : 75436\n",
            "Total steps: 92711 \t Episode: 100/759 \t Total reward: -21.0 \t Memory length : 92711\n",
            "Total steps: 109962 \t Episode: 120/754 \t Total reward: -21.0 \t Memory length : 109962\n",
            "Total steps: 127409 \t Episode: 140/804 \t Total reward: -21.0 \t Memory length : 127409\n",
            "Total steps: 144333 \t Episode: 160/807 \t Total reward: -21.0 \t Memory length : 144333\n",
            "Total steps: 161528 \t Episode: 180/779 \t Total reward: -21.0 \t Memory length : 161528\n",
            "Total steps: 178687 \t Episode: 200/812 \t Total reward: -21.0 \t Memory length : 178687\n",
            "Total steps: 195027 \t Episode: 220/867 \t Total reward: -21.0 \t Memory length : 195027\n",
            "Total steps: 211506 \t Episode: 240/760 \t Total reward: -21.0 \t Memory length : 211506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BmRAJhX6W0h",
        "outputId": "00ca2316-36f7-4f19-eafa-50f3d1cf03f5"
      },
      "source": [
        "#policy_net = torch.load('dqn_pong_model')\n",
        "test(env, 1, policy_net, render=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished Episode 0 with reward 230.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtYFJXJftopf"
      },
      "source": [
        "value_tensor_DDQN = np.array(val_tensor_DDQN)\n",
        "value_tensor_DQN = np.array(val_tensor_DQN)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "LHEx2WCkfl9t",
        "outputId": "c72ec70e-038d-4352-c420-7adf55f9dfc8"
      },
      "source": [
        "import colorlover as cl\n",
        "import plotly.graph_objects as go\n",
        "colors = cl.scales['5']['qual']['Set1']\n",
        "\n",
        "fig = go.Figure([\n",
        "    go.Scatter(\n",
        "        name='Double Deep Q Networks with priority sampling',\n",
        "        x=np.arange(len(value_tensor_DDQN[:,0]))*1000,\n",
        "        y=value_tensor_DDQN[:,0],\n",
        "        mode='lines',\n",
        "        line=dict(color=colors[0], width = 2),\n",
        "    ),\n",
        "    go.Scatter(\n",
        "        name='Upper Bound',\n",
        "        x=np.arange(len(value_tensor_DDQN[:,0]))*1000,\n",
        "        y=value_tensor_DDQN[:,0]+(value_tensor_DDQN[:,1])*np.sqrt(10000-1),\n",
        "        mode='lines',\n",
        "        marker=dict(color=\"#444\"),\n",
        "        line=dict(width=0),\n",
        "        showlegend=False\n",
        "    ),\n",
        "    go.Scatter(\n",
        "        name='Lower Bound',\n",
        "        x=np.arange(len(value_tensor_DDQN[:,0]))*1000,\n",
        "        y=value_tensor_DDQN[:,0]-(value_tensor_DDQN[:,1])*np.sqrt(10000-1),\n",
        "        marker=dict(color=\"#444\"),\n",
        "        line=dict(width=0),\n",
        "        mode='lines',\n",
        "        fillcolor='rgba(68, 68, 68, 0.3)',\n",
        "        fill='tonexty',\n",
        "        showlegend=False\n",
        "    ),\n",
        "        go.Scatter(\n",
        "        name='Double Deep Q Networks with uniform sampling',\n",
        "        x=np.arange(len(value_tensor_DQN[:,0]))*1000,\n",
        "        y=value_tensor_DQN[:,0],\n",
        "        mode='lines',\n",
        "        line=dict(color=colors[1], width = 2),\n",
        "    ),\n",
        "    go.Scatter(\n",
        "        name='Upper Bound',\n",
        "        x=np.arange(len(value_tensor_DQN[:,0]))*1000,\n",
        "        y=value_tensor_DQN[:,0]+(value_tensor_DQN[:,1])*np.sqrt(10000-1),\n",
        "        mode='lines',\n",
        "        marker=dict(color=\"#444\"),\n",
        "        line=dict(width=0),\n",
        "        showlegend=False\n",
        "    ),\n",
        "    go.Scatter(\n",
        "        name='Lower Bound',\n",
        "        x=np.arange(len(value_tensor_DQN[:,0]))*1000,\n",
        "        y=value_tensor_DQN[:,0]-(value_tensor_DQN[:,1])*np.sqrt(10000-1),\n",
        "        marker=dict(color=\"#444\"),\n",
        "        line=dict(width=0),\n",
        "        mode='lines',\n",
        "        fillcolor='rgba(68, 68, 68, 0.3)',\n",
        "        fill='tonexty',\n",
        "        showlegend=False\n",
        "    )\n",
        "])\n",
        "\n",
        "fig.update_layout(\n",
        "    yaxis_title='Avg. Value Estimate (greedy policy)',\n",
        "    title='Estimation Bias in Deep Q networks',\n",
        "    hovermode=\"x\",\n",
        "    paper_bgcolor = 'rgba(0,0,0,0)',\n",
        "    plot_bgcolor = 'rgba(0,0,0,0)',\n",
        "    font = dict(size = 16, color = 'black'),\n",
        "    width = 900,\n",
        "    height = 500\n",
        ")\n",
        "fig.update_xaxes(title = 'Time steps', showgrid=True, gridwidth=1.5, gridcolor='#DFDFDF', showline=True, linecolor = '#AFAFAF', linewidth = 2.5, nticks = 7)\n",
        "fig.update_yaxes(showgrid=True, gridwidth=1.5,gridcolor='#DFDFDF', showline=True, linecolor = '#AFAFAF', linewidth = 2.5, nticks = 7)\n",
        "fig.show()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"8e20b8df-3d4b-4ef7-97ea-22f7b3581e94\" class=\"plotly-graph-div\" style=\"height:500px; width:900px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"8e20b8df-3d4b-4ef7-97ea-22f7b3581e94\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '8e20b8df-3d4b-4ef7-97ea-22f7b3581e94',\n",
              "                        [{\"line\": {\"color\": \"rgb(228,26,28)\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"Double Deep Q Networks with priority sampling\", \"type\": \"scatter\", \"x\": [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000, 21000, 22000, 23000, 24000, 25000, 26000, 27000, 28000, 29000, 30000, 31000, 32000, 33000, 34000, 35000, 36000, 37000, 38000, 39000, 40000, 41000, 42000, 43000, 44000, 45000, 46000, 47000, 48000, 49000, 50000, 51000, 52000, 53000, 54000, 55000, 56000, 57000, 58000, 59000, 60000, 61000, 62000, 63000, 64000, 65000, 66000, 67000, 68000, 69000, 70000, 71000, 72000, 73000, 74000, 75000, 76000, 77000, 78000, 79000, 80000, 81000, 82000, 83000, 84000, 85000, 86000, 87000, 88000, 89000, 90000, 91000, 92000, 93000, 94000, 95000, 96000, 97000, 98000, 99000, 100000, 101000, 102000, 103000, 104000, 105000, 106000, 107000, 108000, 109000, 110000, 111000, 112000, 113000, 114000, 115000, 116000, 117000, 118000, 119000, 120000, 121000, 122000, 123000, 124000, 125000, 126000, 127000, 128000, 129000, 130000, 131000, 132000, 133000, 134000, 135000, 136000, 137000, 138000, 139000, 140000, 141000, 142000, 143000, 144000, 145000, 146000, 147000, 148000, 149000, 150000, 151000, 152000, 153000, 154000, 155000, 156000, 157000, 158000, 159000, 160000, 161000, 162000, 163000, 164000, 165000, 166000, 167000, 168000, 169000, 170000, 171000, 172000, 173000, 174000, 175000, 176000, 177000, 178000, 179000, 180000, 181000, 182000, 183000, 184000, 185000, 186000, 187000, 188000, 189000, 190000, 191000, 192000, 193000, 194000, 195000, 196000, 197000, 198000, 199000, 200000, 201000, 202000, 203000, 204000, 205000, 206000, 207000, 208000, 209000, 210000, 211000, 212000, 213000, 214000, 215000, 216000, 217000, 218000, 219000, 220000, 221000, 222000, 223000, 224000, 225000, 226000, 227000, 228000], \"y\": [0.10481864413087989, 0.10885312435896816, 0.09892229461473619, 0.11575628973473355, 0.1028063697575467, 0.11113590197341795, 0.10871105225921246, 0.11069867855935983, 0.10393301600737072, 0.10503646550900013, 0.10337617765393366, 0.11158001403951386, 0.10803637556920323, 0.10245007539957665, 0.10567148235440255, 0.11265607428197798, 0.1098136161310426, 0.09865770954513035, 0.1044333218747901, 0.1037091323784713, 0.09261052313018335, 0.10432353570420098, 0.10215272603466385, 0.09840846272479546, 0.09611397802981796, 0.1034836728048469, 0.11450045947269134, 0.09589853428093661, 0.1166189487641852, 0.09164289935407313, 0.11339476702307336, 0.10239595368998876, 0.10827058137111042, 0.11147540714025014, 0.11291093217656795, 0.11449829155238092, 0.10772537259555766, 0.1113548310674221, 0.11306989061625122, 0.10797473571237622, 0.08516731921752746, 0.09971039835363626, 0.09687892415306786, 0.1042724548983322, 0.09857531815456848, 0.11231577304030253, 0.11064963092245585, 0.1004166378868076, 0.11202600580553451, 0.11028203325516316, 0.10506748890192369, 0.10915895598331858, 0.10878874531545497, 0.10616741652100857, 0.1032964518526569, 0.09778718181255766, 0.09433167465624819, 0.09824574609912438, 0.1148469762568523, 0.1138052813453125, 0.10465143171407408, 0.11283041889200339, 0.1072817804073009, 0.10283384138816282, 0.10485308769751679, 0.10189756845124066, 0.10625085434964243, 0.10518792190402747, 0.10494167568243068, 0.10136009256530087, 0.11477918274366722, 0.11309456127611074, 0.11466402733673202, 0.11108050567444659, 0.10995431049515555, 0.09147594757378101, 0.10274894229239888, 0.10930590858002623, 0.10710019851545229, 0.10726996228863307, 0.11195934415635975, 0.10404589450453051, 0.09329483937472105, 0.10447913698107004, 0.10521172548749336, 0.10803338528449576, 0.09024075340818274, 0.08926001169081581, 0.10560071670634162, 0.10512077740920142, 0.11023992961725158, 0.1102658766509467, 0.10569895989530027, 0.11152394892360788, 0.10982067005062013, 0.10349015140125895, 0.10033848861527771, 0.10090325819385564, 0.11136869358117173, 0.11150565849634532, 0.10557227105516748, 0.10454834744959444, 0.11076938313599981, 0.11413024768132615, 0.10270660729659797, 0.11229740699606114, 0.11539292566978378, 0.11243557839150556, 0.10754933185181945, 0.09508364017497986, 0.08941600793972611, 0.10827823731590781, 0.10636801186125823, 0.09758564090776828, 0.11481603961911495, 0.10644968424327253, 0.1148044297990654, 0.10874028566252049, 0.09962874663169266, 0.11214583367109299, 0.09358723795948884, 0.10211813395475819, 0.104059084918625, 0.11323468321158241, 0.10952843627906941, 0.12072933325290923, 0.10598162739750064, 0.0919120111144506, 0.10925910229859657, 0.11535942608673798, 0.10995489682555815, 0.10540179992863617, 0.10177821046028762, 0.10411869432684293, 0.10853088532433365, 0.09886627623604403, 0.08684276714920998, 0.09051809986073946, 0.10137851767593604, 0.11104336239605538, 0.11126314240891494, 0.1116884433363955, 0.10688785950946256, 0.10266620597304708, 0.1305824425071478, 0.09076535906148168, 0.10980635320302098, 0.1035975485670665, 0.10234552303000408, 0.11164527342498931, 0.10483999135097963, 0.10436997704819781, 0.1151547691941096, 0.09455733632911807, 0.10743247682228685, 0.09335483622092466, 0.10829998086275602, 0.10464760548562455, 0.11105885443914877, 0.10055079431141783, 0.10986635063548023, 0.09694632931395934, 0.09190473063238735, 0.10474037379026413, 0.1041640345113618, 0.11684679477563444, 0.10008674234652119, 0.11262021838716321, 0.10972971587987809, 0.10053897298723145, 0.08724016941493691, 0.09193004874512553, 0.0895438122309067, 0.10959698429889977, 0.10665661651967433, 0.09212565583565945, 0.08328830349174413, 0.09471214956073003, 0.09837958848935303, 0.10579316972269992, 0.10399055225266651, 0.09833895336263455, 0.10690509804905696, 0.10873621394857765, 0.10357938322328752, 0.12057601846754551, 0.10662260926550343, 0.11099063358517085, 0.10484431836599144, 0.10547643017498452, 0.10647130419328735, 0.10025656132855064, 0.09805157551793356, 0.11232583331580781, 0.09636837244033813, 0.11487592057030845, 0.10433574359898173, 0.11090242317586671, 0.10301357415422016, 0.10323921701859069, 0.10136794343777, 0.10609983230668883, 0.11188451923630045, 0.0941332641769858, 0.09357308983802795, 0.09878822691293794, 0.1081475277944487, 0.09891099594433302, 0.10942706422737011, 0.1059140254612137, 0.10688893453218043, 0.1135481715867979, 0.09763376730942416, 0.10396385841149419, 0.10878768607758944, 0.10976581388429084, 0.11324719596942166, 0.09680302897962093, 0.11370973069603581, 0.10308203637006058, 0.11455621809784508, 0.0982201499760594, 0.09841830818913877, 0.09911967746791292, 0.11006427363204797, 0.11124845690085974, 0.1078285537317627, 0.1100891692682881, 0.11552888427162543]}, {\"line\": {\"width\": 0}, \"marker\": {\"color\": \"#444\"}, \"mode\": \"lines\", \"name\": \"Upper Bound\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000, 21000, 22000, 23000, 24000, 25000, 26000, 27000, 28000, 29000, 30000, 31000, 32000, 33000, 34000, 35000, 36000, 37000, 38000, 39000, 40000, 41000, 42000, 43000, 44000, 45000, 46000, 47000, 48000, 49000, 50000, 51000, 52000, 53000, 54000, 55000, 56000, 57000, 58000, 59000, 60000, 61000, 62000, 63000, 64000, 65000, 66000, 67000, 68000, 69000, 70000, 71000, 72000, 73000, 74000, 75000, 76000, 77000, 78000, 79000, 80000, 81000, 82000, 83000, 84000, 85000, 86000, 87000, 88000, 89000, 90000, 91000, 92000, 93000, 94000, 95000, 96000, 97000, 98000, 99000, 100000, 101000, 102000, 103000, 104000, 105000, 106000, 107000, 108000, 109000, 110000, 111000, 112000, 113000, 114000, 115000, 116000, 117000, 118000, 119000, 120000, 121000, 122000, 123000, 124000, 125000, 126000, 127000, 128000, 129000, 130000, 131000, 132000, 133000, 134000, 135000, 136000, 137000, 138000, 139000, 140000, 141000, 142000, 143000, 144000, 145000, 146000, 147000, 148000, 149000, 150000, 151000, 152000, 153000, 154000, 155000, 156000, 157000, 158000, 159000, 160000, 161000, 162000, 163000, 164000, 165000, 166000, 167000, 168000, 169000, 170000, 171000, 172000, 173000, 174000, 175000, 176000, 177000, 178000, 179000, 180000, 181000, 182000, 183000, 184000, 185000, 186000, 187000, 188000, 189000, 190000, 191000, 192000, 193000, 194000, 195000, 196000, 197000, 198000, 199000, 200000, 201000, 202000, 203000, 204000, 205000, 206000, 207000, 208000, 209000, 210000, 211000, 212000, 213000, 214000, 215000, 216000, 217000, 218000, 219000, 220000, 221000, 222000, 223000, 224000, 225000, 226000, 227000, 228000], \"y\": [0.14684261902236267, 0.14773382670031615, 0.13253040022928755, 0.15984024902622723, 0.13648671681101582, 0.15413939320473982, 0.15077607731907863, 0.14680925095009223, 0.14557273285829753, 0.1428809951878366, 0.14315272057231415, 0.1551546172178275, 0.14934772643728353, 0.13766968943063473, 0.14859828119462812, 0.1555161292520456, 0.14952202867095715, 0.13429122569241803, 0.14409021440837436, 0.1339879499877723, 0.13106527892996445, 0.14439429170231244, 0.1369495292970121, 0.131879664878587, 0.12650024982294492, 0.14303840363527912, 0.15630852992971242, 0.13134258149733424, 0.1587917668440775, 0.1276620879881121, 0.1538313580633437, 0.14357238759457133, 0.1471183277392713, 0.15259648526343686, 0.15661675991385668, 0.15410109924647453, 0.1447836892150155, 0.15151837895188885, 0.1563449069418452, 0.14645426559988567, 0.11418711330954848, 0.12814074087060906, 0.1370208640622363, 0.1415728037047643, 0.1336360696707194, 0.1513132874442087, 0.15369175545713998, 0.13886248513654031, 0.15239744576905792, 0.15107293391730184, 0.14737834150595994, 0.14953534775984428, 0.14769834079033103, 0.14178318857096264, 0.14009452534476757, 0.1327447139397232, 0.130123484567025, 0.13657670457589682, 0.1578256953254874, 0.15415390450427716, 0.14001240697091297, 0.15342616746158044, 0.1429646637654569, 0.13899528910565115, 0.1359126279662926, 0.13792751090317446, 0.14606717841258438, 0.14455197617856336, 0.14316622955059563, 0.13912776852485165, 0.15530072034329773, 0.15235355647829185, 0.1559812642098551, 0.15166553468706703, 0.14799327348462324, 0.12562162589782516, 0.14954320424738488, 0.15200344303150995, 0.14578421310307418, 0.14681094895651758, 0.15392739383702464, 0.1445032876737647, 0.12190590049262663, 0.1463033224981139, 0.1380214334382831, 0.14884238845847741, 0.12054575357282826, 0.13087929799685472, 0.14758319554018218, 0.14116868252471027, 0.15158879465105488, 0.15005324365841968, 0.1441487910317367, 0.15076689911080599, 0.14845490468991335, 0.14398323296458482, 0.1374012546561306, 0.13881938679673875, 0.1501638056425857, 0.1511240736730095, 0.1479552186199176, 0.14927758554938422, 0.1524584136538627, 0.15279644878457685, 0.1376676078575117, 0.1538746676285677, 0.15932917718257505, 0.15494443027260404, 0.15048151082384625, 0.127725516703875, 0.125132194868272, 0.14805052271567112, 0.13938860829706182, 0.13691455881632547, 0.15798622255821718, 0.14426044135679472, 0.15699307677066393, 0.14946821780668745, 0.12683044052307318, 0.13542845734827022, 0.12740641905135183, 0.14287634021677734, 0.14007685760939123, 0.1595555184008481, 0.1535498609309889, 0.16277381578964042, 0.1425257129303388, 0.13025814907705857, 0.14859618761781115, 0.16008697962260202, 0.15539341781439844, 0.14733390244582753, 0.13698456350832577, 0.14260600421810293, 0.15026213269401967, 0.12657047338467478, 0.12147602148493998, 0.12287309101842411, 0.14057017303821662, 0.15129078753002592, 0.150457237262273, 0.15243524985886037, 0.14739562462945396, 0.13748502854842481, 0.15510758436233768, 0.1248139363564856, 0.15288891432785295, 0.14484022841242009, 0.1430109093662182, 0.15595529808873862, 0.14258715683191384, 0.14658025824904153, 0.15930726100354742, 0.1251491736639145, 0.1459540449370607, 0.12608623877707847, 0.15169682243127056, 0.14340321972109538, 0.14994810524826296, 0.13600145261258334, 0.14729741823497708, 0.13078205332155568, 0.1288466695782761, 0.1338491523616791, 0.1455813593910617, 0.15828851028082472, 0.13711469561853099, 0.15422781121471282, 0.1503918268148283, 0.13716309013629877, 0.11970274514735206, 0.13293112659414685, 0.12311586198163645, 0.1493598594109024, 0.14867130369373954, 0.12474932414572093, 0.1167716246840069, 0.13069624278604733, 0.13443524993447298, 0.14709733772208702, 0.1415134223021079, 0.13508008074699032, 0.1479768681010705, 0.1456155222016927, 0.13721953901923822, 0.13889899083651766, 0.1470877264967513, 0.15092340512395389, 0.14163061534661314, 0.14439381888760772, 0.14613947507711, 0.13844452975769983, 0.13612262967287722, 0.15382439044979362, 0.12549396006581343, 0.15785043073858104, 0.1434482618376924, 0.15137347335324583, 0.1440624077053162, 0.14581498975231139, 0.14015689065941633, 0.14704774894500383, 0.1544745916109887, 0.13003435575575784, 0.12924721110241294, 0.1349395660293432, 0.1492082979247782, 0.13521297337400454, 0.1514035118974687, 0.1459671178743625, 0.14795032934879776, 0.15424676687350758, 0.13431672370899217, 0.14446493078968037, 0.14843354349845247, 0.14984545609086378, 0.15612544608943296, 0.13954528276962375, 0.15487480779335588, 0.1443289128422913, 0.15509930697427557, 0.13526443073179242, 0.1264624946957264, 0.1300010993187634, 0.15100987967344331, 0.1514133767992913, 0.1480680061388823, 0.1488073619272512, 0.1543441710183886]}, {\"fill\": \"tonexty\", \"fillcolor\": \"rgba(68, 68, 68, 0.3)\", \"line\": {\"width\": 0}, \"marker\": {\"color\": \"#444\"}, \"mode\": \"lines\", \"name\": \"Lower Bound\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000, 21000, 22000, 23000, 24000, 25000, 26000, 27000, 28000, 29000, 30000, 31000, 32000, 33000, 34000, 35000, 36000, 37000, 38000, 39000, 40000, 41000, 42000, 43000, 44000, 45000, 46000, 47000, 48000, 49000, 50000, 51000, 52000, 53000, 54000, 55000, 56000, 57000, 58000, 59000, 60000, 61000, 62000, 63000, 64000, 65000, 66000, 67000, 68000, 69000, 70000, 71000, 72000, 73000, 74000, 75000, 76000, 77000, 78000, 79000, 80000, 81000, 82000, 83000, 84000, 85000, 86000, 87000, 88000, 89000, 90000, 91000, 92000, 93000, 94000, 95000, 96000, 97000, 98000, 99000, 100000, 101000, 102000, 103000, 104000, 105000, 106000, 107000, 108000, 109000, 110000, 111000, 112000, 113000, 114000, 115000, 116000, 117000, 118000, 119000, 120000, 121000, 122000, 123000, 124000, 125000, 126000, 127000, 128000, 129000, 130000, 131000, 132000, 133000, 134000, 135000, 136000, 137000, 138000, 139000, 140000, 141000, 142000, 143000, 144000, 145000, 146000, 147000, 148000, 149000, 150000, 151000, 152000, 153000, 154000, 155000, 156000, 157000, 158000, 159000, 160000, 161000, 162000, 163000, 164000, 165000, 166000, 167000, 168000, 169000, 170000, 171000, 172000, 173000, 174000, 175000, 176000, 177000, 178000, 179000, 180000, 181000, 182000, 183000, 184000, 185000, 186000, 187000, 188000, 189000, 190000, 191000, 192000, 193000, 194000, 195000, 196000, 197000, 198000, 199000, 200000, 201000, 202000, 203000, 204000, 205000, 206000, 207000, 208000, 209000, 210000, 211000, 212000, 213000, 214000, 215000, 216000, 217000, 218000, 219000, 220000, 221000, 222000, 223000, 224000, 225000, 226000, 227000, 228000], \"y\": [0.06279466923939711, 0.06997242201762016, 0.06531418900018482, 0.07167233044323987, 0.06912602270407757, 0.06813241074209608, 0.06664602719934629, 0.07458810616862743, 0.0622932991564439, 0.06719193583016368, 0.06359963473555316, 0.06800541086120021, 0.06672502470112293, 0.06723046136851857, 0.06274468351417697, 0.06979601931191036, 0.07010520359112804, 0.0630241933978427, 0.06477642934120584, 0.07343031476917031, 0.05415576733040225, 0.06425277970608954, 0.06735592277231561, 0.06493726057100394, 0.065727706236691, 0.06392894197441468, 0.07269238901567027, 0.060454487064539, 0.0744461306842929, 0.05562371072003416, 0.07295817598280302, 0.06121951978540618, 0.06942283500294956, 0.07035432901706343, 0.06920510443927921, 0.07489548385828732, 0.07066705597609983, 0.07119128318295534, 0.06979487429065726, 0.06949520582486678, 0.05614752512550644, 0.07128005583666347, 0.05673698424389943, 0.0669721060919001, 0.06351456663841756, 0.07331825863639638, 0.06760750638777172, 0.061970790637074884, 0.0716545658420111, 0.06949113259302447, 0.06275663629788744, 0.06878256420679289, 0.06987914984057891, 0.0705516444710545, 0.06649837836054624, 0.0628296496853921, 0.05853986474547138, 0.05991478762235195, 0.07186825718821721, 0.07345665818634783, 0.0692904564572352, 0.07223467032242634, 0.07159889704914486, 0.06667239367067448, 0.07379354742874097, 0.06586762599930686, 0.06643453028670047, 0.06582386762949158, 0.06671712181426573, 0.0635924166057501, 0.07425764514403671, 0.07383556607392965, 0.07334679046360892, 0.07049547666182615, 0.07191534750568787, 0.057330269249736845, 0.05595468033741287, 0.06660837412854251, 0.06841618392783039, 0.06772897562074856, 0.06999129447569485, 0.06358850133529634, 0.06468377825681547, 0.0626549514640262, 0.07240201753670361, 0.0672243821105141, 0.059935753243537226, 0.04764072538477689, 0.06361823787250105, 0.06907287229369256, 0.06889106458344829, 0.07047850964347371, 0.06724912875886385, 0.07228099873640978, 0.07118643541132692, 0.06299706983793307, 0.06327572257442482, 0.06298712959097252, 0.07257358151975778, 0.07188724331968112, 0.06318932349041737, 0.05981910934980466, 0.06908035261813691, 0.07546404657807546, 0.06774560673568425, 0.07072014636355459, 0.0714566741569925, 0.06992672651040707, 0.06461715287979264, 0.06244176364608473, 0.0536998210111802, 0.0685059519161445, 0.07334741542545464, 0.0582567229992111, 0.07164585668001272, 0.06863892712975034, 0.07261578282746688, 0.06801235351835352, 0.07242705274031214, 0.08886320999391577, 0.05976805686762584, 0.06135992769273905, 0.06804131222785878, 0.0669138480223167, 0.06550701162714992, 0.07868485071617803, 0.06943754186466247, 0.05356587315184262, 0.069922016979382, 0.07063187255087394, 0.06451637583671785, 0.06346969741144481, 0.06657185741224948, 0.06563138443558292, 0.06679963795464763, 0.07116207908741327, 0.05220951281347998, 0.0581631087030548, 0.06218686231365546, 0.07079593726208483, 0.07206904755555688, 0.07094163681393062, 0.06638009438947115, 0.06784738339766935, 0.1060573006519579, 0.05671678176647776, 0.06672379207818901, 0.062354868721712926, 0.06168013669378998, 0.06733524876124, 0.06709282587004542, 0.06215969584735409, 0.07100227738467177, 0.06396549899432163, 0.06891090870751299, 0.06062343366477084, 0.06490313929424149, 0.06589199125015373, 0.07216960363003458, 0.06510013601025233, 0.07243528303598337, 0.063110605306363, 0.05496279168649862, 0.07563159521884916, 0.0627467096316619, 0.07540507927044415, 0.0630587890745114, 0.0710126255596136, 0.06906760494492789, 0.06391485583816414, 0.05477759368252176, 0.0509289708961042, 0.05597176248017695, 0.06983410918689714, 0.06464192934560911, 0.05950198752559795, 0.04980498229948136, 0.05872805633541272, 0.0623239270442331, 0.06448900172331282, 0.06646768220322512, 0.06159782597827878, 0.06583332799704342, 0.0718569056954626, 0.06993922742733681, 0.10225304609857334, 0.06615749203425556, 0.07105786204638781, 0.06805802138536975, 0.06655904146236132, 0.0668031333094647, 0.062068592899401455, 0.05998052136298989, 0.070827276181822, 0.06724278481486286, 0.07190141040203585, 0.06522322536027106, 0.07043137299848759, 0.061964740603124124, 0.06066344428487001, 0.06257899621612367, 0.06515191566837383, 0.06929444686161222, 0.05823217259821375, 0.057898968573642975, 0.06263688779653268, 0.0670867576641192, 0.0626090185146615, 0.06745061655727151, 0.06586093304806491, 0.06582753971556311, 0.07284957630008825, 0.060950810909856164, 0.06346278603330802, 0.06914182865672641, 0.0696861716777179, 0.07036894584941036, 0.05406077518961809, 0.07254465359871574, 0.06183515989782986, 0.07401312922141459, 0.06117586922032639, 0.07037412168255114, 0.06823825561706243, 0.06911866759065265, 0.0710835370024282, 0.0675891013246431, 0.07137097660932501, 0.07671359752486225]}, {\"line\": {\"color\": \"rgb(55,126,184)\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"Double Deep Q Networks with uniform sampling\", \"type\": \"scatter\", \"x\": [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000, 21000, 22000, 23000, 24000, 25000, 26000, 27000, 28000, 29000, 30000, 31000, 32000, 33000, 34000, 35000, 36000, 37000, 38000, 39000, 40000, 41000, 42000, 43000, 44000, 45000, 46000, 47000, 48000, 49000, 50000, 51000, 52000, 53000, 54000, 55000, 56000, 57000, 58000, 59000, 60000, 61000, 62000, 63000, 64000, 65000, 66000, 67000, 68000, 69000, 70000, 71000, 72000, 73000, 74000, 75000, 76000, 77000, 78000, 79000, 80000, 81000, 82000, 83000, 84000, 85000, 86000, 87000, 88000, 89000, 90000, 91000, 92000, 93000, 94000, 95000, 96000, 97000, 98000, 99000, 100000, 101000, 102000, 103000, 104000, 105000, 106000, 107000, 108000, 109000, 110000, 111000, 112000, 113000, 114000, 115000, 116000, 117000, 118000, 119000, 120000, 121000, 122000, 123000, 124000, 125000, 126000, 127000, 128000, 129000, 130000, 131000, 132000, 133000, 134000, 135000, 136000, 137000, 138000, 139000, 140000, 141000, 142000, 143000, 144000, 145000, 146000, 147000, 148000, 149000, 150000, 151000, 152000, 153000, 154000, 155000, 156000, 157000, 158000, 159000, 160000, 161000, 162000, 163000, 164000, 165000, 166000, 167000, 168000, 169000, 170000, 171000, 172000, 173000, 174000, 175000, 176000, 177000, 178000, 179000, 180000, 181000, 182000, 183000, 184000, 185000, 186000, 187000, 188000, 189000, 190000, 191000, 192000, 193000, 194000, 195000, 196000, 197000, 198000, 199000, 200000, 201000, 202000, 203000, 204000, 205000, 206000, 207000, 208000, 209000, 210000, 211000, 212000, 213000, 214000, 215000, 216000, 217000], \"y\": [0.18352412283420563, 0.17079494296578887, 0.18362716472730403, 0.17686183750629425, 0.18104077194723786, 0.18660773470659148, 0.18146813800669057, 0.1749856640319808, 0.18450396349084391, 0.1752867647630023, 0.19129548850552544, 0.17871550188014843, 0.18894785832122835, 0.17884332260807154, 0.1833485303253963, 0.17729321141438237, 0.1726531081304357, 0.18571153129334975, 0.1803208520227575, 0.1747552467296358, 0.17944373716103848, 0.18864655182462373, 0.17834659181904083, 0.1873182076812738, 0.17555057993296333, 0.18094946942344814, 0.18368980843820476, 0.1826669437965999, 0.1771526804436808, 0.17842797827571164, 0.17947180328696077, 0.17467644047627057, 0.18667681921612134, 0.17513894020896598, 0.1791184155745545, 0.1778767955888595, 0.1785661356287752, 0.17501770904553787, 0.17860608359409533, 0.19024267409865564, 0.18759063617203003, 0.17904031727558528, 0.1921176114332965, 0.1840534919970914, 0.17640573107222518, 0.17620358004345807, 0.18049657608692846, 0.18326600158171166, 0.1764058592719036, 0.1800106400710957, 0.1825107426528471, 0.17775213805007012, 0.17776673093779397, 0.17878086452974992, 0.18222404477747892, 0.17950161383866486, 0.1772406174513812, 0.1829758810602662, 0.17498116439039058, 0.19558513128469068, 0.19495416998118162, 0.17920234663208492, 0.18152645311062843, 0.1792418085417505, 0.18746800349652767, 0.17530227811580681, 0.17613493787205736, 0.1768928334527349, 0.18344487518072128, 0.18148560646093553, 0.18527828927697806, 0.1702959755141484, 0.16968169905871988, 0.18557933602676632, 0.17937476469191493, 0.17520993591306058, 0.17743308622700063, 0.18446358102412264, 0.17875621955870657, 0.17416998106790216, 0.1769608091450099, 0.1772086736640081, 0.17818464093305023, 0.17746972393318516, 0.19016208453860195, 0.19156770481769478, 0.1797412154535768, 0.17929874566301263, 0.17434678103549195, 0.18439453387396998, 0.18082646107673644, 0.18611542272324466, 0.17263609526685364, 0.1736970886113715, 0.1748620096053786, 0.1735500082569687, 0.1753605036592146, 0.17537901411412662, 0.17565498130876314, 0.17722049999208608, 0.17519067744172453, 0.1823918371152269, 0.17787254764698446, 0.17125663152301168, 0.1876404098787036, 0.1773098291366301, 0.17747104610684963, 0.1818420164937756, 0.18151479238415627, 0.19181259211740995, 0.18012700998500403, 0.1760552028941019, 0.17549285758872452, 0.1770835288726123, 0.1768953500129552, 0.17604397557849108, 0.1787391999982438, 0.18440852794382306, 0.18641693371215037, 0.19104531583460896, 0.17516364073249654, 0.18311823472081118, 0.1797155180528503, 0.17516957096908076, 0.18291338266276602, 0.17645467367707465, 0.17424881569288594, 0.18685629667616535, 0.17719817935142546, 0.18447412669292987, 0.18648732205231985, 0.17565206998399088, 0.17575675070111174, 0.17952973481213558, 0.18440141229147322, 0.18618548823306796, 0.1742071038068727, 0.17875105441821554, 0.17852446912009207, 0.17669424949411336, 0.1777907483340279, 0.17931571186587797, 0.1733885644833102, 0.17460890887599242, 0.17538735845769898, 0.1714469939470291, 0.17593851204841368, 0.1795320105711384, 0.17357865874242934, 0.18129339993399587, 0.1796205677290229, 0.17568540505387567, 0.1906198717802763, 0.18032492977089998, 0.18070731659730274, 0.17472625608151815, 0.1792426913398785, 0.17842209618173394, 0.1787067113573698, 0.19010485882560413, 0.17111956747987914, 0.17479472073836852, 0.1757442666914876, 0.18141013491573868, 0.1845903427977311, 0.17782879296021584, 0.17304969114020355, 0.17443807560461339, 0.1796203725727419, 0.1776344626877278, 0.18516972044418598, 0.17632409386391187, 0.1759345283513127, 0.17779155364902804, 0.19111917073330606, 0.18646479666233062, 0.18553088949620725, 0.1730438353168586, 0.17082642185421418, 0.178300368414674, 0.172253094210818, 0.18005493030233202, 0.17553383957224283, 0.1737140249038977, 0.17585369996237057, 0.17774553982059607, 0.1813537898388776, 0.18223616058627765, 0.1749850600026548, 0.17769781463327838, 0.1748402614294636, 0.17099935350773846, 0.1771809726151461, 0.17960938743796925, 0.17890399482708055, 0.17184320389281346, 0.17445212973291008, 0.18495535110587516, 0.17489266123854474, 0.1786497441488643, 0.1767103392048739, 0.17870003070150103, 0.17852623510886642, 0.1739409857815172, 0.17918218830628863, 0.18791013004931997, 0.17436714641383436, 0.1772645087074047, 0.17990005536461776, 0.1768060028553009, 0.17306722209734074, 0.17611480410765057, 0.17639949936799856, 0.17413858183253528, 0.17785401455251684, 0.17418165242424902, 0.17862003313663077, 0.17480977407502168]}, {\"line\": {\"width\": 0}, \"marker\": {\"color\": \"#444\"}, \"mode\": \"lines\", \"name\": \"Upper Bound\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000, 21000, 22000, 23000, 24000, 25000, 26000, 27000, 28000, 29000, 30000, 31000, 32000, 33000, 34000, 35000, 36000, 37000, 38000, 39000, 40000, 41000, 42000, 43000, 44000, 45000, 46000, 47000, 48000, 49000, 50000, 51000, 52000, 53000, 54000, 55000, 56000, 57000, 58000, 59000, 60000, 61000, 62000, 63000, 64000, 65000, 66000, 67000, 68000, 69000, 70000, 71000, 72000, 73000, 74000, 75000, 76000, 77000, 78000, 79000, 80000, 81000, 82000, 83000, 84000, 85000, 86000, 87000, 88000, 89000, 90000, 91000, 92000, 93000, 94000, 95000, 96000, 97000, 98000, 99000, 100000, 101000, 102000, 103000, 104000, 105000, 106000, 107000, 108000, 109000, 110000, 111000, 112000, 113000, 114000, 115000, 116000, 117000, 118000, 119000, 120000, 121000, 122000, 123000, 124000, 125000, 126000, 127000, 128000, 129000, 130000, 131000, 132000, 133000, 134000, 135000, 136000, 137000, 138000, 139000, 140000, 141000, 142000, 143000, 144000, 145000, 146000, 147000, 148000, 149000, 150000, 151000, 152000, 153000, 154000, 155000, 156000, 157000, 158000, 159000, 160000, 161000, 162000, 163000, 164000, 165000, 166000, 167000, 168000, 169000, 170000, 171000, 172000, 173000, 174000, 175000, 176000, 177000, 178000, 179000, 180000, 181000, 182000, 183000, 184000, 185000, 186000, 187000, 188000, 189000, 190000, 191000, 192000, 193000, 194000, 195000, 196000, 197000, 198000, 199000, 200000, 201000, 202000, 203000, 204000, 205000, 206000, 207000, 208000, 209000, 210000, 211000, 212000, 213000, 214000, 215000, 216000, 217000], \"y\": [0.20854354812156772, 0.2037169554146345, 0.22131774781202587, 0.21190902620301783, 0.21804801320911013, 0.21962225164033516, 0.21671291842050142, 0.20661921809127143, 0.2197324926050923, 0.2068059056092082, 0.2229686491322515, 0.21552819018309588, 0.2226638658996324, 0.2122457240977615, 0.21681022212026413, 0.2172335978191165, 0.20670765065165747, 0.22379510371413486, 0.21465149412238435, 0.211096153909675, 0.21128369722432758, 0.22646883937526033, 0.21314175078829833, 0.22244870301182643, 0.2108839075629986, 0.21470891188444258, 0.21835516675598393, 0.21997766479815684, 0.2145931800962237, 0.21225749059432944, 0.21495428369244296, 0.2036741867616111, 0.21106616128951813, 0.21251189387324168, 0.21394280129693466, 0.2139438637938577, 0.2125868104082901, 0.20971865410293353, 0.21593918936446932, 0.22216311424645732, 0.22338785392432256, 0.21374999595002164, 0.22995208923689966, 0.20625715296960015, 0.21208393748890544, 0.21195740872155516, 0.21566844626069998, 0.21753006569686228, 0.20834061597853087, 0.21660217181318614, 0.21665617284406158, 0.21364998806118013, 0.21333745558324932, 0.21414371986072783, 0.21500706221062327, 0.21420670541726466, 0.2106931765405491, 0.21859439250062423, 0.20948705948559132, 0.22369062159023262, 0.22921175968962218, 0.21429777774304312, 0.2153782046932879, 0.21816935649431687, 0.22140925369001638, 0.2100453234597688, 0.21258870725398665, 0.2131375227389879, 0.21904516182430092, 0.21805999607541932, 0.20608287628520217, 0.20514382640359424, 0.20089305041066033, 0.21906416612064072, 0.2124680143990503, 0.20990409985572486, 0.21050353080168166, 0.21890667578516348, 0.21511101923211187, 0.20595505960023364, 0.21492501681346732, 0.21346604053505236, 0.2110514093881834, 0.21485395496297807, 0.21969266696931533, 0.2269174024973796, 0.2171209245808763, 0.2129343505118227, 0.20795992233629296, 0.21730924502701685, 0.2178916639357105, 0.21075579528292146, 0.20987789806988422, 0.20691263942103444, 0.20735881155577454, 0.20580313131416864, 0.20928567968945394, 0.21231446774513782, 0.21019294248142467, 0.21217644223857157, 0.2081072705605102, 0.21838185130682497, 0.2071321072240518, 0.20394475888607247, 0.2233116808342337, 0.21436506760965213, 0.2125296584100225, 0.2171164338094583, 0.21838959345903847, 0.21956325734546156, 0.21591019470025902, 0.21042416593869645, 0.2088155591829207, 0.2131005913417876, 0.21083884722489143, 0.21478725590537548, 0.2168552227940853, 0.22035420446428175, 0.2254976798312317, 0.22963674188159638, 0.20830383953448636, 0.21723983515617057, 0.2174351931610916, 0.20877631726663026, 0.2138534099929395, 0.21014555470465893, 0.20981328694536672, 0.21838844346055697, 0.21282873600218113, 0.21986485365593145, 0.22073419326840024, 0.2112714800622354, 0.20957584593566986, 0.2136909738233198, 0.22078131388661382, 0.21746279821929407, 0.2080935935463879, 0.2121025566653562, 0.21510480019116734, 0.21240994796869378, 0.2143727467732383, 0.21524421498461663, 0.20576044804957333, 0.20800330935587283, 0.20968776724785382, 0.1714469939470291, 0.21112865739950915, 0.21461654752387527, 0.20722501679736857, 0.2175249707099653, 0.21350448886369963, 0.2118224437334826, 0.2217335383131122, 0.21556143006836448, 0.21329207406032238, 0.20492062677193718, 0.21531496527213662, 0.21265762109424036, 0.21324700193128815, 0.22337887241170934, 0.20288931420746875, 0.20677275094646713, 0.20746024268333496, 0.21632009523218576, 0.20773593691605777, 0.2149404677707781, 0.2032515574832468, 0.2068393929371579, 0.21415327850930482, 0.2144322453335705, 0.21649069326390277, 0.21378595422312444, 0.21070656634348267, 0.21351269185538044, 0.22784503158699354, 0.21698172812300634, 0.22000634584892054, 0.2073850994612576, 0.20115956179485342, 0.21132535661056023, 0.20446153717452897, 0.21479241515262312, 0.2132677515928268, 0.20809873936106002, 0.2109387994879156, 0.2146964742321527, 0.2154574052806651, 0.21351269486155294, 0.20898096349849593, 0.21158038637148452, 0.20622658728216026, 0.2055644767283213, 0.21095291684813772, 0.2135836367259456, 0.20891934148290803, 0.20515732200581885, 0.20688040532502003, 0.21777519712804755, 0.2070900548715536, 0.2138627899197496, 0.2122739821130355, 0.20464646457367985, 0.2140948723142651, 0.20609562004899187, 0.215609643419595, 0.2178834801341183, 0.209766105078524, 0.2120730676933861, 0.21463573726667878, 0.1851176852384938, 0.20751440992514097, 0.21007986507552098, 0.21102836939792302, 0.20476331812066295, 0.20933368761264998, 0.20987547251066313, 0.21461884349530141, 0.20978333637740276]}, {\"fill\": \"tonexty\", \"fillcolor\": \"rgba(68, 68, 68, 0.3)\", \"line\": {\"width\": 0}, \"marker\": {\"color\": \"#444\"}, \"mode\": \"lines\", \"name\": \"Lower Bound\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000, 21000, 22000, 23000, 24000, 25000, 26000, 27000, 28000, 29000, 30000, 31000, 32000, 33000, 34000, 35000, 36000, 37000, 38000, 39000, 40000, 41000, 42000, 43000, 44000, 45000, 46000, 47000, 48000, 49000, 50000, 51000, 52000, 53000, 54000, 55000, 56000, 57000, 58000, 59000, 60000, 61000, 62000, 63000, 64000, 65000, 66000, 67000, 68000, 69000, 70000, 71000, 72000, 73000, 74000, 75000, 76000, 77000, 78000, 79000, 80000, 81000, 82000, 83000, 84000, 85000, 86000, 87000, 88000, 89000, 90000, 91000, 92000, 93000, 94000, 95000, 96000, 97000, 98000, 99000, 100000, 101000, 102000, 103000, 104000, 105000, 106000, 107000, 108000, 109000, 110000, 111000, 112000, 113000, 114000, 115000, 116000, 117000, 118000, 119000, 120000, 121000, 122000, 123000, 124000, 125000, 126000, 127000, 128000, 129000, 130000, 131000, 132000, 133000, 134000, 135000, 136000, 137000, 138000, 139000, 140000, 141000, 142000, 143000, 144000, 145000, 146000, 147000, 148000, 149000, 150000, 151000, 152000, 153000, 154000, 155000, 156000, 157000, 158000, 159000, 160000, 161000, 162000, 163000, 164000, 165000, 166000, 167000, 168000, 169000, 170000, 171000, 172000, 173000, 174000, 175000, 176000, 177000, 178000, 179000, 180000, 181000, 182000, 183000, 184000, 185000, 186000, 187000, 188000, 189000, 190000, 191000, 192000, 193000, 194000, 195000, 196000, 197000, 198000, 199000, 200000, 201000, 202000, 203000, 204000, 205000, 206000, 207000, 208000, 209000, 210000, 211000, 212000, 213000, 214000, 215000, 216000, 217000], \"y\": [0.15850469754684354, 0.13787293051694324, 0.1459365816425822, 0.14181464880957068, 0.1440335306853656, 0.1535932177728478, 0.14622335759287972, 0.14335210997269016, 0.14927543437659552, 0.14376762391679643, 0.15962232787879937, 0.14190281357720097, 0.15523185074282428, 0.14544092111838158, 0.14988683853052848, 0.13735282500964824, 0.1385985656092139, 0.14762795887256464, 0.14599020992313064, 0.1384143395495966, 0.14760377709774938, 0.15082426427398712, 0.14355143284978333, 0.15218771235072118, 0.14021725230292806, 0.1471900269624537, 0.1490244501204256, 0.14535622279504296, 0.1397121807911379, 0.14459846595709383, 0.1439893228814786, 0.14567869419093005, 0.16228747714272454, 0.13776598654469027, 0.14429402985217432, 0.14180972738386127, 0.14454546084926032, 0.14031676398814222, 0.14127297782372134, 0.15832223395085396, 0.1517934184197375, 0.14433063860114892, 0.15428313362969334, 0.16184983102458264, 0.14072752465554492, 0.14044975136536098, 0.14532470591315694, 0.14900193746656104, 0.14447110256527634, 0.14341910832900528, 0.14836531246163265, 0.1418542880389601, 0.1421960062923386, 0.143418009198772, 0.14944102734433456, 0.14479652226006506, 0.1437880583622133, 0.14735736961990814, 0.14047526929518983, 0.16747964097914875, 0.16069658027274106, 0.14410691552112673, 0.14767470152796897, 0.14031426058918414, 0.15352675330303897, 0.14055923277184482, 0.13968116849012807, 0.14064814416648191, 0.14784458853714164, 0.14491121684645175, 0.16447370226875396, 0.13544812462470257, 0.13847034770677943, 0.15209450593289192, 0.14628151498477956, 0.1405157719703963, 0.1443626416523196, 0.1500204862630818, 0.14240141988530128, 0.14238490253557068, 0.13899660147655246, 0.14095130679296386, 0.14531787247791705, 0.14008549290339226, 0.16063150210788857, 0.15621800713800996, 0.14236150632627728, 0.14566314081420256, 0.14073363973469094, 0.1514798227209231, 0.1437612582177624, 0.16147505016356786, 0.13539429246382306, 0.14048153780170858, 0.14236520765498265, 0.14129688519976877, 0.14143532762897526, 0.13844356048311543, 0.1411170201361016, 0.1422645577456006, 0.14227408432293887, 0.14640182292362885, 0.14861298806991713, 0.1385685041599509, 0.15196913892317349, 0.14025459066360807, 0.14241243380367677, 0.1465675991780929, 0.14463999130927407, 0.16406192688935833, 0.14434382526974904, 0.14168623984950734, 0.14217015599452834, 0.141066466403437, 0.14295185280101896, 0.13730069525160668, 0.1406231772024023, 0.14846285142336438, 0.14733618759306905, 0.15245388978762153, 0.14202344193050673, 0.1489966342854518, 0.14199584294460899, 0.14156282467153125, 0.15197335533259254, 0.14276379264949038, 0.13868434444040517, 0.15532414989177373, 0.14156762270066978, 0.1490833997299283, 0.15224045083623947, 0.14003265990574637, 0.14193765546655362, 0.14536849580095135, 0.14802151069633263, 0.15490817824684186, 0.14032061406735752, 0.14539955217107486, 0.1419441380490168, 0.14097855101953294, 0.14120874989481746, 0.1433872087471393, 0.14101668091704705, 0.14121450839611202, 0.14108694966754415, 0.1714469939470291, 0.14074836669731822, 0.14444747361840155, 0.1399323006874901, 0.14506182915802646, 0.14573664659434618, 0.13954836637426873, 0.1595062052474404, 0.14508842947343548, 0.1481225591342831, 0.14453188539109912, 0.14317041740762038, 0.14418657126922751, 0.14416642078345143, 0.15683084523949892, 0.13934982075228952, 0.1428166905302699, 0.14402829069964024, 0.1465001745992916, 0.16144474867940442, 0.14071711814965357, 0.1428478247971603, 0.14203675827206888, 0.145087466636179, 0.14083668004188513, 0.15384874762446918, 0.1388622335046993, 0.14116249035914274, 0.14207041544267565, 0.15439330987961858, 0.1559478652016549, 0.15105543314349396, 0.1387025711724596, 0.14049328191357494, 0.14527538021878778, 0.14004465124710702, 0.14531744545204092, 0.13779992755165887, 0.13932931044673538, 0.14076860043682554, 0.14079460540903943, 0.1472501743970901, 0.15095962631100235, 0.14098915650681365, 0.14381524289507225, 0.14345393557676694, 0.13643423028715562, 0.14340902838215447, 0.1456351381499929, 0.14888864817125308, 0.13852908577980808, 0.14202385414080013, 0.15213550508370277, 0.14269526760553589, 0.143436698377979, 0.14114669629671228, 0.1527535968293222, 0.14295759790346774, 0.14178635151404254, 0.14275473319298226, 0.15793677996452166, 0.1389681877491447, 0.1424559497214233, 0.14516437346255673, 0.168494320472108, 0.1386200342695405, 0.14214974313978015, 0.1417706293380741, 0.1435138455444076, 0.1463743414923837, 0.1384878323378349, 0.14262122277796013, 0.1398362117726406]}],\n",
              "                        {\"font\": {\"color\": \"black\", \"size\": 16}, \"height\": 500, \"hovermode\": \"x\", \"paper_bgcolor\": \"rgba(0,0,0,0)\", \"plot_bgcolor\": \"rgba(0,0,0,0)\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Estimation Bias in Deep Q networks\"}, \"width\": 900, \"xaxis\": {\"gridcolor\": \"#DFDFDF\", \"gridwidth\": 1.5, \"linecolor\": \"#AFAFAF\", \"linewidth\": 2.5, \"nticks\": 7, \"showgrid\": true, \"showline\": true, \"title\": {\"text\": \"Time steps\"}}, \"yaxis\": {\"gridcolor\": \"#DFDFDF\", \"gridwidth\": 1.5, \"linecolor\": \"#AFAFAF\", \"linewidth\": 2.5, \"nticks\": 7, \"showgrid\": true, \"showline\": true, \"title\": {\"text\": \"Avg. Value Estimate (greedy policy)\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8e20b8df-3d4b-4ef7-97ea-22f7b3581e94');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To1WGMUfTbmZ"
      },
      "source": [
        "avg_result_DDQN = np.mean(np.array(result_DDQN).reshape(-1, 10), axis=1)\n",
        "avg_result_DQN = np.mean(np.array(result_DQN).reshape(-1, 10), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "8bKG4eDVh3Bl",
        "outputId": "f7fc5bdc-c976-4821-ebad-562bdf4543a1"
      },
      "source": [
        "import colorlover as cl\n",
        "import plotly.graph_objects as go\n",
        "colors = cl.scales['5']['qual']['Set1']\n",
        "\n",
        "fig = go.Figure([\n",
        "    go.Scatter(\n",
        "        name='Double Deep Q Networks',\n",
        "        x=np.arange(len(avg_result_DDQN)),\n",
        "        y=avg_result_DDQN,\n",
        "        mode='lines',\n",
        "        line=dict(color=colors[0], width = 2),\n",
        "    ),\n",
        "        go.Scatter(\n",
        "        name='Deep Q Networks',\n",
        "        x=np.arange(len(avg_result_DQN)),\n",
        "        y=avg_result_DQN,\n",
        "        mode='lines',\n",
        "        line=dict(color=colors[1], width = 2),\n",
        "    ),\n",
        "])\n",
        "\n",
        "fig.update_layout(\n",
        "    yaxis_title='Avg. Rewards per episode',\n",
        "    title='Reward accumulation profile',\n",
        "    hovermode=\"x\",\n",
        "    paper_bgcolor = 'rgba(0,0,0,0)',\n",
        "    plot_bgcolor = 'rgba(0,0,0,0)',\n",
        "    font = dict(size = 16, color = 'black'),\n",
        "    width = 900,\n",
        "    height = 500\n",
        ")\n",
        "fig.update_xaxes(title = 'Sets (10 episodes in each set)', showgrid=True, gridwidth=1.5, gridcolor='#DFDFDF', showline=True, linecolor = '#AFAFAF', linewidth = 2.5, nticks = 7)\n",
        "fig.update_yaxes(showgrid=True, gridwidth=1.5,gridcolor='#DFDFDF', showline=True, linecolor = '#AFAFAF', linewidth = 2.5, nticks = 7)\n",
        "fig.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"0f8908ab-6bf4-41aa-82a7-d6613f491d93\" class=\"plotly-graph-div\" style=\"height:500px; width:900px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"0f8908ab-6bf4-41aa-82a7-d6613f491d93\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '0f8908ab-6bf4-41aa-82a7-d6613f491d93',\n",
              "                        [{\"line\": {\"color\": \"rgb(228,26,28)\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"Double Deep Q Networks\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"y\": [1.6327701097580998, 1.7764296702492341, 1.3888686143809297, 1.9209893238324416, 1.433918835811612, 1.3783200137068536, 1.4604873851944227, 1.4183004619572428, 2.1944454635192097, 1.3047713866663826, 1.7595453869130584, 1.444396181852144, 1.31160144376972, 1.1932995376043825, 1.6030985076128714, 1.572994480445685, 1.153154994923332, 1.5167603963058625, 1.7923218778403496, 1.854511492237899, 1.7845210907842108, 1.7113784025896397, 1.938062002746335, 1.3148291209034302, 1.3863759647619918, 1.4861052362448135, 1.4558732514657735, 1.8755603479523635, 1.5407830731568422, 1.4076818207107131, 1.29870676127558, 1.5554879376534196, 1.6119218892670886, 1.9702857378586682, 2.1611584846885346, 1.2551368964148213, 1.5232009641173878, 1.302947802971893, 1.4533157937931411, 1.39267030422478, 1.908585306792657, 1.5442854769007026, 1.4306302223052048, 2.588757544596381, 1.5341066483852983, 1.5404826022789013, 1.2246359789421561, 1.5861124574685985, 1.6011928345872917, 1.6004754062174686, 2.328410564563484, 2.1056627691389105, 2.0213712910404977, 1.5463871612822715, 1.5719452955996327, 1.4809151497780413, 2.123554789237946, 1.4946403911466255, 3.208057006667714, 1.9408704489815218, 1.440381065517082, 1.4200581542588218, 1.3199763677052105, 1.518314951861936, 1.6935751184991066, 1.3484734853282285, 1.9426394595365282, 1.7904462870262812, 1.4657717359104963, 1.3747162671782984, 1.5614288650669519, 1.4869516915178909, 1.2979527390660877, 1.4220652585163103, 1.6471352204685281, 1.9348025525744177, 1.4227598232554457, 1.5486630883224444, 2.948844402517594, 1.7049719836423833, 1.5453143695975646, 1.380652813919474, 1.5360299200815146, 1.3161154316975008, 1.5866163699190003, 1.4225899712156775, 1.3287825846511805, 1.5577439027394901, 1.3695301226551226, 1.5547782267610342, 1.537590417054297, 1.6011289849689487, 1.521468727227537, 1.801093607434121, 1.2694810370687428, 2.1784098475274947, 1.546527402972989, 1.3465770114259688, 1.5378963612451693, 1.5837482221243195, 1.359387857671158, 1.3392596083520516, 2.4633661342661965, 1.6466609419877352, 2.5914982677371774, 1.8375931522656668, 1.9362781864640461, 1.3539535287832511, 1.2832667512925031, 1.7770164373374946, 1.449700185404383, 1.8164907045456133, 2.1118268879313873, 1.4484736334126458, 1.4625668513604226, 1.6703324336241567, 2.9609427113797926, 1.666520676149256, 1.668219658389885, 1.6359698329228434, 1.647196296667552, 1.623274666130455, 1.6685504249590095, 1.7766403136145772, 1.9529163037106656, 1.5614660007425702, 1.778467025766329, 1.4696508724555095, 1.6662799786205666, 2.39477836461143, 1.5299203305484963, 2.061565183322973, 1.8956217796603299, 1.4379233599363783, 1.4360810570101836, 1.4359075495402984, 1.6483430671323471, 1.4890105758243233, 1.4734277243509104, 2.051133185386818, 1.5372812666124127, 1.6082452998387555, 1.608602952209008, 1.8686871362118105, 1.7573804813177625, 1.2611734511856103, 1.693689344729864, 1.6657372022707377, 1.839588619240213, 1.5491899639749134, 1.714452632743464, 1.932416648566561, 1.7330796282742007, 1.5068919412683424, 1.5611582854371417, 1.5635837318049564, 1.9782083270388768, 1.2062126203384549, 1.9730249670621824, 2.138218778393632, 2.0478088928756186, 1.4425457576902216, 1.9575406055198836, 1.9900381897328725, 1.6331186475855262, 1.8990764200573071, 1.972956707533013, 1.2954658429196604, 1.5267068801888812, 1.9232146699264319, 1.2617997082284258, 1.6863069805108588, 1.8048542530666587, 1.9414285013291797, 1.6146706247618166, 1.2594654888326686, 1.6388210752604864, 1.4988351989410797, 1.5759005544391234, 1.4705736927699085, 3.062249780817984, 2.047953775880708, 1.5930162391489788, 1.533795611903544, 1.3093403789299043, 1.7543673303107798, 2.334330325119798, 1.6002962339119626, 1.6990203080624293, 1.7967472215747957, 1.8336316964335784, 1.752575386974197, 1.702749354461205, 2.101108089090711, 1.5481076574903818, 1.80926274083836, 2.116551607942916, 2.1524814576574007, 1.8273055408657015, 1.7921253963345625]}, {\"line\": {\"color\": \"rgb(55,126,184)\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"Deep Q Networks\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"y\": [1.6068361490652248, 1.925283840872852, 1.4966384767657268, 1.0850025790317637, 1.4876489797048296, 1.9340799231723025, 1.597745082450444, 1.4191907227784668, 1.5325733192383582, 1.7078024715011015, 1.627092952671901, 2.2215212130074393, 1.5588963380348166, 1.7693280501281343, 1.2672219207429634, 1.8241910166433501, 2.3330338639907433, 1.4886742439493497, 1.5828559649564535, 1.6998075746722912, 1.255195090904905, 1.5766130330006454, 1.3363873983794885, 1.179732693353531, 1.4469511963694353, 1.7175502918300716, 3.0245492666603004, 1.5461999242876177, 1.997239492796447, 1.1326198368476195, 1.3693768286780779, 1.7565873015873017, 1.4235400922445387, 1.9201101321402079, 1.282152892235059, 1.4040738546399174, 2.337901744088767, 1.8467850644934525, 3.055846277254716, 1.661178288821634, 1.5067186937945976, 1.395216351087551, 1.8369737038042733, 1.8276135902947668, 1.3506548924025616, 1.4198758660640023, 1.7859573542119827, 1.749290448267147, 1.7846228139030464, 2.065631584235738, 1.5065924500400059, 1.4838003796054906, 1.722609105583399, 1.2697249129433008, 1.2823718958996895, 1.6351304745650548, 2.0725394418607896, 1.7741140004995988, 1.6309744512299045, 1.569345104591358, 1.215909561512984, 2.7288501811536117, 1.2308956603435388, 1.4100826228068866, 1.759524318013351, 1.339538170563607, 1.8113440745715663, 1.8594480888042106, 1.4270567112005073, 1.5540059661099566, 2.1741157324061193, 1.3830048490603246, 1.890503309597846, 1.5550735470361712, 1.9743898835854048, 1.2688610518363792, 2.092425928267637, 1.6012474460288053, 1.4260921172623502, 1.754150931848915, 1.6255813959497796, 1.7179398103714085, 1.8089883738333197, 1.8000505521731938, 1.5657480321211568, 1.6676608157711026, 1.1587913693417244, 1.4343248388176835, 1.330110121954643, 1.7677394722008315, 1.9372589614922546, 1.7399528625474083, 1.8959259009486455, 1.4193618660789777, 2.0482713818789735, 1.5286758983847204, 1.4771775905452227, 2.160485980762683, 1.4169298858269799, 1.7412439045163453, 1.7696086732983694, 1.4710850617319162, 1.4907893359457887, 1.5392135450025788, 1.567081139741689, 1.420235579267843, 2.700722895871163, 1.677583329321445, 1.9802812661961025, 1.5871878055338988, 1.400855497375095, 1.4956728634232976, 1.7482265622997164, 1.3036472806189112, 2.729948339770539, 1.6969417922165952, 2.4514926624039517, 1.1581186002917652, 2.044086865705658, 1.7662361784521643, 1.447169360325131, 1.6074777286240085, 1.6034785012620731, 1.5391283581476418, 1.7203462250155515, 2.2723445188305362, 2.046560062298492, 1.6026186423494828, 1.6783067272371497, 1.5195329988311312, 1.511803467292052, 1.7853624529203067, 1.3412458981963218, 1.6133281342634405, 1.6821410515568833, 1.8674263258565584, 1.3952239533001785, 1.8779669673142152, 1.5639163346212075, 1.923546018658915, 1.7195290190563406, 1.2927833569963827, 1.7989082403430625, 1.6997811234495308, 1.5055390977270986, 1.731417715117939, 1.5979498968045998, 1.7379320710617745, 1.830401400756274, 1.6218929280253787, 1.4908517116445883, 1.6721698202507072, 1.694642462707566, 1.6892806105841853, 1.6249167659980177, 1.6700950814700697, 1.9735169822804721, 1.7103568136006846, 1.8048032253232287, 1.879420737549511, 1.4872556552846998, 2.4823300902764047, 1.5961000794394051, 1.5049177164389582, 2.0371735001462747, 1.5680769939273644, 1.4630514467120996, 1.353494086737567, 1.7295048193642741, 1.9433308264100844, 2.232495283676016, 1.500492769409011, 2.0095468107066727, 1.8205994802172178, 1.7136386594356565, 1.8616263160945088, 1.9572477289424584, 1.8251431175425725, 1.5361040100856946, 1.957934044078545, 1.3402815762266655, 1.6426845226255167, 1.999557359973497, 1.4263905362962717, 1.9776999060421736, 1.9486070821725838, 2.0135475120140582, 1.9354698921362747, 2.090985253648297, 1.4357665515901337, 2.3272846245993604, 1.8526161998902313, 1.8059751826721908, 1.823491972301822, 1.7640655453999272, 2.081596156463378, 1.90457412865782, 1.7894193335442519, 1.8635681254559575, 1.7266243480430792]}],\n",
              "                        {\"font\": {\"color\": \"black\", \"size\": 16}, \"height\": 500, \"hovermode\": \"x\", \"paper_bgcolor\": \"rgba(0,0,0,0)\", \"plot_bgcolor\": \"rgba(0,0,0,0)\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Reward accumulation profile\"}, \"width\": 900, \"xaxis\": {\"gridcolor\": \"#DFDFDF\", \"gridwidth\": 1.5, \"linecolor\": \"#AFAFAF\", \"linewidth\": 2.5, \"nticks\": 7, \"showgrid\": true, \"showline\": true, \"title\": {\"text\": \"Sets (10 episodes in each set)\"}}, \"yaxis\": {\"gridcolor\": \"#DFDFDF\", \"gridwidth\": 1.5, \"linecolor\": \"#AFAFAF\", \"linewidth\": 2.5, \"nticks\": 7, \"showgrid\": true, \"showline\": true, \"title\": {\"text\": \"Avg. Rewards per episode\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0f8908ab-6bf4-41aa-82a7-d6613f491d93');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he05cAg4jXus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7d55bf0-72f8-4ebb-9e6d-c0f2acddf77e"
      },
      "source": [
        "policy_net = torch.load('ddqn_pong_model')\n",
        "obs = env.reset()\n",
        "state = get_state(obs)\n",
        "for t in count():\n",
        "  action = policy_net(state.to('cuda')).max(1)[1].view(1,1)\n",
        "  obs, reward, done, info = env.step(action)\n",
        "  print(reward)\n",
        "  \n",
        "  if not done:\n",
        "    next_state = get_state(obs)\n",
        "  else:\n",
        "    next_state = None\n",
        "  state = next_state\n",
        "  if done:\n",
        "    break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "-1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALCzuQIeVpdb",
        "outputId": "deebf3c9-1790-4eb4-85ce-cdb9d8332238"
      },
      "source": [
        "env.unwrapped.get_action_meanings()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnNz6fr3dekl",
        "outputId": "d6ce456d-e018-42f7-b088-2f340bc482bf"
      },
      "source": [
        "gym.envs.registry.all()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values([EnvSpec(Copy-v0), EnvSpec(RepeatCopy-v0), EnvSpec(ReversedAddition-v0), EnvSpec(ReversedAddition3-v0), EnvSpec(DuplicatedInput-v0), EnvSpec(Reverse-v0), EnvSpec(CartPole-v0), EnvSpec(CartPole-v1), EnvSpec(MountainCar-v0), EnvSpec(MountainCarContinuous-v0), EnvSpec(Pendulum-v0), EnvSpec(Acrobot-v1), EnvSpec(LunarLander-v2), EnvSpec(LunarLanderContinuous-v2), EnvSpec(BipedalWalker-v3), EnvSpec(BipedalWalkerHardcore-v3), EnvSpec(CarRacing-v0), EnvSpec(Blackjack-v0), EnvSpec(KellyCoinflip-v0), EnvSpec(KellyCoinflipGeneralized-v0), EnvSpec(FrozenLake-v0), EnvSpec(FrozenLake8x8-v0), EnvSpec(CliffWalking-v0), EnvSpec(NChain-v0), EnvSpec(Roulette-v0), EnvSpec(Taxi-v3), EnvSpec(GuessingGame-v0), EnvSpec(HotterColder-v0), EnvSpec(Reacher-v2), EnvSpec(Pusher-v2), EnvSpec(Thrower-v2), EnvSpec(Striker-v2), EnvSpec(InvertedPendulum-v2), EnvSpec(InvertedDoublePendulum-v2), EnvSpec(HalfCheetah-v2), EnvSpec(HalfCheetah-v3), EnvSpec(Hopper-v2), EnvSpec(Hopper-v3), EnvSpec(Swimmer-v2), EnvSpec(Swimmer-v3), EnvSpec(Walker2d-v2), EnvSpec(Walker2d-v3), EnvSpec(Ant-v2), EnvSpec(Ant-v3), EnvSpec(Humanoid-v2), EnvSpec(Humanoid-v3), EnvSpec(HumanoidStandup-v2), EnvSpec(FetchSlide-v1), EnvSpec(FetchPickAndPlace-v1), EnvSpec(FetchReach-v1), EnvSpec(FetchPush-v1), EnvSpec(HandReach-v0), EnvSpec(HandManipulateBlockRotateZ-v0), EnvSpec(HandManipulateBlockRotateZTouchSensors-v0), EnvSpec(HandManipulateBlockRotateZTouchSensors-v1), EnvSpec(HandManipulateBlockRotateParallel-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensors-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensors-v1), EnvSpec(HandManipulateBlockRotateXYZ-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensors-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensors-v1), EnvSpec(HandManipulateBlockFull-v0), EnvSpec(HandManipulateBlock-v0), EnvSpec(HandManipulateBlockTouchSensors-v0), EnvSpec(HandManipulateBlockTouchSensors-v1), EnvSpec(HandManipulateEggRotate-v0), EnvSpec(HandManipulateEggRotateTouchSensors-v0), EnvSpec(HandManipulateEggRotateTouchSensors-v1), EnvSpec(HandManipulateEggFull-v0), EnvSpec(HandManipulateEgg-v0), EnvSpec(HandManipulateEggTouchSensors-v0), EnvSpec(HandManipulateEggTouchSensors-v1), EnvSpec(HandManipulatePenRotate-v0), EnvSpec(HandManipulatePenRotateTouchSensors-v0), EnvSpec(HandManipulatePenRotateTouchSensors-v1), EnvSpec(HandManipulatePenFull-v0), EnvSpec(HandManipulatePen-v0), EnvSpec(HandManipulatePenTouchSensors-v0), EnvSpec(HandManipulatePenTouchSensors-v1), EnvSpec(FetchSlideDense-v1), EnvSpec(FetchPickAndPlaceDense-v1), EnvSpec(FetchReachDense-v1), EnvSpec(FetchPushDense-v1), EnvSpec(HandReachDense-v0), EnvSpec(HandManipulateBlockRotateZDense-v0), EnvSpec(HandManipulateBlockRotateZTouchSensorsDense-v0), EnvSpec(HandManipulateBlockRotateZTouchSensorsDense-v1), EnvSpec(HandManipulateBlockRotateParallelDense-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensorsDense-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensorsDense-v1), EnvSpec(HandManipulateBlockRotateXYZDense-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensorsDense-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensorsDense-v1), EnvSpec(HandManipulateBlockFullDense-v0), EnvSpec(HandManipulateBlockDense-v0), EnvSpec(HandManipulateBlockTouchSensorsDense-v0), EnvSpec(HandManipulateBlockTouchSensorsDense-v1), EnvSpec(HandManipulateEggRotateDense-v0), EnvSpec(HandManipulateEggRotateTouchSensorsDense-v0), EnvSpec(HandManipulateEggRotateTouchSensorsDense-v1), EnvSpec(HandManipulateEggFullDense-v0), EnvSpec(HandManipulateEggDense-v0), EnvSpec(HandManipulateEggTouchSensorsDense-v0), EnvSpec(HandManipulateEggTouchSensorsDense-v1), EnvSpec(HandManipulatePenRotateDense-v0), EnvSpec(HandManipulatePenRotateTouchSensorsDense-v0), EnvSpec(HandManipulatePenRotateTouchSensorsDense-v1), EnvSpec(HandManipulatePenFullDense-v0), EnvSpec(HandManipulatePenDense-v0), EnvSpec(HandManipulatePenTouchSensorsDense-v0), EnvSpec(HandManipulatePenTouchSensorsDense-v1), EnvSpec(Adventure-v0), EnvSpec(Adventure-v4), EnvSpec(AdventureDeterministic-v0), EnvSpec(AdventureDeterministic-v4), EnvSpec(AdventureNoFrameskip-v0), EnvSpec(AdventureNoFrameskip-v4), EnvSpec(Adventure-ram-v0), EnvSpec(Adventure-ram-v4), EnvSpec(Adventure-ramDeterministic-v0), EnvSpec(Adventure-ramDeterministic-v4), EnvSpec(Adventure-ramNoFrameskip-v0), EnvSpec(Adventure-ramNoFrameskip-v4), EnvSpec(AirRaid-v0), EnvSpec(AirRaid-v4), EnvSpec(AirRaidDeterministic-v0), EnvSpec(AirRaidDeterministic-v4), EnvSpec(AirRaidNoFrameskip-v0), EnvSpec(AirRaidNoFrameskip-v4), EnvSpec(AirRaid-ram-v0), EnvSpec(AirRaid-ram-v4), EnvSpec(AirRaid-ramDeterministic-v0), EnvSpec(AirRaid-ramDeterministic-v4), EnvSpec(AirRaid-ramNoFrameskip-v0), EnvSpec(AirRaid-ramNoFrameskip-v4), EnvSpec(Alien-v0), EnvSpec(Alien-v4), EnvSpec(AlienDeterministic-v0), EnvSpec(AlienDeterministic-v4), EnvSpec(AlienNoFrameskip-v0), EnvSpec(AlienNoFrameskip-v4), EnvSpec(Alien-ram-v0), EnvSpec(Alien-ram-v4), EnvSpec(Alien-ramDeterministic-v0), EnvSpec(Alien-ramDeterministic-v4), EnvSpec(Alien-ramNoFrameskip-v0), EnvSpec(Alien-ramNoFrameskip-v4), EnvSpec(Amidar-v0), EnvSpec(Amidar-v4), EnvSpec(AmidarDeterministic-v0), EnvSpec(AmidarDeterministic-v4), EnvSpec(AmidarNoFrameskip-v0), EnvSpec(AmidarNoFrameskip-v4), EnvSpec(Amidar-ram-v0), EnvSpec(Amidar-ram-v4), EnvSpec(Amidar-ramDeterministic-v0), EnvSpec(Amidar-ramDeterministic-v4), EnvSpec(Amidar-ramNoFrameskip-v0), EnvSpec(Amidar-ramNoFrameskip-v4), EnvSpec(Assault-v0), EnvSpec(Assault-v4), EnvSpec(AssaultDeterministic-v0), EnvSpec(AssaultDeterministic-v4), EnvSpec(AssaultNoFrameskip-v0), EnvSpec(AssaultNoFrameskip-v4), EnvSpec(Assault-ram-v0), EnvSpec(Assault-ram-v4), EnvSpec(Assault-ramDeterministic-v0), EnvSpec(Assault-ramDeterministic-v4), EnvSpec(Assault-ramNoFrameskip-v0), EnvSpec(Assault-ramNoFrameskip-v4), EnvSpec(Asterix-v0), EnvSpec(Asterix-v4), EnvSpec(AsterixDeterministic-v0), EnvSpec(AsterixDeterministic-v4), EnvSpec(AsterixNoFrameskip-v0), EnvSpec(AsterixNoFrameskip-v4), EnvSpec(Asterix-ram-v0), EnvSpec(Asterix-ram-v4), EnvSpec(Asterix-ramDeterministic-v0), EnvSpec(Asterix-ramDeterministic-v4), EnvSpec(Asterix-ramNoFrameskip-v0), EnvSpec(Asterix-ramNoFrameskip-v4), EnvSpec(Asteroids-v0), EnvSpec(Asteroids-v4), EnvSpec(AsteroidsDeterministic-v0), EnvSpec(AsteroidsDeterministic-v4), EnvSpec(AsteroidsNoFrameskip-v0), EnvSpec(AsteroidsNoFrameskip-v4), EnvSpec(Asteroids-ram-v0), EnvSpec(Asteroids-ram-v4), EnvSpec(Asteroids-ramDeterministic-v0), EnvSpec(Asteroids-ramDeterministic-v4), EnvSpec(Asteroids-ramNoFrameskip-v0), EnvSpec(Asteroids-ramNoFrameskip-v4), EnvSpec(Atlantis-v0), EnvSpec(Atlantis-v4), EnvSpec(AtlantisDeterministic-v0), EnvSpec(AtlantisDeterministic-v4), EnvSpec(AtlantisNoFrameskip-v0), EnvSpec(AtlantisNoFrameskip-v4), EnvSpec(Atlantis-ram-v0), EnvSpec(Atlantis-ram-v4), EnvSpec(Atlantis-ramDeterministic-v0), EnvSpec(Atlantis-ramDeterministic-v4), EnvSpec(Atlantis-ramNoFrameskip-v0), EnvSpec(Atlantis-ramNoFrameskip-v4), EnvSpec(BankHeist-v0), EnvSpec(BankHeist-v4), EnvSpec(BankHeistDeterministic-v0), EnvSpec(BankHeistDeterministic-v4), EnvSpec(BankHeistNoFrameskip-v0), EnvSpec(BankHeistNoFrameskip-v4), EnvSpec(BankHeist-ram-v0), EnvSpec(BankHeist-ram-v4), EnvSpec(BankHeist-ramDeterministic-v0), EnvSpec(BankHeist-ramDeterministic-v4), EnvSpec(BankHeist-ramNoFrameskip-v0), EnvSpec(BankHeist-ramNoFrameskip-v4), EnvSpec(BattleZone-v0), EnvSpec(BattleZone-v4), EnvSpec(BattleZoneDeterministic-v0), EnvSpec(BattleZoneDeterministic-v4), EnvSpec(BattleZoneNoFrameskip-v0), EnvSpec(BattleZoneNoFrameskip-v4), EnvSpec(BattleZone-ram-v0), EnvSpec(BattleZone-ram-v4), EnvSpec(BattleZone-ramDeterministic-v0), EnvSpec(BattleZone-ramDeterministic-v4), EnvSpec(BattleZone-ramNoFrameskip-v0), EnvSpec(BattleZone-ramNoFrameskip-v4), EnvSpec(BeamRider-v0), EnvSpec(BeamRider-v4), EnvSpec(BeamRiderDeterministic-v0), EnvSpec(BeamRiderDeterministic-v4), EnvSpec(BeamRiderNoFrameskip-v0), EnvSpec(BeamRiderNoFrameskip-v4), EnvSpec(BeamRider-ram-v0), EnvSpec(BeamRider-ram-v4), EnvSpec(BeamRider-ramDeterministic-v0), EnvSpec(BeamRider-ramDeterministic-v4), EnvSpec(BeamRider-ramNoFrameskip-v0), EnvSpec(BeamRider-ramNoFrameskip-v4), EnvSpec(Berzerk-v0), EnvSpec(Berzerk-v4), EnvSpec(BerzerkDeterministic-v0), EnvSpec(BerzerkDeterministic-v4), EnvSpec(BerzerkNoFrameskip-v0), EnvSpec(BerzerkNoFrameskip-v4), EnvSpec(Berzerk-ram-v0), EnvSpec(Berzerk-ram-v4), EnvSpec(Berzerk-ramDeterministic-v0), EnvSpec(Berzerk-ramDeterministic-v4), EnvSpec(Berzerk-ramNoFrameskip-v0), EnvSpec(Berzerk-ramNoFrameskip-v4), EnvSpec(Bowling-v0), EnvSpec(Bowling-v4), EnvSpec(BowlingDeterministic-v0), EnvSpec(BowlingDeterministic-v4), EnvSpec(BowlingNoFrameskip-v0), EnvSpec(BowlingNoFrameskip-v4), EnvSpec(Bowling-ram-v0), EnvSpec(Bowling-ram-v4), EnvSpec(Bowling-ramDeterministic-v0), EnvSpec(Bowling-ramDeterministic-v4), EnvSpec(Bowling-ramNoFrameskip-v0), EnvSpec(Bowling-ramNoFrameskip-v4), EnvSpec(Boxing-v0), EnvSpec(Boxing-v4), EnvSpec(BoxingDeterministic-v0), EnvSpec(BoxingDeterministic-v4), EnvSpec(BoxingNoFrameskip-v0), EnvSpec(BoxingNoFrameskip-v4), EnvSpec(Boxing-ram-v0), EnvSpec(Boxing-ram-v4), EnvSpec(Boxing-ramDeterministic-v0), EnvSpec(Boxing-ramDeterministic-v4), EnvSpec(Boxing-ramNoFrameskip-v0), EnvSpec(Boxing-ramNoFrameskip-v4), EnvSpec(Breakout-v0), EnvSpec(Breakout-v4), EnvSpec(BreakoutDeterministic-v0), EnvSpec(BreakoutDeterministic-v4), EnvSpec(BreakoutNoFrameskip-v0), EnvSpec(BreakoutNoFrameskip-v4), EnvSpec(Breakout-ram-v0), EnvSpec(Breakout-ram-v4), EnvSpec(Breakout-ramDeterministic-v0), EnvSpec(Breakout-ramDeterministic-v4), EnvSpec(Breakout-ramNoFrameskip-v0), EnvSpec(Breakout-ramNoFrameskip-v4), EnvSpec(Carnival-v0), EnvSpec(Carnival-v4), EnvSpec(CarnivalDeterministic-v0), EnvSpec(CarnivalDeterministic-v4), EnvSpec(CarnivalNoFrameskip-v0), EnvSpec(CarnivalNoFrameskip-v4), EnvSpec(Carnival-ram-v0), EnvSpec(Carnival-ram-v4), EnvSpec(Carnival-ramDeterministic-v0), EnvSpec(Carnival-ramDeterministic-v4), EnvSpec(Carnival-ramNoFrameskip-v0), EnvSpec(Carnival-ramNoFrameskip-v4), EnvSpec(Centipede-v0), EnvSpec(Centipede-v4), EnvSpec(CentipedeDeterministic-v0), EnvSpec(CentipedeDeterministic-v4), EnvSpec(CentipedeNoFrameskip-v0), EnvSpec(CentipedeNoFrameskip-v4), EnvSpec(Centipede-ram-v0), EnvSpec(Centipede-ram-v4), EnvSpec(Centipede-ramDeterministic-v0), EnvSpec(Centipede-ramDeterministic-v4), EnvSpec(Centipede-ramNoFrameskip-v0), EnvSpec(Centipede-ramNoFrameskip-v4), EnvSpec(ChopperCommand-v0), EnvSpec(ChopperCommand-v4), EnvSpec(ChopperCommandDeterministic-v0), EnvSpec(ChopperCommandDeterministic-v4), EnvSpec(ChopperCommandNoFrameskip-v0), EnvSpec(ChopperCommandNoFrameskip-v4), EnvSpec(ChopperCommand-ram-v0), EnvSpec(ChopperCommand-ram-v4), EnvSpec(ChopperCommand-ramDeterministic-v0), EnvSpec(ChopperCommand-ramDeterministic-v4), EnvSpec(ChopperCommand-ramNoFrameskip-v0), EnvSpec(ChopperCommand-ramNoFrameskip-v4), EnvSpec(CrazyClimber-v0), EnvSpec(CrazyClimber-v4), EnvSpec(CrazyClimberDeterministic-v0), EnvSpec(CrazyClimberDeterministic-v4), EnvSpec(CrazyClimberNoFrameskip-v0), EnvSpec(CrazyClimberNoFrameskip-v4), EnvSpec(CrazyClimber-ram-v0), EnvSpec(CrazyClimber-ram-v4), EnvSpec(CrazyClimber-ramDeterministic-v0), EnvSpec(CrazyClimber-ramDeterministic-v4), EnvSpec(CrazyClimber-ramNoFrameskip-v0), EnvSpec(CrazyClimber-ramNoFrameskip-v4), EnvSpec(Defender-v0), EnvSpec(Defender-v4), EnvSpec(DefenderDeterministic-v0), EnvSpec(DefenderDeterministic-v4), EnvSpec(DefenderNoFrameskip-v0), EnvSpec(DefenderNoFrameskip-v4), EnvSpec(Defender-ram-v0), EnvSpec(Defender-ram-v4), EnvSpec(Defender-ramDeterministic-v0), EnvSpec(Defender-ramDeterministic-v4), EnvSpec(Defender-ramNoFrameskip-v0), EnvSpec(Defender-ramNoFrameskip-v4), EnvSpec(DemonAttack-v0), EnvSpec(DemonAttack-v4), EnvSpec(DemonAttackDeterministic-v0), EnvSpec(DemonAttackDeterministic-v4), EnvSpec(DemonAttackNoFrameskip-v0), EnvSpec(DemonAttackNoFrameskip-v4), EnvSpec(DemonAttack-ram-v0), EnvSpec(DemonAttack-ram-v4), EnvSpec(DemonAttack-ramDeterministic-v0), EnvSpec(DemonAttack-ramDeterministic-v4), EnvSpec(DemonAttack-ramNoFrameskip-v0), EnvSpec(DemonAttack-ramNoFrameskip-v4), EnvSpec(DoubleDunk-v0), EnvSpec(DoubleDunk-v4), EnvSpec(DoubleDunkDeterministic-v0), EnvSpec(DoubleDunkDeterministic-v4), EnvSpec(DoubleDunkNoFrameskip-v0), EnvSpec(DoubleDunkNoFrameskip-v4), EnvSpec(DoubleDunk-ram-v0), EnvSpec(DoubleDunk-ram-v4), EnvSpec(DoubleDunk-ramDeterministic-v0), EnvSpec(DoubleDunk-ramDeterministic-v4), EnvSpec(DoubleDunk-ramNoFrameskip-v0), EnvSpec(DoubleDunk-ramNoFrameskip-v4), EnvSpec(ElevatorAction-v0), EnvSpec(ElevatorAction-v4), EnvSpec(ElevatorActionDeterministic-v0), EnvSpec(ElevatorActionDeterministic-v4), EnvSpec(ElevatorActionNoFrameskip-v0), EnvSpec(ElevatorActionNoFrameskip-v4), EnvSpec(ElevatorAction-ram-v0), EnvSpec(ElevatorAction-ram-v4), EnvSpec(ElevatorAction-ramDeterministic-v0), EnvSpec(ElevatorAction-ramDeterministic-v4), EnvSpec(ElevatorAction-ramNoFrameskip-v0), EnvSpec(ElevatorAction-ramNoFrameskip-v4), EnvSpec(Enduro-v0), EnvSpec(Enduro-v4), EnvSpec(EnduroDeterministic-v0), EnvSpec(EnduroDeterministic-v4), EnvSpec(EnduroNoFrameskip-v0), EnvSpec(EnduroNoFrameskip-v4), EnvSpec(Enduro-ram-v0), EnvSpec(Enduro-ram-v4), EnvSpec(Enduro-ramDeterministic-v0), EnvSpec(Enduro-ramDeterministic-v4), EnvSpec(Enduro-ramNoFrameskip-v0), EnvSpec(Enduro-ramNoFrameskip-v4), EnvSpec(FishingDerby-v0), EnvSpec(FishingDerby-v4), EnvSpec(FishingDerbyDeterministic-v0), EnvSpec(FishingDerbyDeterministic-v4), EnvSpec(FishingDerbyNoFrameskip-v0), EnvSpec(FishingDerbyNoFrameskip-v4), EnvSpec(FishingDerby-ram-v0), EnvSpec(FishingDerby-ram-v4), EnvSpec(FishingDerby-ramDeterministic-v0), EnvSpec(FishingDerby-ramDeterministic-v4), EnvSpec(FishingDerby-ramNoFrameskip-v0), EnvSpec(FishingDerby-ramNoFrameskip-v4), EnvSpec(Freeway-v0), EnvSpec(Freeway-v4), EnvSpec(FreewayDeterministic-v0), EnvSpec(FreewayDeterministic-v4), EnvSpec(FreewayNoFrameskip-v0), EnvSpec(FreewayNoFrameskip-v4), EnvSpec(Freeway-ram-v0), EnvSpec(Freeway-ram-v4), EnvSpec(Freeway-ramDeterministic-v0), EnvSpec(Freeway-ramDeterministic-v4), EnvSpec(Freeway-ramNoFrameskip-v0), EnvSpec(Freeway-ramNoFrameskip-v4), EnvSpec(Frostbite-v0), EnvSpec(Frostbite-v4), EnvSpec(FrostbiteDeterministic-v0), EnvSpec(FrostbiteDeterministic-v4), EnvSpec(FrostbiteNoFrameskip-v0), EnvSpec(FrostbiteNoFrameskip-v4), EnvSpec(Frostbite-ram-v0), EnvSpec(Frostbite-ram-v4), EnvSpec(Frostbite-ramDeterministic-v0), EnvSpec(Frostbite-ramDeterministic-v4), EnvSpec(Frostbite-ramNoFrameskip-v0), EnvSpec(Frostbite-ramNoFrameskip-v4), EnvSpec(Gopher-v0), EnvSpec(Gopher-v4), EnvSpec(GopherDeterministic-v0), EnvSpec(GopherDeterministic-v4), EnvSpec(GopherNoFrameskip-v0), EnvSpec(GopherNoFrameskip-v4), EnvSpec(Gopher-ram-v0), EnvSpec(Gopher-ram-v4), EnvSpec(Gopher-ramDeterministic-v0), EnvSpec(Gopher-ramDeterministic-v4), EnvSpec(Gopher-ramNoFrameskip-v0), EnvSpec(Gopher-ramNoFrameskip-v4), EnvSpec(Gravitar-v0), EnvSpec(Gravitar-v4), EnvSpec(GravitarDeterministic-v0), EnvSpec(GravitarDeterministic-v4), EnvSpec(GravitarNoFrameskip-v0), EnvSpec(GravitarNoFrameskip-v4), EnvSpec(Gravitar-ram-v0), EnvSpec(Gravitar-ram-v4), EnvSpec(Gravitar-ramDeterministic-v0), EnvSpec(Gravitar-ramDeterministic-v4), EnvSpec(Gravitar-ramNoFrameskip-v0), EnvSpec(Gravitar-ramNoFrameskip-v4), EnvSpec(Hero-v0), EnvSpec(Hero-v4), EnvSpec(HeroDeterministic-v0), EnvSpec(HeroDeterministic-v4), EnvSpec(HeroNoFrameskip-v0), EnvSpec(HeroNoFrameskip-v4), EnvSpec(Hero-ram-v0), EnvSpec(Hero-ram-v4), EnvSpec(Hero-ramDeterministic-v0), EnvSpec(Hero-ramDeterministic-v4), EnvSpec(Hero-ramNoFrameskip-v0), EnvSpec(Hero-ramNoFrameskip-v4), EnvSpec(IceHockey-v0), EnvSpec(IceHockey-v4), EnvSpec(IceHockeyDeterministic-v0), EnvSpec(IceHockeyDeterministic-v4), EnvSpec(IceHockeyNoFrameskip-v0), EnvSpec(IceHockeyNoFrameskip-v4), EnvSpec(IceHockey-ram-v0), EnvSpec(IceHockey-ram-v4), EnvSpec(IceHockey-ramDeterministic-v0), EnvSpec(IceHockey-ramDeterministic-v4), EnvSpec(IceHockey-ramNoFrameskip-v0), EnvSpec(IceHockey-ramNoFrameskip-v4), EnvSpec(Jamesbond-v0), EnvSpec(Jamesbond-v4), EnvSpec(JamesbondDeterministic-v0), EnvSpec(JamesbondDeterministic-v4), EnvSpec(JamesbondNoFrameskip-v0), EnvSpec(JamesbondNoFrameskip-v4), EnvSpec(Jamesbond-ram-v0), EnvSpec(Jamesbond-ram-v4), EnvSpec(Jamesbond-ramDeterministic-v0), EnvSpec(Jamesbond-ramDeterministic-v4), EnvSpec(Jamesbond-ramNoFrameskip-v0), EnvSpec(Jamesbond-ramNoFrameskip-v4), EnvSpec(JourneyEscape-v0), EnvSpec(JourneyEscape-v4), EnvSpec(JourneyEscapeDeterministic-v0), EnvSpec(JourneyEscapeDeterministic-v4), EnvSpec(JourneyEscapeNoFrameskip-v0), EnvSpec(JourneyEscapeNoFrameskip-v4), EnvSpec(JourneyEscape-ram-v0), EnvSpec(JourneyEscape-ram-v4), EnvSpec(JourneyEscape-ramDeterministic-v0), EnvSpec(JourneyEscape-ramDeterministic-v4), EnvSpec(JourneyEscape-ramNoFrameskip-v0), EnvSpec(JourneyEscape-ramNoFrameskip-v4), EnvSpec(Kangaroo-v0), EnvSpec(Kangaroo-v4), EnvSpec(KangarooDeterministic-v0), EnvSpec(KangarooDeterministic-v4), EnvSpec(KangarooNoFrameskip-v0), EnvSpec(KangarooNoFrameskip-v4), EnvSpec(Kangaroo-ram-v0), EnvSpec(Kangaroo-ram-v4), EnvSpec(Kangaroo-ramDeterministic-v0), EnvSpec(Kangaroo-ramDeterministic-v4), EnvSpec(Kangaroo-ramNoFrameskip-v0), EnvSpec(Kangaroo-ramNoFrameskip-v4), EnvSpec(Krull-v0), EnvSpec(Krull-v4), EnvSpec(KrullDeterministic-v0), EnvSpec(KrullDeterministic-v4), EnvSpec(KrullNoFrameskip-v0), EnvSpec(KrullNoFrameskip-v4), EnvSpec(Krull-ram-v0), EnvSpec(Krull-ram-v4), EnvSpec(Krull-ramDeterministic-v0), EnvSpec(Krull-ramDeterministic-v4), EnvSpec(Krull-ramNoFrameskip-v0), EnvSpec(Krull-ramNoFrameskip-v4), EnvSpec(KungFuMaster-v0), EnvSpec(KungFuMaster-v4), EnvSpec(KungFuMasterDeterministic-v0), EnvSpec(KungFuMasterDeterministic-v4), EnvSpec(KungFuMasterNoFrameskip-v0), EnvSpec(KungFuMasterNoFrameskip-v4), EnvSpec(KungFuMaster-ram-v0), EnvSpec(KungFuMaster-ram-v4), EnvSpec(KungFuMaster-ramDeterministic-v0), EnvSpec(KungFuMaster-ramDeterministic-v4), EnvSpec(KungFuMaster-ramNoFrameskip-v0), EnvSpec(KungFuMaster-ramNoFrameskip-v4), EnvSpec(MontezumaRevenge-v0), EnvSpec(MontezumaRevenge-v4), EnvSpec(MontezumaRevengeDeterministic-v0), EnvSpec(MontezumaRevengeDeterministic-v4), EnvSpec(MontezumaRevengeNoFrameskip-v0), EnvSpec(MontezumaRevengeNoFrameskip-v4), EnvSpec(MontezumaRevenge-ram-v0), EnvSpec(MontezumaRevenge-ram-v4), EnvSpec(MontezumaRevenge-ramDeterministic-v0), EnvSpec(MontezumaRevenge-ramDeterministic-v4), EnvSpec(MontezumaRevenge-ramNoFrameskip-v0), EnvSpec(MontezumaRevenge-ramNoFrameskip-v4), EnvSpec(MsPacman-v0), EnvSpec(MsPacman-v4), EnvSpec(MsPacmanDeterministic-v0), EnvSpec(MsPacmanDeterministic-v4), EnvSpec(MsPacmanNoFrameskip-v0), EnvSpec(MsPacmanNoFrameskip-v4), EnvSpec(MsPacman-ram-v0), EnvSpec(MsPacman-ram-v4), EnvSpec(MsPacman-ramDeterministic-v0), EnvSpec(MsPacman-ramDeterministic-v4), EnvSpec(MsPacman-ramNoFrameskip-v0), EnvSpec(MsPacman-ramNoFrameskip-v4), EnvSpec(NameThisGame-v0), EnvSpec(NameThisGame-v4), EnvSpec(NameThisGameDeterministic-v0), EnvSpec(NameThisGameDeterministic-v4), EnvSpec(NameThisGameNoFrameskip-v0), EnvSpec(NameThisGameNoFrameskip-v4), EnvSpec(NameThisGame-ram-v0), EnvSpec(NameThisGame-ram-v4), EnvSpec(NameThisGame-ramDeterministic-v0), EnvSpec(NameThisGame-ramDeterministic-v4), EnvSpec(NameThisGame-ramNoFrameskip-v0), EnvSpec(NameThisGame-ramNoFrameskip-v4), EnvSpec(Phoenix-v0), EnvSpec(Phoenix-v4), EnvSpec(PhoenixDeterministic-v0), EnvSpec(PhoenixDeterministic-v4), EnvSpec(PhoenixNoFrameskip-v0), EnvSpec(PhoenixNoFrameskip-v4), EnvSpec(Phoenix-ram-v0), EnvSpec(Phoenix-ram-v4), EnvSpec(Phoenix-ramDeterministic-v0), EnvSpec(Phoenix-ramDeterministic-v4), EnvSpec(Phoenix-ramNoFrameskip-v0), EnvSpec(Phoenix-ramNoFrameskip-v4), EnvSpec(Pitfall-v0), EnvSpec(Pitfall-v4), EnvSpec(PitfallDeterministic-v0), EnvSpec(PitfallDeterministic-v4), EnvSpec(PitfallNoFrameskip-v0), EnvSpec(PitfallNoFrameskip-v4), EnvSpec(Pitfall-ram-v0), EnvSpec(Pitfall-ram-v4), EnvSpec(Pitfall-ramDeterministic-v0), EnvSpec(Pitfall-ramDeterministic-v4), EnvSpec(Pitfall-ramNoFrameskip-v0), EnvSpec(Pitfall-ramNoFrameskip-v4), EnvSpec(Pong-v0), EnvSpec(Pong-v4), EnvSpec(PongDeterministic-v0), EnvSpec(PongDeterministic-v4), EnvSpec(PongNoFrameskip-v0), EnvSpec(PongNoFrameskip-v4), EnvSpec(Pong-ram-v0), EnvSpec(Pong-ram-v4), EnvSpec(Pong-ramDeterministic-v0), EnvSpec(Pong-ramDeterministic-v4), EnvSpec(Pong-ramNoFrameskip-v0), EnvSpec(Pong-ramNoFrameskip-v4), EnvSpec(Pooyan-v0), EnvSpec(Pooyan-v4), EnvSpec(PooyanDeterministic-v0), EnvSpec(PooyanDeterministic-v4), EnvSpec(PooyanNoFrameskip-v0), EnvSpec(PooyanNoFrameskip-v4), EnvSpec(Pooyan-ram-v0), EnvSpec(Pooyan-ram-v4), EnvSpec(Pooyan-ramDeterministic-v0), EnvSpec(Pooyan-ramDeterministic-v4), EnvSpec(Pooyan-ramNoFrameskip-v0), EnvSpec(Pooyan-ramNoFrameskip-v4), EnvSpec(PrivateEye-v0), EnvSpec(PrivateEye-v4), EnvSpec(PrivateEyeDeterministic-v0), EnvSpec(PrivateEyeDeterministic-v4), EnvSpec(PrivateEyeNoFrameskip-v0), EnvSpec(PrivateEyeNoFrameskip-v4), EnvSpec(PrivateEye-ram-v0), EnvSpec(PrivateEye-ram-v4), EnvSpec(PrivateEye-ramDeterministic-v0), EnvSpec(PrivateEye-ramDeterministic-v4), EnvSpec(PrivateEye-ramNoFrameskip-v0), EnvSpec(PrivateEye-ramNoFrameskip-v4), EnvSpec(Qbert-v0), EnvSpec(Qbert-v4), EnvSpec(QbertDeterministic-v0), EnvSpec(QbertDeterministic-v4), EnvSpec(QbertNoFrameskip-v0), EnvSpec(QbertNoFrameskip-v4), EnvSpec(Qbert-ram-v0), EnvSpec(Qbert-ram-v4), EnvSpec(Qbert-ramDeterministic-v0), EnvSpec(Qbert-ramDeterministic-v4), EnvSpec(Qbert-ramNoFrameskip-v0), EnvSpec(Qbert-ramNoFrameskip-v4), EnvSpec(Riverraid-v0), EnvSpec(Riverraid-v4), EnvSpec(RiverraidDeterministic-v0), EnvSpec(RiverraidDeterministic-v4), EnvSpec(RiverraidNoFrameskip-v0), EnvSpec(RiverraidNoFrameskip-v4), EnvSpec(Riverraid-ram-v0), EnvSpec(Riverraid-ram-v4), EnvSpec(Riverraid-ramDeterministic-v0), EnvSpec(Riverraid-ramDeterministic-v4), EnvSpec(Riverraid-ramNoFrameskip-v0), EnvSpec(Riverraid-ramNoFrameskip-v4), EnvSpec(RoadRunner-v0), EnvSpec(RoadRunner-v4), EnvSpec(RoadRunnerDeterministic-v0), EnvSpec(RoadRunnerDeterministic-v4), EnvSpec(RoadRunnerNoFrameskip-v0), EnvSpec(RoadRunnerNoFrameskip-v4), EnvSpec(RoadRunner-ram-v0), EnvSpec(RoadRunner-ram-v4), EnvSpec(RoadRunner-ramDeterministic-v0), EnvSpec(RoadRunner-ramDeterministic-v4), EnvSpec(RoadRunner-ramNoFrameskip-v0), EnvSpec(RoadRunner-ramNoFrameskip-v4), EnvSpec(Robotank-v0), EnvSpec(Robotank-v4), EnvSpec(RobotankDeterministic-v0), EnvSpec(RobotankDeterministic-v4), EnvSpec(RobotankNoFrameskip-v0), EnvSpec(RobotankNoFrameskip-v4), EnvSpec(Robotank-ram-v0), EnvSpec(Robotank-ram-v4), EnvSpec(Robotank-ramDeterministic-v0), EnvSpec(Robotank-ramDeterministic-v4), EnvSpec(Robotank-ramNoFrameskip-v0), EnvSpec(Robotank-ramNoFrameskip-v4), EnvSpec(Seaquest-v0), EnvSpec(Seaquest-v4), EnvSpec(SeaquestDeterministic-v0), EnvSpec(SeaquestDeterministic-v4), EnvSpec(SeaquestNoFrameskip-v0), EnvSpec(SeaquestNoFrameskip-v4), EnvSpec(Seaquest-ram-v0), EnvSpec(Seaquest-ram-v4), EnvSpec(Seaquest-ramDeterministic-v0), EnvSpec(Seaquest-ramDeterministic-v4), EnvSpec(Seaquest-ramNoFrameskip-v0), EnvSpec(Seaquest-ramNoFrameskip-v4), EnvSpec(Skiing-v0), EnvSpec(Skiing-v4), EnvSpec(SkiingDeterministic-v0), EnvSpec(SkiingDeterministic-v4), EnvSpec(SkiingNoFrameskip-v0), EnvSpec(SkiingNoFrameskip-v4), EnvSpec(Skiing-ram-v0), EnvSpec(Skiing-ram-v4), EnvSpec(Skiing-ramDeterministic-v0), EnvSpec(Skiing-ramDeterministic-v4), EnvSpec(Skiing-ramNoFrameskip-v0), EnvSpec(Skiing-ramNoFrameskip-v4), EnvSpec(Solaris-v0), EnvSpec(Solaris-v4), EnvSpec(SolarisDeterministic-v0), EnvSpec(SolarisDeterministic-v4), EnvSpec(SolarisNoFrameskip-v0), EnvSpec(SolarisNoFrameskip-v4), EnvSpec(Solaris-ram-v0), EnvSpec(Solaris-ram-v4), EnvSpec(Solaris-ramDeterministic-v0), EnvSpec(Solaris-ramDeterministic-v4), EnvSpec(Solaris-ramNoFrameskip-v0), EnvSpec(Solaris-ramNoFrameskip-v4), EnvSpec(SpaceInvaders-v0), EnvSpec(SpaceInvaders-v4), EnvSpec(SpaceInvadersDeterministic-v0), EnvSpec(SpaceInvadersDeterministic-v4), EnvSpec(SpaceInvadersNoFrameskip-v0), EnvSpec(SpaceInvadersNoFrameskip-v4), EnvSpec(SpaceInvaders-ram-v0), EnvSpec(SpaceInvaders-ram-v4), EnvSpec(SpaceInvaders-ramDeterministic-v0), EnvSpec(SpaceInvaders-ramDeterministic-v4), EnvSpec(SpaceInvaders-ramNoFrameskip-v0), EnvSpec(SpaceInvaders-ramNoFrameskip-v4), EnvSpec(StarGunner-v0), EnvSpec(StarGunner-v4), EnvSpec(StarGunnerDeterministic-v0), EnvSpec(StarGunnerDeterministic-v4), EnvSpec(StarGunnerNoFrameskip-v0), EnvSpec(StarGunnerNoFrameskip-v4), EnvSpec(StarGunner-ram-v0), EnvSpec(StarGunner-ram-v4), EnvSpec(StarGunner-ramDeterministic-v0), EnvSpec(StarGunner-ramDeterministic-v4), EnvSpec(StarGunner-ramNoFrameskip-v0), EnvSpec(StarGunner-ramNoFrameskip-v4), EnvSpec(Tennis-v0), EnvSpec(Tennis-v4), EnvSpec(TennisDeterministic-v0), EnvSpec(TennisDeterministic-v4), EnvSpec(TennisNoFrameskip-v0), EnvSpec(TennisNoFrameskip-v4), EnvSpec(Tennis-ram-v0), EnvSpec(Tennis-ram-v4), EnvSpec(Tennis-ramDeterministic-v0), EnvSpec(Tennis-ramDeterministic-v4), EnvSpec(Tennis-ramNoFrameskip-v0), EnvSpec(Tennis-ramNoFrameskip-v4), EnvSpec(TimePilot-v0), EnvSpec(TimePilot-v4), EnvSpec(TimePilotDeterministic-v0), EnvSpec(TimePilotDeterministic-v4), EnvSpec(TimePilotNoFrameskip-v0), EnvSpec(TimePilotNoFrameskip-v4), EnvSpec(TimePilot-ram-v0), EnvSpec(TimePilot-ram-v4), EnvSpec(TimePilot-ramDeterministic-v0), EnvSpec(TimePilot-ramDeterministic-v4), EnvSpec(TimePilot-ramNoFrameskip-v0), EnvSpec(TimePilot-ramNoFrameskip-v4), EnvSpec(Tutankham-v0), EnvSpec(Tutankham-v4), EnvSpec(TutankhamDeterministic-v0), EnvSpec(TutankhamDeterministic-v4), EnvSpec(TutankhamNoFrameskip-v0), EnvSpec(TutankhamNoFrameskip-v4), EnvSpec(Tutankham-ram-v0), EnvSpec(Tutankham-ram-v4), EnvSpec(Tutankham-ramDeterministic-v0), EnvSpec(Tutankham-ramDeterministic-v4), EnvSpec(Tutankham-ramNoFrameskip-v0), EnvSpec(Tutankham-ramNoFrameskip-v4), EnvSpec(UpNDown-v0), EnvSpec(UpNDown-v4), EnvSpec(UpNDownDeterministic-v0), EnvSpec(UpNDownDeterministic-v4), EnvSpec(UpNDownNoFrameskip-v0), EnvSpec(UpNDownNoFrameskip-v4), EnvSpec(UpNDown-ram-v0), EnvSpec(UpNDown-ram-v4), EnvSpec(UpNDown-ramDeterministic-v0), EnvSpec(UpNDown-ramDeterministic-v4), EnvSpec(UpNDown-ramNoFrameskip-v0), EnvSpec(UpNDown-ramNoFrameskip-v4), EnvSpec(Venture-v0), EnvSpec(Venture-v4), EnvSpec(VentureDeterministic-v0), EnvSpec(VentureDeterministic-v4), EnvSpec(VentureNoFrameskip-v0), EnvSpec(VentureNoFrameskip-v4), EnvSpec(Venture-ram-v0), EnvSpec(Venture-ram-v4), EnvSpec(Venture-ramDeterministic-v0), EnvSpec(Venture-ramDeterministic-v4), EnvSpec(Venture-ramNoFrameskip-v0), EnvSpec(Venture-ramNoFrameskip-v4), EnvSpec(VideoPinball-v0), EnvSpec(VideoPinball-v4), EnvSpec(VideoPinballDeterministic-v0), EnvSpec(VideoPinballDeterministic-v4), EnvSpec(VideoPinballNoFrameskip-v0), EnvSpec(VideoPinballNoFrameskip-v4), EnvSpec(VideoPinball-ram-v0), EnvSpec(VideoPinball-ram-v4), EnvSpec(VideoPinball-ramDeterministic-v0), EnvSpec(VideoPinball-ramDeterministic-v4), EnvSpec(VideoPinball-ramNoFrameskip-v0), EnvSpec(VideoPinball-ramNoFrameskip-v4), EnvSpec(WizardOfWor-v0), EnvSpec(WizardOfWor-v4), EnvSpec(WizardOfWorDeterministic-v0), EnvSpec(WizardOfWorDeterministic-v4), EnvSpec(WizardOfWorNoFrameskip-v0), EnvSpec(WizardOfWorNoFrameskip-v4), EnvSpec(WizardOfWor-ram-v0), EnvSpec(WizardOfWor-ram-v4), EnvSpec(WizardOfWor-ramDeterministic-v0), EnvSpec(WizardOfWor-ramDeterministic-v4), EnvSpec(WizardOfWor-ramNoFrameskip-v0), EnvSpec(WizardOfWor-ramNoFrameskip-v4), EnvSpec(YarsRevenge-v0), EnvSpec(YarsRevenge-v4), EnvSpec(YarsRevengeDeterministic-v0), EnvSpec(YarsRevengeDeterministic-v4), EnvSpec(YarsRevengeNoFrameskip-v0), EnvSpec(YarsRevengeNoFrameskip-v4), EnvSpec(YarsRevenge-ram-v0), EnvSpec(YarsRevenge-ram-v4), EnvSpec(YarsRevenge-ramDeterministic-v0), EnvSpec(YarsRevenge-ramDeterministic-v4), EnvSpec(YarsRevenge-ramNoFrameskip-v0), EnvSpec(YarsRevenge-ramNoFrameskip-v4), EnvSpec(Zaxxon-v0), EnvSpec(Zaxxon-v4), EnvSpec(ZaxxonDeterministic-v0), EnvSpec(ZaxxonDeterministic-v4), EnvSpec(ZaxxonNoFrameskip-v0), EnvSpec(ZaxxonNoFrameskip-v4), EnvSpec(Zaxxon-ram-v0), EnvSpec(Zaxxon-ram-v4), EnvSpec(Zaxxon-ramDeterministic-v0), EnvSpec(Zaxxon-ramDeterministic-v4), EnvSpec(Zaxxon-ramNoFrameskip-v0), EnvSpec(Zaxxon-ramNoFrameskip-v4), EnvSpec(CubeCrash-v0), EnvSpec(CubeCrashSparse-v0), EnvSpec(CubeCrashScreenBecomesBlack-v0), EnvSpec(MemorizeDigits-v0)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "I4JZQnqxIptg",
        "outputId": "332bfee7-8d2d-435a-bde2-48db1af13543"
      },
      "source": [
        "gym.EnvSpec('Alien-v0')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-639d431e099d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnvSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Alien-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'gym' has no attribute 'EnvSpec'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX_4yjQvI6dU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}