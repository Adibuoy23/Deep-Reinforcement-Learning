{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab6 figure1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsRL38_S9Aua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35f2ed8d-629b-47e5-d23a-f4bce45e1cb4"
      },
      "source": [
        "%pylab inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "from IPython import display\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc9r7Qax1xSc"
      },
      "source": [
        "class simpleMDP():\n",
        "    # normal distribution reward\n",
        "    def __init__(self, mu=-0.1, std=1, max_actions=10):\n",
        "        \n",
        "        self.mu = mu\n",
        "        self.std = std\n",
        "        self.max_actions = max_actions\n",
        "        \n",
        "        # Action numbers\n",
        "        self.right, self.left = 0, 1\n",
        "        # Define actions available for each state\n",
        "        self.state_actions = {\n",
        "            'A': [self.right, self.left],\n",
        "            'B': [i for i in range(max_actions)],\n",
        "            'C': [self.right], \n",
        "            'D': [self.left] }\n",
        "\n",
        "        self.state_transitions = {\n",
        "            'A': {self.right: 'C',\n",
        "                  self.left: 'B'},\n",
        "            'B': {a: 'D' for a in range(max_actions)},\n",
        "            'C': {self.right: 'Done'},\n",
        "            'D': {self.left: 'Done'}\n",
        "        }\n",
        "        \n",
        "        self.state = 'A'\n",
        "    \n",
        "    def step(self, action):\n",
        "        self.state = self.state_transitions[self.state][action]\n",
        "        # reward = 0 for all transitions except from B to D\n",
        "        reward = np.random.normal(self.mu, self.std) if self.state == 'D' else 0\n",
        "        done = True if self.state == 'D' or self.state == 'C' else False\n",
        "        return self.state, reward, done, None\n",
        "    \n",
        "    def available_actions(self, state=None):\n",
        "        if state is None:\n",
        "            return self.state_actions[self.state]\n",
        "        else:\n",
        "            return self.state_actions[state]\n",
        "    \n",
        "    def sample_actions(self):\n",
        "        return np.random.choice(self.available_actions())\n",
        "    \n",
        "    def reset(self):\n",
        "        self.state = 'A'\n",
        "        return self.state"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HEUCTHy1yCJ"
      },
      "source": [
        "class uniformMDP():\n",
        "    # uniform distribution reward\n",
        "    def __init__(self, low=-1, high=1, max_actions=10):\n",
        "        \n",
        "        self.low = low\n",
        "        self.high = high\n",
        "        self.max_actions = max_actions\n",
        "        \n",
        "        # Action numbers\n",
        "        self.right, self.left = 0, 1\n",
        "        # Define actions available for each state\n",
        "        self.state_actions = {\n",
        "            'A': [self.right, self.left],\n",
        "            'B': [i for i in range(max_actions)],\n",
        "            'C': [self.right], \n",
        "            'D': [self.left] }\n",
        "\n",
        "        self.state_transitions = {\n",
        "            'A': {self.right: 'C',\n",
        "                  self.left: 'B'},\n",
        "            'B': {a: 'D' for a in range(max_actions)},\n",
        "            'C': {self.right: 'Done'},\n",
        "            'D': {self.left: 'Done'}\n",
        "        }\n",
        "        \n",
        "        self.state = 'A'\n",
        "    \n",
        "    def step(self, action):\n",
        "        self.state = self.state_transitions[self.state][action]\n",
        "        # reward = 0 for all transitions except from B to D\n",
        "        reward = np.random.uniform(self.low, self.high) if self.state == 'D' else 0\n",
        "        done = True if self.state == 'D' or self.state == 'C' else False\n",
        "        return self.state, reward, done, None\n",
        "    \n",
        "    def available_actions(self, state=None):\n",
        "        if state is None:\n",
        "            return self.state_actions[self.state]\n",
        "        else:\n",
        "            return self.state_actions[state]\n",
        "    \n",
        "    def sample_actions(self):\n",
        "        return np.random.choice(self.available_actions())\n",
        "    \n",
        "    def reset(self):\n",
        "        self.state = 'A'\n",
        "        return self.state"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioay1w1xHiws",
        "outputId": "19a44d0c-9070-46a1-a203-3805813f2cf5"
      },
      "source": [
        "!pip3 install --upgrade plotly"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: plotly in /usr/local/lib/python3.6/dist-packages (4.13.0)\n",
            "Requirement already satisfied, skipping upgrade: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from plotly) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7olvbuoHloA"
      },
      "source": [
        "# Parameter\n",
        "num_actions_array = 4 #### 10\n",
        "rep = 3 ### 100\n",
        "actions_array = 2**np.arange(1,num_actions_array+1)\n",
        "\n",
        "# Single Q-Learning\n",
        "env = simpleMDP(max_actions=actions_array[3])\n",
        "max_tests = 1000\n",
        "n_eps = 100 #### adjustable\n",
        "eps = 0.1\n",
        "lr = 0.1\n",
        "\n",
        "def Qlearn_func(env=env, max_tests=max_tests, n_eps=n_eps, eps=eps, lr=lr):\n",
        "    left_count_q = np.zeros(n_eps)\n",
        "    q_estimate = np.zeros(n_eps)\n",
        "    greedy_count_q = { 0: np.zeros(n_eps), 1: np.zeros(n_eps) }\n",
        "    qB =np.zeros(n_eps)\n",
        "    t = 0\n",
        "    greedy = None\n",
        "    s_1 = None\n",
        "    while t < max_tests:\n",
        "        Q = {state: np.zeros(env.max_actions) for state in env.state_actions.keys()}\n",
        "        for ep in range(n_eps):\n",
        "            s_0 = env.reset()\n",
        "            while True:\n",
        "                # Select eps-greedy action\n",
        "                if np.random.uniform() < eps:\n",
        "                    action = env.sample_actions()\n",
        "                    greedy = False\n",
        "                else:\n",
        "                    # Break ties among max values randomly if ties exist\n",
        "                    # If no ties exist, the max will be selected with prob=1\n",
        "                    max_qs = np.where(\n",
        "                        np.max(Q[s_0][env.available_actions()])==\n",
        "                            Q[s_0][env.available_actions()])[0]\n",
        "                    action = np.random.choice(max_qs)\n",
        "                    greedy = True\n",
        "                    \n",
        "                # Counting\n",
        "                if s_0 == 'A':\n",
        "                    if action == 1:\n",
        "                        left_count_q[ep] += 1\n",
        "                        if greedy:\n",
        "                            greedy_count_q[1][ep] += 1\n",
        "                    else:\n",
        "                        if greedy:\n",
        "                            greedy_count_q[0][ep] += 1\n",
        "\n",
        "                s_1, reward, done, _ = env.step(action)\n",
        "\n",
        "                # Update Q-Tables\n",
        "                Q[s_0][action] += lr * (reward + np.max(Q[s_1][env.available_actions()]) - \n",
        "                                        Q[s_0][action])\n",
        "                s_0 = s_1\n",
        "                if done:\n",
        "                    q_estimate[ep] += (Q['A'][env.left] - q_estimate[ep]) / (ep + 1)\n",
        "                    qB[ep] = np.max(Q['B'][env.available_actions(state='B')])\n",
        "                    break\n",
        "        t += 1\n",
        "\n",
        "    return left_count_q, q_estimate, greedy_count_q, qB\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FYUWNUMHpKR"
      },
      "source": [
        "# Double Q-Learning\n",
        "\n",
        "def dQlearn_func(env=env, max_tests=max_tests, n_eps=n_eps, eps=eps, lr=lr):\n",
        "    import copy\n",
        "    left_count_dq = np.zeros(n_eps)\n",
        "    q1_estimate = np.zeros(n_eps)\n",
        "    q2_estimate = np.zeros(n_eps)\n",
        "    dq_estimate = np.zeros(n_eps)\n",
        "    greedy_count_dq = { 0: np.zeros(n_eps), 1: np.zeros(n_eps) }\n",
        "    dqB = np.zeros(n_eps)\n",
        "    t = 0\n",
        "    greedy = None\n",
        "    s_1 = None\n",
        "    while t < max_tests:\n",
        "        Q1 = {state: np.zeros(env.max_actions) for state in env.state_actions.keys()}\n",
        "        Q2 = copy.deepcopy(Q1)\n",
        "        for ep in range(n_eps):\n",
        "            s_0 = env.reset()\n",
        "            while True:\n",
        "                # Select eps-greedy action\n",
        "                if np.random.uniform() < eps or ep == 0:\n",
        "                    action = env.sample_actions()\n",
        "                    greedy = False\n",
        "                else:\n",
        "                    # If no ties exist, the max will be selected with prob=1\n",
        "                    Q_sum = Q1[s_0][env.available_actions()] + \\\n",
        "                            Q2[s_0][env.available_actions()]\n",
        "                    max_qs = np.where(np.max(Q_sum)==Q_sum)[0]\n",
        "                    action = np.random.choice(max_qs)\n",
        "                    greedy = True\n",
        "\n",
        "                # Counting ####\n",
        "                if s_0 == 'A':\n",
        "                    if action == 1:\n",
        "                        left_count_dq[ep] += 1\n",
        "                        if greedy:\n",
        "                            greedy_count_dq[1][ep] += 1\n",
        "                    else:\n",
        "                        if greedy:\n",
        "                            greedy_count_dq[0][ep] += 1\n",
        "\n",
        "                s_1, reward, done, _ = env.step(action)\n",
        "\n",
        "                # Update Q-Tables\n",
        "                if np.random.uniform() < 0.5:\n",
        "                    Q1[s_0][action] += lr * (reward + \\\n",
        "                        Q2[s_1][np.argmax(Q1[s_1][env.state_actions[s_1]])] \n",
        "                                             - Q1[s_0][action])\n",
        "                else:\n",
        "                    Q2[s_0][action] += lr * (reward + \\\n",
        "                        Q1[s_1][np.argmax(Q2[s_1][env.state_actions[s_1]])] \\\n",
        "                                             - Q2[s_0][action])\n",
        "                s_0 = s_1\n",
        "                if done:\n",
        "                    q1_estimate[ep] += (Q1['A'][env.left] - q1_estimate[ep]) / (ep + 1)\n",
        "                    q2_estimate[ep] += (Q2['A'][env.left] - q2_estimate[ep]) / (ep + 1)\n",
        "                    dqB[ep] = Q2['B'][np.argmax(Q1['B'][env.state_actions['B']])]\n",
        "                    break\n",
        "        t += 1\n",
        "    dq_estimate = 0.5*(q1_estimate + q2_estimate)\n",
        "    \n",
        "    return left_count_dq, dq_estimate, greedy_count_dq, dqB"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlSJ84gbIfB7"
      },
      "source": [
        "# normal distribution\n",
        "\n",
        "# Parameter\n",
        "actions_list = [2,16,64,256]# [2,4,8,16,32,64,128,256,512,1024]\n",
        "actions_range = size(actions_list)\n",
        "max_tests = 1000\n",
        "n_eps = 40 #### adjustable\n",
        "eps = 0.1\n",
        "lr = 0.1\n",
        "rep = 20 #### repetition\n",
        "\n",
        "qB_mean = np.zeros((actions_range, n_eps))\n",
        "dqB_mean = np.zeros((actions_range, n_eps))\n",
        "qB_std = np.zeros((actions_range, n_eps))\n",
        "dqB_std = np.zeros((actions_range, n_eps))\n",
        "\n",
        "actions_idx = 0\n",
        "while actions_idx < actions_range:\n",
        "    # normal distribution\n",
        "    env = simpleMDP(max_actions=actions_array[3])\n",
        "    \n",
        "    qB_pred = np.zeros((rep, n_eps))\n",
        "    dqB_pred = np.zeros((rep, n_eps))\n",
        "    for r in range(rep):\n",
        "        qB_pred[r,:] = Qlearn_func(env=env, max_tests=max_tests, n_eps=n_eps, eps=eps, lr=lr)[3]\n",
        "        dqB_pred[r,:] = dQlearn_func(env=env, max_tests=max_tests, n_eps=n_eps, eps=eps, lr=lr)[3]\n",
        "\n",
        "    qB_mean[actions_idx,:] = np.mean(qB_pred, axis=0)\n",
        "    dqB_mean[actions_idx,:] = np.mean(dqB_pred, axis=0)\n",
        "    qB_std[actions_idx,:] = np.std(qB_pred, axis=0)\n",
        "    dqB_std[actions_idx,:] = np.std(dqB_pred, axis=0)\n",
        "    \n",
        "    actions_idx += 1\n",
        "    \n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "WaQY6-4IIzkk",
        "outputId": "6155e98a-3ac3-4afe-d9bf-8725debffa6a"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "actions_list_str = ['m = '+str(x) for x in actions_list] \n",
        "V = -0.1\n",
        "\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Bar(\n",
        "    #     name=r'$\\max_a Q(s_B,a) -V_*(s_B)$',\n",
        "    name='Q-learning',\n",
        "    marker_color='indianred',\n",
        "    x=actions_list_str, y=qB_mean[:,-1]-V,\n",
        "    error_y=dict(type='data', array=qB_std[:,-1])  # use the lase col of array\n",
        "))\n",
        "fig.add_trace(go.Bar(\n",
        "    #     name=r'$Q(s_B,\\arg \\max_a Q(s_B,a) -V_*(s_B))$',\n",
        "    name='double Q-learning',\n",
        "    marker_color='lightblue',\n",
        "    x=actions_list_str, y=dqB_mean[:,-1]-V,\n",
        "    error_y=dict(type='data', array=dqB_std[:,-1])\n",
        "))\n",
        "fig.update_layout(barmode='group')\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    yaxis_title='Error',\n",
        "    title='Bias of QL & dQL on i.d.d. normal distribution var',\n",
        "    hovermode=\"x\",\n",
        "    paper_bgcolor = 'rgba(0,0,0,0)',\n",
        "    plot_bgcolor = 'rgba(0,0,0,0)',\n",
        "    font = dict(size = 16, color = 'black'),\n",
        "    width = 700,\n",
        "    height = 400\n",
        ")\n",
        "fig.update_xaxes(title = 'number of actions',showgrid=True, gridwidth=1.5, gridcolor='#DFDFDF', showline=True, linecolor = '#AFAFAF', linewidth = 2.5, nticks = 7)\n",
        "fig.update_yaxes(showgrid=True, gridwidth=1.5, gridcolor='#DFDFDF', showline=True, linecolor = '#AFAFAF', linewidth = 2.5, nticks = 7)\n",
        "fig.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>                <div id=\"f1b942b6-e70c-47af-b188-e8e208430b52\" class=\"plotly-graph-div\" style=\"height:400px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f1b942b6-e70c-47af-b188-e8e208430b52\")) {                    Plotly.newPlot(                        \"f1b942b6-e70c-47af-b188-e8e208430b52\",                        [{\"error_y\": {\"array\": [0.10557595619868972, 0.0891540676687455, 0.12299365366697532, 0.09654761017006512], \"type\": \"data\"}, \"marker\": {\"color\": \"indianred\"}, \"name\": \"Q-learning\", \"type\": \"bar\", \"x\": [\"m = 2\", \"m = 16\", \"m = 64\", \"m = 256\"], \"y\": [0.17132386570731906, 0.18537909839179983, 0.21135468707916338, 0.20412165750132688]}, {\"error_y\": {\"array\": [0.08207287391305837, 0.08619528884101896, 0.05210007911989678, 0.048850860545939415], \"type\": \"data\"}, \"marker\": {\"color\": \"lightblue\"}, \"name\": \"double Q-learning\", \"type\": \"bar\", \"x\": [\"m = 2\", \"m = 16\", \"m = 64\", \"m = 256\"], \"y\": [0.06945496869577186, 0.10387032844946034, 0.0612394351355761, 0.06902127371108506]}],                        {\"barmode\": \"group\", \"font\": {\"color\": \"black\", \"size\": 16}, \"height\": 400, \"hovermode\": \"x\", \"paper_bgcolor\": \"rgba(0,0,0,0)\", \"plot_bgcolor\": \"rgba(0,0,0,0)\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Bias of QL & dQL on i.d.d. normal distribution var\"}, \"width\": 700, \"xaxis\": {\"gridcolor\": \"#DFDFDF\", \"gridwidth\": 1.5, \"linecolor\": \"#AFAFAF\", \"linewidth\": 2.5, \"nticks\": 7, \"showgrid\": true, \"showline\": true, \"title\": {\"text\": \"number of actions\"}}, \"yaxis\": {\"gridcolor\": \"#DFDFDF\", \"gridwidth\": 1.5, \"linecolor\": \"#AFAFAF\", \"linewidth\": 2.5, \"nticks\": 7, \"showgrid\": true, \"showline\": true, \"title\": {\"text\": \"Error\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f1b942b6-e70c-47af-b188-e8e208430b52');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX1Cmx11I5Y5"
      },
      "source": [
        "# uniform distribution\n",
        "\n",
        "# Parameter\n",
        "actions_list = [2,16,64,256]\n",
        "actions_range = size(actions_list)\n",
        "max_tests = 1000\n",
        "n_eps = 40 #### adjustable\n",
        "eps = 0.1\n",
        "lr = 0.1\n",
        "rep = 5 #### repetition\n",
        "\n",
        "qB_mean = np.zeros((actions_range, n_eps))\n",
        "dqB_mean = np.zeros((actions_range, n_eps))\n",
        "qB_std = np.zeros((actions_range, n_eps))\n",
        "dqB_std = np.zeros((actions_range, n_eps))\n",
        "\n",
        "actions_idx = 0\n",
        "while actions_idx < actions_range:\n",
        "    # uniform distribution\n",
        "    env = uniformMDP(max_actions=actions_array[3])\n",
        "    \n",
        "    qB_pred = np.zeros((rep, n_eps))\n",
        "    dqB_pred = np.zeros((rep, n_eps))\n",
        "    for r in range(rep):\n",
        "        qB_pred[r,:] = Qlearn_func(env=env, max_tests=max_tests, n_eps=n_eps, eps=eps, lr=lr)[3]\n",
        "        dqB_pred[r,:] = dQlearn_func(env=env, max_tests=max_tests, n_eps=n_eps, eps=eps, lr=lr)[3]\n",
        "\n",
        "    qB_mean[actions_idx,:] = np.mean(qB_pred, axis=0)\n",
        "    dqB_mean[actions_idx,:] = np.mean(dqB_pred, axis=0)\n",
        "    qB_std[actions_idx,:] = np.std(qB_pred, axis=0)\n",
        "    dqB_std[actions_idx,:] = np.std(dqB_pred, axis=0)\n",
        "    \n",
        "    actions_idx += 1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "GhXe72L1I6uU",
        "outputId": "6414ca7e-ed9b-49e4-90c1-7addeb8768fb"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "V = 0\n",
        "\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Bar(\n",
        "    #     name=r'$\\max_a Q(s_B,a) -V_*(s_B)$',\n",
        "    name='Q-learning',\n",
        "    marker_color='indianred',\n",
        "    x=actions_list_str, y=qB_mean[:,-1]-V,\n",
        "    error_y=dict(type='data', array=qB_std[:,-1])  # use the lase col of array\n",
        "))\n",
        "fig.add_trace(go.Bar(\n",
        "    #     name=r'$Q(s_B,\\arg \\max_a Q(s_B,a) -V_*(s_B))$',\n",
        "    name='double Q-learning',\n",
        "    marker_color='lightblue',\n",
        "    x=actions_list_str, y=dqB_mean[:,-1]-V,\n",
        "    error_y=dict(type='data', array=dqB_std[:,-1])\n",
        "))\n",
        "fig.update_layout(barmode='group')\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    yaxis_title='Error',\n",
        "    title='Bias of QL & dQL on i.d.d. uniform distribution var [-1,1]',\n",
        "    hovermode=\"x\",\n",
        "    paper_bgcolor = 'rgba(0,0,0,0)',\n",
        "    plot_bgcolor = 'rgba(0,0,0,0)',\n",
        "    font = dict(size = 16, color = 'black'),\n",
        "    width = 700,\n",
        "    height = 400\n",
        ")\n",
        "fig.update_xaxes(title = 'number of actions',showgrid=True, gridwidth=1.5, gridcolor='#DFDFDF', showline=True, linecolor = '#AFAFAF', linewidth = 2.5, nticks = 7)\n",
        "fig.update_yaxes(showgrid=True, gridwidth=1.5, gridcolor='#DFDFDF', showline=True, linecolor = '#AFAFAF', linewidth = 2.5, nticks = 7)\n",
        "fig.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>                <div id=\"4f13c8c1-e6ea-471a-aedb-188308ea3d05\" class=\"plotly-graph-div\" style=\"height:400px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4f13c8c1-e6ea-471a-aedb-188308ea3d05\")) {                    Plotly.newPlot(                        \"4f13c8c1-e6ea-471a-aedb-188308ea3d05\",                        [{\"error_y\": {\"array\": [0.04435388571420286, 0.07149945143671806, 0.03778622014922417, 0.08862730332096004], \"type\": \"data\"}, \"marker\": {\"color\": \"indianred\"}, \"name\": \"Q-learning\", \"type\": \"bar\", \"x\": [\"m = 2\", \"m = 16\", \"m = 64\", \"m = 256\"], \"y\": [0.08362178049183701, 0.053208341052301725, 0.12291910899839495, 0.07215824985693242]}, {\"error_y\": {\"array\": [0.03529455411115872, 0.07380498592006697, 0.09146582476835415, 0.09353520428543954], \"type\": \"data\"}, \"marker\": {\"color\": \"lightblue\"}, \"name\": \"double Q-learning\", \"type\": \"bar\", \"x\": [\"m = 2\", \"m = 16\", \"m = 64\", \"m = 256\"], \"y\": [0.026987714056674595, 0.0442556638680903, 0.0002572536275083914, 0.03002493722386577]}],                        {\"barmode\": \"group\", \"font\": {\"color\": \"black\", \"size\": 16}, \"height\": 400, \"hovermode\": \"x\", \"paper_bgcolor\": \"rgba(0,0,0,0)\", \"plot_bgcolor\": \"rgba(0,0,0,0)\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Bias of QL & dQL on i.d.d. uniform distribution var [-1,1]\"}, \"width\": 700, \"xaxis\": {\"gridcolor\": \"#DFDFDF\", \"gridwidth\": 1.5, \"linecolor\": \"#AFAFAF\", \"linewidth\": 2.5, \"nticks\": 7, \"showgrid\": true, \"showline\": true, \"title\": {\"text\": \"number of actions\"}}, \"yaxis\": {\"gridcolor\": \"#DFDFDF\", \"gridwidth\": 1.5, \"linecolor\": \"#AFAFAF\", \"linewidth\": 2.5, \"nticks\": 7, \"showgrid\": true, \"showline\": true, \"title\": {\"text\": \"Error\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4f13c8c1-e6ea-471a-aedb-188308ea3d05');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}